# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_data.block.ipynb (unless otherwise specified).

__all__ = ['DQN', 'TestDatasetNoModule', 'TestDataset', 'DQN', 'TestDataset']

# Cell
# Python native modules
import os
# Third party libs
from fastcore.all import *
from fastai.torch_basics import *
from fastai.data.all import *
from fastai.basics import *
from torch.utils.data import Dataset
from torch import nn


import numpy as np
import gym
import time,sys
import torch.multiprocessing as mp

# Local modules

# Cell
class DQN(Module):
    def __init__(self):
        self.policy=nn.Sequential(
            nn.Linear(4,50),
            nn.ReLU(),
            nn.Linear(50,2),
            nn.ReLU()
        )

    def forward(self,x):
        return torch.argmax(self.policy(x),dim=0)

# Cell
class TestDatasetNoModule(IterableDataset):
    def __init__(self,device='cpu'):
        self.device=device
        self.pids=[os.getpid()]

    def __len__(self): return 10
    def __getitem__(self,idx):
        print('starting')
        sys.stdout.flush()
        try:
            print('making env')
            print('pid is: ',os.getpid(),flush=True)
            self.pids.append(os.getpid())
#             env=gym.make('CartPole-v1')
            return torch.rand(1,4).to(device=self.device)
        except Exception as e:
            print(e,'it crashed lol omg')
            sys.stdout.flush()
            return torch.rand(1,4).to(device=self.device)

# Cell

class TestDataset(Dataset):
    def __init__(self,policy,device='cpu'):
        self.policy=policy
        self.device=device
        self.policy.to(device=self.device)

        self.pids=mp.Queue()
        self.pids.put(os.getpid())
        self.envs=mp.Queue()
        self.envs.put(os.getpid())

        self.env=gym.make('CartPole-v1')

    def __len__(self): return 100
    def __getitem__(self,idx):
        self.pids.put(os.getpid())
        self.envs.put(id(self.env))
        try:
#             env=gym.make('CartPole-v1')
            next_state=self.env.reset()
            print(id(self.env),' ')
            print('pid is: ',os.getpid(),flush=True)
            next_state, r, is_done, _=self.env.step(self.policy(Tensor(next_state).to(device=self.device)).cpu().numpy())
            if is_done:next_state=self.env.reset()
            return Tensor(next_state).to(device=self.device)
        except Exception as e:
            print(e)
            return Tensor(np.random.rand(0,4)).to(device=self.device)

# Cell
# Python native modules
import os
# Third party libs
from fastcore.all import *
from fastai.torch_basics import *
from fastai.data.all import *
from fastai.basics import *
from torch.utils.data import Dataset
from torch import nn


import numpy as np
import gym
import time,sys
import torch.multiprocessing as mp

# Local modules

# Cell
class DQN(Module):
    def __init__(self):
        self.policy=nn.Sequential(
            nn.Linear(4,50),
            nn.ReLU(),
            nn.Linear(50,2),
            nn.ReLU()
        )

    def forward(self,x):
        return torch.argmax(self.policy(x),dim=0)

# Cell
class TestDataset(IterableDataset):
    names='start,end,policy,device'
    def __init__(self,start=1, end=10,policy=None,device='cpu'):
#         delattr(self,'__slots__')
        store_attr('start,end,policy,device')

    def init_envs(self):
        self.env=gym.make('CartPole-v1')

    def __iter__(self):
        worker_info = torch.utils.data.get_worker_info()
        if worker_info is None:  # single-process data loading, return the full iterator
            iter_start = self.start
            iter_end = self.end
        else:  # in a worker process
            # split workload
            per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers)))
            worker_id = worker_info.id
            iter_start = self.start + worker_id * per_worker
            iter_end = min(iter_start + per_worker, self.end)
        return iter(range(iter_start, iter_end))