# AUTOGENERATED BY NBDEV! DO NOT EDIT!

__all__ = ["index", "modules", "custom_doc_links", "git_url"]

index = {"PixelObservationWrapper": "01_wrappers.ipynb",
         "STATE_KEY": "01_wrappers.ipynb",
         "ActionSelector": "03_basic_agents.ipynb",
         "ArgmaxActionSelector": "03_basic_agents.ipynb",
         "EpsilonGreedyActionSelector": "03_basic_agents.ipynb",
         "ProbabilityActionSelector": "03_basic_agents.ipynb",
         "default_states_preprocessor": "03_basic_agents.ipynb",
         "float32_preprocessor": "03_basic_agents.ipynb",
         "BaseAgent": "03_basic_agents.ipynb",
         "TestAgent": "05a_data.ipynb",
         "DiscreteAgent": "03_basic_agents.ipynb",
         "DQNAgent": "03_basic_agents.ipynb",
         "TargetNet": "03_basic_agents.ipynb",
         "PolicyAgent": "03_basic_agents.ipynb",
         "ActorCriticAgent": "03_basic_agents.ipynb",
         "AgentLearner": "06_basic_train.ipynb",
         "is_single_nested_tuple": "05a_data.ipynb",
         "TfmdSourceDL": "05a_data.ipynb",
         "TfmdSource": "05a_data.ipynb",
         "IterableDataBlock": "05a_data.ipynb",
         "SeedZeroWrapper": "05a_data.ipynb",
         "MakeTfm": "05a_data.ipynb",
         "env_display": "05a_data.ipynb",
         "envlen": "05a_data.ipynb",
         "ResetAndStepTfm": "05a_data.ipynb",
         "ExperienceBlock": "05a_data.ipynb",
         "FirstLastTfm": "15_actorcritic.a3c_data.ipynb",
         "FirstLastExperienceBlock": "15_actorcritic.a3c_data.ipynb",
         "ExperienceFirstLast": "05a_data.ipynb",
         "template_data_fit": "05b_async_data.ipynb",
         "DataFitProcess": "05b_async_data.ipynb",
         "MultiProcessTfm": "05b_async_data.ipynb",
         "AsyncExperienceBlock": "05b_async_data.ipynb",
         "FloatifyCallback": "06_basic_train.ipynb",
         "FakeRunCallback": "06_basic_train.ipynb",
         "LatentLossBuffer": "06_basic_train.ipynb",
         "AvgEpisodeRewardMetric": "13_metrics.ipynb",
         "Critic": "14_actorcritic.sac.ipynb",
         "Actor": "14_actorcritic.sac.ipynb",
         "SACTrainer": "14_actorcritic.sac.ipynb",
         "loss_func": "15_actorcritic.a3c_data.ipynb",
         "SACLearner": "14_actorcritic.sac.ipynb",
         "LinearA2C": "16_actorcritic.a2c.ipynb",
         "r_estimate": "16_actorcritic.a2c.ipynb",
         "unbatch": "16_actorcritic.a2c.ipynb",
         "A3CLearner": "15_actorcritic.a3c_data.ipynb",
         "A2CTrainer": "15_actorcritic.a3c_data.ipynb"}

modules = ["wrappers.py",
           "basic_agents.py",
           "learner.py",
           "data.py",
           "async_data.py",
           "basic_train.py",
           "metrics.py",
           "actorcritic/sac.py",
           "actorcritic/a3c_data.py",
           "actorcritic/a2c.py"]

doc_url = "https://josiahls.github.io/fast-reinforcement-learning-2/"

git_url = "https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/"

def custom_doc_links(name): return None
