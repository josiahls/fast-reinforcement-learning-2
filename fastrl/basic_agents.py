# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03_basic_agents.ipynb (unless otherwise specified).

__all__ = ['ActionSelector', 'ArgmaxActionSelector', 'EpsilonGreedyActionSelector', 'ProbabilityActionSelector',
           'default_states_preprocessor', 'float32_preprocessor', 'BaseAgent', 'TestAgent', 'DQNAgent']

# Cell
import torch, torch.nn.functional as F
from torch import ByteTensor, DoubleTensor, FloatTensor, HalfTensor, LongTensor, ShortTensor, Tensor
from torch import nn, optim, as_tensor
from torch.utils.data import BatchSampler, DataLoader, Dataset, Sampler, TensorDataset
from torch.nn.utils import weight_norm, spectral_norm
from dataclasses import asdict,dataclass
from typing import Callable,Tuple,Union
import textwrap
import numpy as np
import logging

"Note these are modified versions of 'Shmuma/Ptan'. Github, 2020, https://github.com/Shmuma/ptan/blob/master/ptan/agent.py. Accessed 13 June 2020."

# Cell
class ActionSelector:
    "Abstract class which converts scores to the actions."
    def __call__(self,scores):raise NotImplementedError

class ArgmaxActionSelector(ActionSelector):
    "Selects actions using argmax."
    def __call__(self,scores):
        assert isinstance(scores,np.ndarray)
        return np.argmax(scores,axis=1)

@dataclass
class EpsilonGreedyActionSelector(ActionSelector):
    epsilon:float=0.05
    selector:ActionSelector=ArgmaxActionSelector()

    def __call__(self,scores):
        assert isinstance(scores,np.ndarray)
        bs,n_a=scores.shape
        a=self.selector(scores)
        mask=np.random.random(size=bs)<self.epsilon
        rand_a=np.random.choice(n_a, sum(mask))
        a[mask]=rand_a
        return a

class ProbabilityActionSelector(ActionSelector):
    "Converts probabilities of actions into action by sampling them."
    def __call__(self,probs):
        assert isinstance(probs,np.ndarray)
        actions=[np.random.choice(len(prob),p=prob) for prob in probs]
        return np.array(actions)

# Cell
def default_states_preprocessor(s,dtype=np.float32):
    "Convert list of states into the form suitable for model. By default we assume Variable."
    np_s=np.expand_dims(s,0) if len(np.array(s).shape)==1 else np.array(s, copy=False)
    return torch.tensor(np_s.astype(dtype))

def float32_preprocessor(s):
    np_s=np.array(s, dtype=np.float32)
    return torch.tensor(np_s)

# Cell
@dataclass
class BaseAgent(object):
    model:nn.Module=None # If None, learner will set
    def initial_state(self):return None
    def __call__(self,sl,asl,include_batch_dim=False):
        assert isinstance(sl,(list,np.ndarray))
        assert isinstance(asl,(list,np.ndarray))
        assert len(asl)==len(sl)
        raise NotImplementedError()


@dataclass
class TestAgent(BaseAgent):
    env:object=None
    def initial_state(self):return None
    def __call__(self,sl,asl=None,include_batch_dim=False):
        if type(self.env)!=list:return self.env.action_space.sample(),None
        return self.env[0].action_space.sample(),None

# Cell
@dataclass
class DQNAgent(BaseAgent):
    "DQNAgent is a memoryless DQN agent which calculates Q values from the observations and  converts them into the actions using a_selector."
    a_selector:ActionSelector=ArgmaxActionSelector()
    device:str=None
    preprocessor:Callable=default_states_preprocessor

    def safe_unbatch(self,o:np.array)->np.array:return o[0] if o.shape[0]==1 and len(o.shape)>1 else o

    @torch.no_grad()
    def __call__(self,s,asl=None,include_batch_dim=False)->Tuple[np.array,np.array]:
        s=self.preprocessor(s) if self.preprocessor is not None else s
        asl= np.zeros(s.shape) if asl is None else asl
        s=s.to(self.device) if torch.is_tensor(s) else s
        q_v=self.model(s)
        q=q_v.data.cpu().numpy()
        al=self.a_selector(q)
        if not include_batch_dim:al=self.safe_unbatch(al).tolist()
        return al if len(al)!=1 or include_batch_dim else al[0],asl