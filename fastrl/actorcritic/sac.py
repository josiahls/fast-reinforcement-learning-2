# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/14_actorcritic.sac.ipynb (unless otherwise specified).

__all__ = ['LinearA2C', 'SACTrainer', 'loss_func', 'SACLearner']

# Cell
import torch.nn.utils as nn_utils
from fastai.torch_basics import *
from fastai.data.all import *
from fastai.basics import *
from dataclasses import field,asdict
from typing import List,Any,Dict,Callable
from collections import deque
import gym
import torch.multiprocessing as mp
from torch.optim import *

from ..data import *
from ..async_data import *
from ..basic_agents import *
from ..learner import *
from ..metrics import *
from fastai.callback.progress import *

if IN_NOTEBOOK:
    from IPython import display
    import PIL.Image

# Cell
class LinearA2C(Module):
    def __init__(self, input_shape, n_actions):
        super(LinearA2C, self).__init__()

        self.policy = nn.Sequential(
            nn.Linear(input_shape[0], 512),
            nn.ReLU(),
            nn.Linear(512, n_actions)
        )

        self.value = nn.Sequential(
            nn.Linear(input_shape[0], 512),
            nn.ReLU(),
            nn.Linear(512, 1)
        )

    def _get_conv_out(self, shape):
        o=self.conv(torch.zeros(1, *shape))
        return int(np.prod(o.size()))

    def forward(self,x):
        fx=x.float()
        return self.policy(fx),self.value(fx)

# Cell
class SACTrainer(Callback):

    def after_backward(self):
        nn_utils.clip_grad_norm_(self.learn.model.parameters(),self.learn.clip_grad)

# Cell
def loss_func(pred,yb,learn):



    return loss_v

class SACLearner(AgentLearner):
    def __init__(self,dls,**kwargs):
        self.create_m=True
        super().__init__(dls,loss_func=partial(loss_func,learn=self),**kwargs)

    def _split(self, b):
        if len(b)==1 and type(b[0])==tuple:b=b[0]
        super()._split(b)