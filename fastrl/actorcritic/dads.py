# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/14c_actorcritic.dads.ipynb (unless otherwise specified).

__all__ = ['OptionalClampLinear', 'MultiCompGMM', 'SimpleGMM', 'GMM', 'SkillDynamics', 'discrete_uniform',
           'cont_gaussian', 'cont_uniform', 'DADS']

# Cell
import torch.nn.utils as nn_utils
from fastai.torch_basics import *
import torch.nn.functional as F
from fastai.data.all import *
from fastai.basics import *
from dataclasses import field,asdict
from typing import List,Any,Dict,Callable
from collections import deque
import gym
import torch.multiprocessing as mp
from torch.optim import *
from dataclasses import dataclass

from ..data import *
from ..async_data import *
from ..basic_agents import *
from ..learner import *
from ..metrics import *
from fastai.callback.progress import *
from ..ptan_extension import *
from .sac import *
from .diayn import *
import gym
from torch.distributions import *

import matplotlib.pyplot as plt

if IN_NOTEBOOK:
    from IPython import display
    import PIL.Image

# Cell
class OptionalClampLinear(Module):
    def __init__(self,num_inputs,state_dims,fix_variance:bool=False,
                 clip_min=0.3,clip_max=10.0):
        "Linear layer or constant block used for std."
        store_attr()
        if not self.fix_variance: self.fc=nn.Linear(self.num_inputs,self.state_dims)

    def forward(self,x):
        if self.fix_variance: return torch.full((x.shape[0],self.state_dims),1.0)
        else:                 return torch.clamp(nn.Softplus()(self.fc(x)),self.clip_min,self.clip_max)

class MultiCompGMM(Module):
    def __init__(self,num_inputs,state_dims,n_components,fix_variance:bool=False):
        "Multi-component GMM parameterized by a fully connected layer with optional std layer."
        store_attr()
        self.logit_fc=nn.Linear(self.num_inputs,self.n_components)
        self.mean_fcs=nn.ModuleList([nn.Linear(self.num_inputs,self.state_dims)
                                     for _ in range(self.n_components)])
        self.std_fcs=nn.ModuleList([OptionalClampLinear(self.num_inputs,self.state_dims,fix_variance)
                                    for _ in range(self.n_components)])
        self.means,self.logits,self.stds=[],[],[]

    def forward(self,x):
        self.means=torch.stack([o(x) for o in self.mean_fcs],dim=1)
        self.stds=torch.stack([o(x) for o in self.std_fcs],dim=1)
        self.logits=self.logit_fc(x)
        return MixtureSameFamily(
            mixture_distribution=Categorical(self.logits),
            component_distribution=Independent(Normal(self.means,self.stds),1)
        )

class SimpleGMM(Module):
    def __init__(self,num_inputs,state_dims,fix_variance:bool=False):
        "Single-component GMM parameterized by a fully connected layer with optional std layer."
        store_attr()
        self.mean_fc=nn.Linear(self.num_inputs,self.state_dims)
        self.std_fc=OptionalClampLinear(self.num_inputs,self.state_dims,fix_variance)

    def forward(self,x): return Independent(Normal(self.mean_fc(x),self.std_fc(x)),1)

class GMM(Module):
    def __init__(self,num_inputs,state_dims,n_components,fix_variance:bool=False):
        "N-component GMM parameterized by fully connected layers with optional std layers."
        store_attr()
        if self.n_components>1: self.distribution=MultiCompGMM(num_inputs,state_dims,n_components,fix_variance)
        else:                   self.distribution=SimpleGMM(num_inputs,state_dims,fix_variance)

    def forward(self,x): return self.distribution(x)

# Cell
class SkillDynamics(Module):
    def __init__(self,s_dim,a_dim,n_components,fix_variance:bool=False,
                 use_model_mean:bool=None,use_batch_norm:bool=True,fc_params:tuple=None):
        store_attr(but='fc_params,use_model_mean')
        self.fc_params=ifnone(fc_params,(256,256))
        self.use_model_mean=ifnone(use_model_mean,n_components>1)
        if self.use_batch_norm:
            self.s_bn,self.sp_bn=nn.BatchNorm1d(s_dim),nn.BatchNorm1d(s_dim)
        self.fcs=nn.Sequential(*[nn.Linear((s_dim+a_dim) if i==0 else self.fc_params[i-1],p)
                                for i,p in enumerate(self.fc_params)])

        self.gmm=GMM(self.fc_params[-1],s_dim,n_components,fix_variance)

    def forward(self,s,a,sp=None,training=True):
        "Returns the `GMM` distribution of `s` and `a`, mean, and **optionally** "\
        "log(p) of the state transition between `s` and `sp` if `sp` is not None."
        if sp is not None: sp=sp-s
        if not training: self.eval()

        if self.use_batch_norm:
            s=self.s_bn(s)
            if sp is not None: sp=self.sp_bn(sp)

        sa=torch.hstack([s,a])

        x=self.fcs(sa)

        dist=self.gmm(x)
        self.train()
        return dist,(sp if sp is None else dist.log_prob(sp))

    def log_prob(self,s,a,sp): return self(s,a,sp,training=False)[1]

    def predict_state(self,s,a):
        "Returns the predicted state that `s` and `a` will result in."
        dist,_=self(s,a,training=False)
        if self.use_model_mean:
            means,idx=dist.component_distribution.mean,torch.argmax(dist.mixture_distribution.logits,dim=1)
            pred_s=means[[torch.arange(means.shape[0]),idx]]
        else:
            pred_s=dist.mean

        if self.use_batch_norm:
            pred_s=pred_s*(self.sp_bn.running_var+1e-3).sqrt()+self.sp_bn.running_mean

        pred_s+=s
        return pred_s

# Cell
def discrete_uniform(current_skill,latent_sz:int=2,alt_s:Tensor=None,deterministic:bool=False):
    "Returns a uniform discrete distribution."
    if deterministic:
        return torch.cat([torch.roll(current_skill,i,dims=1) for i in range(1,alt_s.shape[0])])
    return Multinomial(1,probs=Tensor([1./latent_sz]*latent_sz)).sample_n(alt_s.shape[0])

# Cell
def cont_gaussian(sz:int,alt_s:Tensor):
    "Returns a continuous guassian distribution of size `sz`"
    return MultivariateNormal(torch.zeros(sz),torch.eye(sz)).sample_n(alt_s.shape[0])

# Cell
def cont_uniform(sz,alt_s:Tensor,low=-1.0, high=1.0):
    return torch.zeros((alt_s.shape[0],sz)).uniform_(low,high)

# Cell
@delegates(SAC)
class DADS(SAC):
    def __init__(self,num_inputs,action_space,num_skills:int=20,include_actions:bool=False,hidden_size=100,lr=0.003,
                 n_components:int=4,prior_samples:int=100,latent_sz:int=2,latent_prior_method='',
                 skill_lr=3e-4,**kwargs):
        store_attr()
        self.num_inputs=num_inputs+self.num_skills
        self.original_num_inputs=num_inputs
        self.skill_dyn=SkillDynamics(self.original_num_inputs,self.num_skills,self.n_components)
        super().__init__(self.num_inputs,self.action_space,hidden_size=hidden_size,lr=lr,**kwargs)
        self.skill_opt=Adam(self.skill_dyn.parameters(),lr=3e-4)

    @torch.no_grad()
    def intrinsic_reward(self,s,skill:Tensor,sp,gpu_limit=20*4000):
        "Given a batch of `s` and `sp` what is the reward for using skill `z`?"
        n_repetitions=self.prior_samples if self.prior_samples>0 else self.num_skills-1
        alt_s=torch.cat([s]*n_repetitions,axis=0)
        alt_sp=torch.cat([sp]*n_repetitions,axis=0)

        if self.latent_prior_method=='discrete_uniform' and not self.prior_samples:
            alt_skill=discrete_uniform(skill,self.num_skills,alt_s,True)
        elif self.latent_prior_method=='discrete_uniform':
            alt_skill=discrete_uniform(skill,self.num_skills,alt_s,False)
        elif self.latent_prior_method=='cont_gaussian':
            alt_skill=cont_gaussian(self.num_skills,alt_s)
        else:
            alt_skill=cont_uniform(self.num_skills,alt_s)

        logp=self.skill_dyn.log_prob(s,skill,sp)

        if alt_s.shape[0]<=gpu_limit:
            logp_altz=self.skill_dyn.log_prob(alt_s,alt_skill,alt_sp)
        else:
            # Does this chunking code have to be so complex? Does fastcore have something
            logp_altz=[]
            for idx in range(alt_s.shape[0]//gpu_limit):
                start_idx=idx*gpu_limit
                end_idx=(idx+1)*gpu_limit
                logp_altz.append(
                    self.skill_dyn.log_prob(alt_s[start_idx:end_idx],
                                            alt_skill[start_idx:end_idx],
                                            alt_sp[start_idx:end_idx])
                )
            # TODO: JL: ok what is the scenario where this if statement is needed?
            if alt_s.shape[0]%gpu_limit:
                start_idx=alt_s.shape[0]%gpu_limit
                logp_altz.append(
                    self.skill_dyn.log_prob(alt_s[-start_idx:],
                                            alt_skill[-start_idx:],
                                            alt_sp[-start_idx:]))
            logp_altz=torch.cat(logp_altz)
        logp_altz=torch.stack(torch.chunk(logp_altz,n_repetitions))

        intrinsic_reward=np.log(n_repetitions+1)-torch.log(
            1+torch.exp(torch.clamp(logp_altz-logp.reshape(1,-1),-50,50)).sum(dim=0)
        )

        return intrinsic_reward,logp,logp_altz

    # TODO: They have batch weighting here. Maybe look into
    def increase_skill_opt(self,log_prob:Tensor):
        self.skill_opt.zero_grad()
        loss=-torch.mean(log_prob)
        loss.backward()
        self.skill_opt.step()
    def decrease_skill_opt(self,log_prob:Tensor):
        self.skill_opt.zero_grad()
        loss=torch.mean(log_prob)
        loss.backward()
        self.skill_opt.step()