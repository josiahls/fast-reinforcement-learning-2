# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/06_basic_train.ipynb (unless otherwise specified).

__all__ = ['FloatifyCallback', 'FakeRunCallback', 'LatentLossBuffer', 'AgentLearner']

# Cell
from fastai.basic_data import *
from fastai.basic_train import *
from fastai.torch_core import *
from fastai.layers import *
from .data_block import *
from .basic_agents import *
from dataclasses import asdict
import logging
import gym

# Cell
class FloatifyCallback(LearnerCallback):
    def on_batch_begin(self,last_input,**kwargs):
        return {'last_input':[o.float() for o in last_input]}

class FakeRunCallback(LearnerCallback):
    def on_backward_begin(self,*args,**kwargs): return {'skip_bwd':True,'skip_validate':True}


@dataclass
class LatentLossBuffer(object):
    "Most RL agents have complex / intensive loss functions that need to be handled by the trainers. This primarily serves as a compat layer with fastai."
    loss:float=0.5

    def __call__(self,xb,yb):return tensor(self.loss)

# Cell
@dataclass
class AgentLearner(Learner):
    data:DataBunch
    model:nn.Module
    agent:BaseAgent=BaseAgent()
    training:bool=False

    def __post_init__(self):
        self.callback_fns=listify(self.callback_fns)+listify(self.data.callback_fns)+listify(FloatifyCallback)
        if self.loss_func is None:self.loss_func=LatentLossBuffer()
        super(AgentLearner,self).__post_init__()
        self.data.learner=self

    def predict(self,s):
        return self.agent(s,None)