# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_data.ipynb (unless otherwise specified).

__all__ = ['EnvLists', 'EnvMakeTfm', 'EnvResetTfm', 'EnvGenUnwrapTfm', 'env_display', 'EnvStepTfm']

# Cell
from fastai.torch_basics import *
from fastai.data.all import *
from fastai.basics import *
from dataclasses import field,asdict
from typing import List,Any
from collections import deque
import gym

if IN_NOTEBOOK:
    from IPython import display
    import PIL.Image

# Cell
@delegates(TfmdLists.__init__)
class EnvLists(TfmdLists):
    def __init__(self,items,tfms,**kwargs):
        self.is_set=False
        super().__init__(items,tfms,**kwargs)

    def __len__(self):
        if (len(self.items)!=0 and not issubclass(type(self.items[0]),gym.Env)) or not self.is_set: return len(self.items)
        else:                                                                                       return self.items[0].spec.max_episode_steps

    def _get(self,i): return i if self.is_set else super()._get(i)

    def setup(self,train_setup=True):
        super().setup(train_setup)
        for f in self.fs:
            if hasattr(f,'reset'):f.reset()
        self.is_set=True

# Cell
class EnvMakeTfm(Transform):
    def setup(self,items=None,train_setup=False):
        for i,o in enumerate(items):items[i]=gym.make(o)
        return super().setup(items,train_setup)

# Cell
@dataclass
class DoneStateEnv:d:bool;s:np.array;env:object
DoneStateEnv.__repr__=lambda self:str((self.d,self.s,self.env))

@dataclass
class EnvResetTfm(Transform):
    env_idx:int=0;seed:Optional[int]=None;s:Optional[np.ndarray]=None;d:bool=False;was_setup:bool=False
    callback:DoneStateEnv=field(default_factory=lambda:DoneStateEnv(True,None,None))
    items:List[gym.Env]=field(default_factory=list)

    def setup(self,items=None,train_setup=False):
        for o in items:self.items.append(o)
        self._env_idx=len(items)
        return self

    def reset(self):
        self._env_idx=0
        if self.seed is not None:[o.seed(self.seed) for o in self.items]
        self.s=[_o.reset() for _o in self.items]
        self.d=[False for _ in self.items]
        self.callback=DoneStateEnv(d=self.d[self._env_idx],s=self.s[self._env_idx],env=self.items[self._env_idx])

    def encodes(self,o):
        if self.callback.d:
#             print('was done lol')
            self._env_idx+=1
            if self._env_idx>=len(self.items):self.reset()
            self.callback=DoneStateEnv(d=self.d[self._env_idx],s=self.s[self._env_idx],env=self.items[self._env_idx])
#             print(self.callback.s)
        return self.callback

# Cell
@dataclass
class EnvGenUnwrapTfm(Transform):
    step:int=0

    def encodes(self,o:Generator):
        result= tuple([xx for x in o for xx in x])
        self.step+=1
        return result

# Cell
def env_display(env:gym.Env):
    img=env.render('rgb_array')
    try:display.clear_output(wait=True)
    except AttributeError:pass
    new_im=PIL.Image.fromarray(img)
    display.display(new_im)

# Cell
@dataclass
class Experience:d:bool;s:np.ndarray;sp:np.ndarray;r:float;a:Any

@dataclass
class EnvStepTfm(Transform):
    agent:Optional[object]=None;constant_action:Optional[int]=None;n_steps:int=1;steps_delta:int=1;step:int=-1
    _reset_step:bool=False;history:deque=None;display:bool=False;enc_set:bool=False

    def __post_init__(self):     self.history=deque(maxlen=self.n_steps)
    def bump_step_count(self,d): self.step=0 if d else self.step+1
    def reset(self):             self.step=0; self.history.clear()

    def encodes(self,o:DoneStateEnv):
        while True:
            if self.agent is None: a=ifnone(self.constant_action,o.env.action_space.sample())
            else:                  a=self.agent(o.s)

            sp,r,o.d,_=o.env.step(a)
            if self.display:env_display(o.env)
            self.history.append(Experience(d=o.d,s=o.s.copy(),sp=sp.copy(),r=r,a=a))
            o.s=sp.copy()
            self.bump_step_count(o.d)
            if o.d:
                while len(self.history)>1: # We allow the a single element left to be yielded by the broken while
                    yield tuple(self.history)
                    self.history.popleft()
                break
#             print(len(self.history),((self.step-1)%self.steps_delta),self.step)
            if len(self.history)==self.n_steps and ((self.step-1)%self.steps_delta)==0 and not o.d or \
                 (len(self.history)==self.step and len(self.history)==self.n_steps and not o.d):break

        history=tuple(copy(self.history))
        if o.d:self.history.clear();self.reset()
        yield tuple(history)
        return None