---

title: DQN


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/20a_qlearning.dqn.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/20a_qlearning.dqn.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LinearDQN" class="doc_header"><code>class</code> <code>LinearDQN</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn.py#L30" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LinearDQN</code>(<strong><code>input_shape</code></strong>, <strong><code>n_actions</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ExperienceReplay" class="doc_header"><code>class</code> <code>ExperienceReplay</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn.py#L44" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ExperienceReplay</code>(<strong><code>sz</code></strong>=<em><code>100</code></em>, <strong><code>bs</code></strong>=<em><code>128</code></em>, <strong><code>starting_els</code></strong>=<em><code>1</code></em>, <strong><code>max_steps</code></strong>=<em><code>1</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>Basic class handling tweaks of the training loop by changing a <code>Learner</code> in various events</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EpsilonTracker" class="doc_header"><code>class</code> <code>EpsilonTracker</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn.py#L76" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EpsilonTracker</code>(<strong><code>e_stop</code></strong>=<em><code>0.2</code></em>, <strong><code>e_start</code></strong>=<em><code>1.0</code></em>, <strong><code>e_steps</code></strong>=<em><code>5000</code></em>, <strong><code>current_step</code></strong>=<em><code>0</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>Basic class handling tweaks of the training loop by changing a <code>Learner</code> in various events</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="calc_target" class="doc_header"><code>calc_target</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn.py#L88" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>calc_target</code>(<strong><code>net</code></strong>, <strong><code>local_reward</code></strong>, <strong><code>next_state</code></strong>, <strong><code>done</code></strong>, <strong><code>discount</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DQNTrainer" class="doc_header"><code>class</code> <code>DQNTrainer</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn.py#L94" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DQNTrainer</code>(<strong><code>after_create</code></strong>=<em><code>None</code></em>, <strong><code>before_fit</code></strong>=<em><code>None</code></em>, <strong><code>before_epoch</code></strong>=<em><code>None</code></em>, <strong><code>before_train</code></strong>=<em><code>None</code></em>, <strong><code>before_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_pred</code></strong>=<em><code>None</code></em>, <strong><code>after_loss</code></strong>=<em><code>None</code></em>, <strong><code>before_backward</code></strong>=<em><code>None</code></em>, <strong><code>after_backward</code></strong>=<em><code>None</code></em>, <strong><code>after_step</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_train</code></strong>=<em><code>None</code></em>, <strong><code>after_train</code></strong>=<em><code>None</code></em>, <strong><code>before_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_fit</code></strong>=<em><code>None</code></em>, <strong><code>after_fit</code></strong>=<em><code>None</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>Basic class handling tweaks of the training loop by changing a <code>Learner</code> in various events</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DQNLearner" class="doc_header"><code>class</code> <code>DQNLearner</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn.py#L116" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DQNLearner</code>(<strong><code>dls</code></strong>, <strong><code>agent</code></strong>:<a href="/fast-reinforcement-learning-2/basic_agents.html#BaseAgent"><code>BaseAgent</code></a>=<em><code>BaseAgent(model=None)</code></em>, <strong><code>model</code></strong>=<em><code>None</code></em>, <strong><code>use_train_mets</code></strong>=<em><code>True</code></em>, <strong><code>loss_func</code></strong>=<em><code>None</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>lr</code></strong>=<em><code>0.001</code></em>, <strong><code>splitter</code></strong>=<em><code>trainable_params</code></em>, <strong><code>cbs</code></strong>=<em><code>None</code></em>, <strong><code>metrics</code></strong>=<em><code>None</code></em>, <strong><code>path</code></strong>=<em><code>None</code></em>, <strong><code>model_dir</code></strong>=<em><code>'models'</code></em>, <strong><code>wd</code></strong>=<em><code>None</code></em>, <strong><code>wd_bn_bias</code></strong>=<em><code>False</code></em>, <strong><code>train_bn</code></strong>=<em><code>True</code></em>, <strong><code>moms</code></strong>=<em><code>(0.95, 0.85, 0.95)</code></em>) :: <a href="/fast-reinforcement-learning-2/learner.html#AgentLearner"><code>AgentLearner</code></a></p>
</blockquote>
<p>Base Learner for all reinforcement learning agents</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span><span class="o">=</span><span class="s1">&#39;CartPole-v1&#39;</span>
<span class="n">model</span><span class="o">=</span><span class="n">LinearDQN</span><span class="p">((</span><span class="mi">4</span><span class="p">,),</span><span class="mi">2</span><span class="p">)</span>
<span class="n">agent</span><span class="o">=</span><span class="n">DiscreteAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">default_device</span><span class="p">()),</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">(),</span>
                    <span class="n">a_selector</span><span class="o">=</span><span class="n">EpsilonGreedyActionSelector</span><span class="p">())</span>

<span class="n">block</span><span class="o">=</span><span class="n">FirstLastExperienceBlock</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">dls_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;bs&#39;</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;indexed&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;shuffle_train&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">})</span>
<span class="n">blk</span><span class="o">=</span><span class="n">IterableDataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">block</span><span class="p">),</span>
                      <span class="n">splitter</span><span class="o">=</span><span class="n">FuncSplitter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="kc">False</span><span class="p">),</span>
<span class="c1">#                       batch_tfms=lambda x:(x[&#39;s&#39;],x),</span>
                     <span class="p">)</span>
<span class="n">dls</span><span class="o">=</span><span class="n">blk</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">([</span><span class="n">env</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">8</span><span class="o">*</span><span class="mi">1000</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">())</span>

<span class="n">learner</span><span class="o">=</span><span class="n">DQNLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">EpsilonTracker</span><span class="p">,</span>
                                        <span class="n">ExperienceReplay</span><span class="p">(</span><span class="n">sz</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">starting_els</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">_max_episode_steps</span><span class="p">),</span>
                                        <span class="n">DQNTrainer</span><span class="p">],</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">AvgEpisodeRewardMetric</span><span class="p">(</span><span class="n">experience_cls</span><span class="o">=</span><span class="n">ExperienceFirstLast</span><span class="p">)])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span><span class="n">wd</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_avg_episode_r</th>
      <th>valid_loss</th>
      <th>valid_avg_episode_r</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>24.613981</td>
      <td>29.540000</td>
      <td>None</td>
      <td>29.540000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>1</td>
      <td>32.930523</td>
      <td>51.570000</td>
      <td>None</td>
      <td>51.570000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>2</td>
      <td>21.004852</td>
      <td>82.090000</td>
      <td>None</td>
      <td>82.090000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.406000</td>
      <td>121.940000</td>
      <td>None</td>
      <td>121.940000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>4</td>
      <td>8.700549</td>
      <td>157.430000</td>
      <td>None</td>
      <td>157.430000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>5</td>
      <td>25.562292</td>
      <td>185.620000</td>
      <td>None</td>
      <td>185.620000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>6</td>
      <td>72.588402</td>
      <td>192.840000</td>
      <td>None</td>
      <td>192.840000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>7</td>
      <td>4.033764</td>
      <td>207.890000</td>
      <td>None</td>
      <td>207.890000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>8</td>
      <td>39.098164</td>
      <td>186.120000</td>
      <td>None</td>
      <td>186.120000</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>9</td>
      <td>18.933603</td>
      <td>222.090000</td>
      <td>None</td>
      <td>222.090000</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>10</td>
      <td>16.825060</td>
      <td>218.860000</td>
      <td>None</td>
      <td>218.860000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>11</td>
      <td>37.401455</td>
      <td>240.070000</td>
      <td>None</td>
      <td>240.070000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>12</td>
      <td>47.032150</td>
      <td>256.590000</td>
      <td>None</td>
      <td>256.590000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>13</td>
      <td>40.052586</td>
      <td>288.350000</td>
      <td>None</td>
      <td>288.350000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>14</td>
      <td>45.070744</td>
      <td>323.100000</td>
      <td>None</td>
      <td>323.100000</td>
      <td>00:13</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

