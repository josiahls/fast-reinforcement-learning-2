---

title: Basic Action Selection

keywords: fastai
sidebar: home_sidebar

summary: "Methods of exploratively selecting actions based on a model state input."
description: "Methods of exploratively selecting actions based on a model state input."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/03_basic_agents.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#34;Note these are modified versions of &#39;Shmuma/Ptan&#39;. Github, 2020, https://github.com/Shmuma/ptan/blob/master/ptan/agent.py. Accessed 13 June 2020.&#34;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ActionSelector" class="doc_header"><code>class</code> <code>ActionSelector</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L24" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ActionSelector</code>()</p>
</blockquote>
<p>Abstract class which converts scores to the actions.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ArgmaxActionSelector" class="doc_header"><code>class</code> <code>ArgmaxActionSelector</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L28" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ArgmaxActionSelector</code>() :: <a href="/fastrl/basic_agents#ActionSelector"><code>ActionSelector</code></a></p>
</blockquote>
<p>Selects actions using argmax.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EpsilonGreedyActionSelector" class="doc_header"><code>class</code> <code>EpsilonGreedyActionSelector</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L35" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EpsilonGreedyActionSelector</code>(<strong><code>epsilon</code></strong>:<code>float</code>=<em><code>0.05</code></em>, <strong><code>selector</code></strong>:<a href="/fastrl/basic_agents#ActionSelector"><code>ActionSelector</code></a>=<em><code>&lt;fastrl.basic_agents.ArgmaxActionSelector object at 0x7f912950b050&gt;</code></em>) :: <a href="/fastrl/basic_agents#ActionSelector"><code>ActionSelector</code></a></p>
</blockquote>
<p>EpsilonGreedyActionSelector(epsilon: float = 0.05, selector: fastrl.basic_agents.ActionSelector = &lt;fastrl.basic_agents.ArgmaxActionSelector object at 0x7f912950b050&gt;)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ProbabilityActionSelector" class="doc_header"><code>class</code> <code>ProbabilityActionSelector</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L48" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ProbabilityActionSelector</code>() :: <a href="/fastrl/basic_agents#ActionSelector"><code>ActionSelector</code></a></p>
</blockquote>
<p>Converts probabilities of actions into action by sampling them.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Basic-Agents">Basic Agents<a class="anchor-link" href="#Basic-Agents"> </a></h1><blockquote><p>Basic Agent classes for handling models and actions. Details, please ref <a href="/fastrl/basic_train"><code>basic_train</code></a></p>
</blockquote>
<p>There is an important difference between <code>Learner</code>'s, <code>nn.Module</code>'s, and <code>Agent</code>'s.</p>
<p><code>Learners</code>:- Ref <a href="/fastrl/basic_train"><code>basic_train</code></a>
<code>nn.Module</code>:</p>
<ul>
<li>Contain only <code>pytorch</code> related code.</li>
<li>Function as the brain of any of these agents and are the objects to be optimized.</li>
<li>Are highly portable, however for runtime usage are too "dumb" or simple to be practical. If by themselves, extra code needs to wrap them to handle environments.</li>
</ul>
<p><code>Agent</code> (<code>agent_core</code>):</p>
<ul>
<li>Contain a <code>nn.Module</code> and a limited number of <code>fastrl</code> objects. Unlike <code>nn.Module</code>, these can maintain a state.</li>
<li>Function as the interface between the <code>nn.Module</code> and the environments. They have 2 goals:<ul>
<li>Convert states into something the <code>nn.Module</code> can interpret.</li>
<li>Modify the <code>nn.Module</code> output (actions) for randomized exploration.</li>
</ul>
</li>
<li>Designed to be highly portable only requiring <a href="/fastrl/basic_agents"><code>basic_agents</code></a> as a dependency. These should allow for easily saving, and using in environments where <code>fastrl</code> might not necessarily be installed.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="default_states_preprocessor" class="doc_header"><code>default_states_preprocessor</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L56" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>default_states_preprocessor</code>(<strong><code>s</code></strong>, <strong><code>dtype</code></strong>=<em><code>'float32'</code></em>)</p>
</blockquote>
<p>Convert list of states into the form suitable for model. By default we assume Variable.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="float32_preprocessor" class="doc_header"><code>float32_preprocessor</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L61" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>float32_preprocessor</code>(<strong><code>s</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BaseAgent" class="doc_header"><code>class</code> <code>BaseAgent</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L67" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BaseAgent</code>(<strong><code>model</code></strong>:<code>Module</code>=<em><code>None</code></em>)</p>
</blockquote>
<p>BaseAgent(model: torch.nn.modules.module.Module = None)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TestAgent" class="doc_header"><code>class</code> <code>TestAgent</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L78" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TestAgent</code>(<strong><code>model</code></strong>:<code>Module</code>=<em><code>None</code></em>, <strong><code>env</code></strong>:<code>object</code>=<em><code>None</code></em>) :: <a href="/fastrl/basic_agents#BaseAgent"><code>BaseAgent</code></a></p>
</blockquote>
<p>TestAgent(model: torch.nn.modules.module.Module = None, env: object = None)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">add_docs</span><span class="p">(</span><span class="n">BaseAgent</span><span class="o">.</span><span class="n">initial_state</span><span class="p">,</span><span class="s2">&quot;Should create initial empty state for the agent. It will be called for the start of the episode.&quot;</span><span class="p">)</span>
<span class="n">add_docs</span><span class="p">(</span><span class="n">BaseAgent</span><span class="o">.</span><span class="fm">__call__</span><span class="p">,</span><span class="n">textwrap</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;Convert observations and state list `sl` into actions to take. Agent state list `asl` may also be used by the agent.</span>
<span class="s2">         It is expected that `asl` is likely either going to be an internal state tracked by the agent, or it is simply a parameter used during subclassing.</span>
<span class="s2">         The `include_batch_dim` should toggle whether to remove/include the batch dim of an action. Naturally, `gym` envs don&#39;t understand batch dimensions.&quot;&quot;&quot;</span>
        <span class="p">))</span>
<span class="n">add_docs</span><span class="p">(</span><span class="n">BaseAgent</span><span class="p">,</span><span class="s2">&quot;Abstract Agent interface&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">IN_NOTEBOOK</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
    <span class="kn">import</span> <span class="nn">PIL.Image</span>

<span class="n">env</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">)</span>
<span class="n">agent</span><span class="o">=</span><span class="n">TestAgent</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>

<span class="n">done</span><span class="p">,</span><span class="n">episode_count</span><span class="p">,</span><span class="n">max_episodes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">done</span><span class="p">:</span><span class="n">s</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">s</span><span class="p">,</span><span class="n">done</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">agent</span><span class="p">(</span><span class="n">s</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">im</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rgb_array&#39;</span><span class="p">)</span>
    <span class="n">new_im</span><span class="o">=</span><span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">new_im</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">done</span> <span class="ow">and</span> <span class="n">episode_count</span><span class="o">&gt;</span><span class="n">max_episodes</span><span class="p">:</span><span class="k">break</span>
    <span class="k">if</span> <span class="n">done</span><span class="p">:</span><span class="n">episode_count</span><span class="o">+=</span><span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DiscreteAgent" class="doc_header"><code>class</code> <code>DiscreteAgent</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L87" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DiscreteAgent</code>(<strong><code>model</code></strong>:<code>Module</code>=<em><code>None</code></em>, <strong><code>a_selector</code></strong>:<a href="/fastrl/basic_agents#ActionSelector"><code>ActionSelector</code></a>=<em><code>None</code></em>, <strong><code>device</code></strong>:<code>str</code>=<em><code>None</code></em>, <strong><code>preprocessor</code></strong>:<code>Callable</code>=<em><code>'default_states_preprocessor'</code></em>, <strong><code>apply_softmax</code></strong>:<code>bool</code>=<em><code>False</code></em>) :: <a href="/fastrl/basic_agents#BaseAgent"><code>BaseAgent</code></a></p>
</blockquote>
<p>DQNAgent is a memoryless DQN agent which calculates Q values from the observations and  converts them into the actions using a_selector.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DQNAgent" class="doc_header"><code>class</code> <code>DQNAgent</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/basic_agents.py#L112" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DQNAgent</code>(<strong><code>model</code></strong>:<code>Module</code>=<em><code>None</code></em>, <strong><code>a_selector</code></strong>:<a href="/fastrl/basic_agents#ActionSelector"><code>ActionSelector</code></a>=<em><code>None</code></em>, <strong><code>device</code></strong>:<code>str</code>=<em><code>None</code></em>, <strong><code>preprocessor</code></strong>:<code>Callable</code>=<em><code>'default_states_preprocessor'</code></em>, <strong><code>apply_softmax</code></strong>:<code>bool</code>=<em><code>False</code></em>) :: <a href="/fastrl/basic_agents#DiscreteAgent"><code>DiscreteAgent</code></a></p>
</blockquote>
<p>DQNAgent is a memoryless DQN agent which calculates Q values from the observations and  converts them into the actions using a_selector.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">add_docs</span><span class="p">(</span><span class="n">DQNAgent</span><span class="p">,</span><span class="fm">__call__</span><span class="o">=</span><span class="s1">&#39;DQNAgents will likely never have `asl` passed and used. This is however here for novel DQN implimentations.&#39;</span><span class="p">,</span>
         <span class="n">safe_unbatch</span><span class="o">=</span><span class="s1">&#39;Will remove the batch dim from `o` if `o` represents a single item.&#39;</span><span class="p">,</span>
         <span class="n">split_v</span><span class="o">=</span><span class="s1">&#39;In the event that `v` is a tuple, then there is multle ouputs from the `model`. Primarly used for A2C.&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">)</span>
<span class="n">agent</span><span class="o">=</span><span class="n">DQNAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>

<span class="n">done</span><span class="p">,</span><span class="n">episode_count</span><span class="p">,</span><span class="n">max_episodes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">done</span><span class="p">:</span><span class="n">s</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">s</span><span class="p">,</span><span class="n">done</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">agent</span><span class="p">(</span><span class="n">s</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">im</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rgb_array&#39;</span><span class="p">)</span>
    <span class="n">new_im</span><span class="o">=</span><span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">new_im</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">done</span> <span class="ow">and</span> <span class="n">episode_count</span><span class="o">&gt;</span><span class="n">max_episodes</span><span class="p">:</span><span class="k">break</span>
    <span class="k">if</span> <span class="n">done</span><span class="p">:</span><span class="n">episode_count</span><span class="o">+=</span><span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAlgAAAGQCAIAAAD9V4nPAAAGmElEQVR4nO3d22njUBRA0fGQJlKHU8bUIdck15Ey4jqmDOUjkIQ8TECJrsJe68tIYM6P2NyDsA/LsvwBgKq/owcAgJGEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQg7Wb0AFB3OZ+ePx+neeAk0CSEsCOvo/hEGuGnWY0CkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQggjXc6nK3eP07zZJJAlhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhDDM5Xy6cvc4zZtNAmVCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoSwymGFUd8MvCaEAKQJIQBpN6MHgLr7/9ObK/9uz0MmgSYnQhjpfQU/uwj8ECGEYQQP9kAIAUgTQtgjh0XYjBDCHnlfBjYjhACkCSGM8TBPV459dycnQtiIEMJIH7bQXhS2dFiWZfQM8It94w97PswvL8isPBF6ruHrhBBW2ecvXHuu4eusRgEAAKqsRmEVq1H47axGAUgTQgDShBCANCEEIE0IAUgTQgDShBCANCEEIE0IAUgTQgDShBCANCEEIE0IAUjz7xMApDkRApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQNojhtY8iW9+cLYAAAAASUVORK5CYII=
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TargetNet</span><span class="p">:</span>
    <span class="s2">&quot;Wrapper around model which provides copy of it instead of trained weights.&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sync</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span><span class="bp">self</span><span class="o">.</span><span class="n">target_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="k">def</span> <span class="nf">alpha_sync</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">alpha</span><span class="p">):</span>
        <span class="s2">&quot;Blend params of target net with params from the model.&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">assert</span> <span class="mf">0.0</span><span class="o">&lt;</span><span class="n">alpha</span><span class="o">&lt;=</span><span class="mf">1.0</span>
        <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="n">tgt_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">tgt_state</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">tgt_state</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="n">alpha</span><span class="o">+</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="o">*</span><span class="n">v</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">tgt_state</span><span class="p">)</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">PolicyAgent</span><span class="p">(</span><span class="n">DiscreteAgent</span><span class="p">):</span>
    <span class="s2">&quot;Policy agent gets action probabilities from the model and samples actions from it.&quot;</span>
    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a_selector</span><span class="o">=</span><span class="n">ifnone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a_selector</span><span class="p">,</span><span class="n">ProbabilityActionSelector</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_softmax</span><span class="o">=</span><span class="kc">True</span>

<span class="k">class</span> <span class="nc">ActorCriticAgent</span><span class="p">(</span><span class="n">PolicyAgent</span><span class="p">):</span>
    <span class="s2">&quot;Policy agent which returns policy and value tensors from observations. Value are stored in agent&#39;s state </span><span class="se">\</span>
<span class="s2">     and could be reused for rollouts calculations by ExperienceSource.&quot;</span>
    <span class="k">def</span> <span class="nf">split_v</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">asl</span><span class="p">):</span><span class="k">return</span> <span class="n">v</span><span class="p">,</span><span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

