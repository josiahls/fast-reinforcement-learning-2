---

title: A3C Data

keywords: fastai
sidebar: home_sidebar

summary: "A decoupled actor critic agent which trains on data collected from environments running in a completely separate process."
description: "A decoupled actor critic agent which trains on data collected from environments running in a completely separate process."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/12_a3c.a3c_data.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="a3c_data_fitter" class="doc_header"><code>a3c_data_fitter</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/a3c/a3c_data.py#L33" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>a3c_data_fitter</code>(<strong><code>model</code></strong>, <strong><code>agent</code></strong>, <strong><code>ds</code></strong>, <strong><code>data_queue</code></strong>, <strong><code>pause_event</code></strong>, <strong><code>cancel_event</code></strong>, <strong><code>metric_queue</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="A3CLearner" class="doc_header"><code>class</code> <code>A3CLearner</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/a3c/a3c_data.py#L51" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>A3CLearner</code>(<strong><code>data</code></strong>:<code>DataBunch</code>, <strong><code>model</code></strong>:<code>Module</code>, <strong><code>opt_func</code></strong>:<code>Callable</code>=<em><code>'Adam'</code></em>, <strong><code>loss_func</code></strong>:<code>Callable</code>=<em><code>None</code></em>, <strong><code>metrics</code></strong>:<code>Collection</code>[<code>Callable</code>]=<em><code>None</code></em>, <strong><code>true_wd</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>bn_wd</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>wd</code></strong>:<code>Union</code>[<code>float</code>, <code>Collection</code>[<code>float</code>]]=<em><code>0.01</code></em>, <strong><code>train_bn</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>path</code></strong>:<code>str</code>=<em><code>None</code></em>, <strong><code>model_dir</code></strong>:<code>Union</code>[<code>Path</code>, <code>str</code>]=<em><code>'models'</code></em>, <strong><code>callback_fns</code></strong>:<code>Collection</code>[<code>Callable</code>]=<em><code>None</code></em>, <strong><code>callbacks</code></strong>:<code>Collection</code>[<code>Callback</code>]=<em><code>&lt;factory&gt;</code></em>, <strong><code>layer_groups</code></strong>:<code>Collection</code>[<code>Module</code>]=<em><code>None</code></em>, <strong><code>add_time</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>silent</code></strong>:<code>bool</code>=<em><code>None</code></em>, <strong><code>agent</code></strong>:<a href="/fastrl/basic_agents#BaseAgent"><code>BaseAgent</code></a>=<em><code>BaseAgent(model=None)</code></em>, <strong><code>training</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>fitter</code></strong>:<code>Callable</code>=<em><code>'a3c_data_fitter'</code></em>, <strong><code>batch_sz</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>discount</code></strong>:<code>float</code>=<em><code>0.99</code></em>, <strong><code>entropy_beta</code></strong>:<code>float</code>=<em><code>0.01</code></em>, <strong><code>clip_grad</code></strong>:<code>float</code>=<em><code>0.1</code></em>) :: <a href="/fastrl/basic_train#AgentLearner"><code>AgentLearner</code></a></p>
</blockquote>
<p>A3CLearner(data: fastai.basic_data.DataBunch, model: torch.nn.modules.module.Module, opt_func: Callable = functools.partial(&lt;class 'torch.optim.adam.Adam'&gt;, betas=(0.9, 0.99)), loss_func: Callable = None, metrics: Collection[Callable] = None, true_wd: bool = True, bn_wd: bool = True, wd: Union[float, Collection[float]] = 0.01, train_bn: bool = True, path: str = None, model_dir: Union[pathlib.Path, str] = 'models', callback_fns: Collection[Callable] = None, callbacks: Collection[fastai.callback.Callback] = <factory>, layer_groups: Collection[torch.nn.modules.module.Module] = None, add_time: bool = True, silent: bool = None, agent: fastrl.basic_agents.BaseAgent = BaseAgent(model=None), training: bool = False, fitter: Callable = &lt;function a3c_data_fitter at 0x7f7075e58710&gt;, batch_sz: int = 128, discount: float = 0.99, entropy_beta: float = 0.01, clip_grad: float = 0.1)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch</span><span class="o">=</span><span class="p">[</span>
 <span class="n">Experience</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0285</span><span class="p">,</span>  <span class="mf">0.1640</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0033</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3421</span><span class="p">]]),</span><span class="n">sp</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0285</span><span class="p">,</span>  <span class="mf">0.1640</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0033</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3421</span><span class="p">]]),</span>
            <span class="n">a</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span><span class="n">r</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]),</span><span class="n">d</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">]),</span><span class="n">agent_s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">]]])),</span>
 <span class="n">Experience</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0252</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0311</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0101</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0504</span><span class="p">]]),</span><span class="n">sp</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0252</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0311</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0101</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0504</span><span class="p">]]),</span>
            <span class="n">a</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span><span class="n">r</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]),</span><span class="n">d</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">]),</span><span class="n">agent_s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">]]])),</span>
 <span class="n">Experience</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0258</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2261</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0111</span><span class="p">,</span>  <span class="mf">0.2391</span><span class="p">]]),</span><span class="n">sp</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0258</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2261</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0111</span><span class="p">,</span>  <span class="mf">0.2391</span><span class="p">]]),</span>
            <span class="n">a</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span><span class="n">r</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]),</span><span class="n">d</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">]),</span><span class="n">agent_s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">]]])),</span>
 <span class="n">Experience</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0517</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2260</span><span class="p">,</span>  <span class="mf">0.0195</span><span class="p">,</span>  <span class="mf">0.2377</span><span class="p">]]),</span><span class="n">sp</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0517</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2260</span><span class="p">,</span>  <span class="mf">0.0195</span><span class="p">,</span>  <span class="mf">0.2377</span><span class="p">]]),</span>
            <span class="n">a</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span><span class="n">r</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]),</span><span class="n">d</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">]),</span><span class="n">agent_s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">]]])),</span>
 <span class="n">Experience</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0562</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4214</span><span class="p">,</span>  <span class="mf">0.0242</span><span class="p">,</span>  <span class="mf">0.5365</span><span class="p">]]),</span><span class="n">sp</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0562</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4214</span><span class="p">,</span>  <span class="mf">0.0242</span><span class="p">,</span>  <span class="mf">0.5365</span><span class="p">]]),</span>
            <span class="n">a</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span><span class="n">r</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]),</span><span class="n">d</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">]),</span><span class="n">agent_s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">]]])),</span>
 <span class="n">Experience</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0647</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6169</span><span class="p">,</span>  <span class="mf">0.0349</span><span class="p">,</span>  <span class="mf">0.8367</span><span class="p">]]),</span><span class="n">sp</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0647</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6169</span><span class="p">,</span>  <span class="mf">0.0349</span><span class="p">,</span>  <span class="mf">0.8367</span><span class="p">]]),</span>
            <span class="n">a</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span><span class="n">r</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]),</span><span class="n">d</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]),</span><span class="n">agent_s</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">]]]))</span>
<span class="p">]</span>
<span class="k">class</span> <span class="nc">LinearA2C</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearA2C</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_conv_out</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
        <span class="n">o</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">fx</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">fx</span><span class="p">),</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">fx</span><span class="p">)</span>
<span class="n">model</span><span class="o">=</span><span class="n">LinearA2C</span><span class="p">((</span><span class="mi">4</span><span class="p">,),</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">getBack</span><span class="p">(</span><span class="n">var_grad_fn</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">var_grad_fn</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">var_grad_fn</span><span class="o">.</span><span class="n">next_functions</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;variable&#39;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Tensor with grad found:&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; - gradient:&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">getBack</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">r_estimate</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">d_mask</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">val_gamma</span><span class="p">,</span><span class="n">device</span><span class="p">):</span>
    <span class="s2">&quot;Returns rewards `r` estimated direction by `model` from states `s`&quot;</span>
    <span class="n">r_np</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1">#     print(r_np.mean())</span>
    <span class="k">if</span> <span class="n">d_mask</span><span class="p">:</span>
        <span class="n">s_v</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">v</span><span class="o">=</span><span class="n">model</span><span class="p">(</span><span class="n">s_v</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># Remember that models are going to return the actions and the values</span>
        <span class="n">v_np</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[:,</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">r_np</span><span class="p">[</span><span class="n">d_mask</span><span class="p">]</span><span class="o">+=</span><span class="n">val_gamma</span><span class="o">*</span><span class="n">v_np</span>
        
<span class="c1">#     print(r_np.mean())</span>
    <span class="k">return</span> <span class="n">r_np</span>

<span class="k">def</span> <span class="nf">unbatch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">last_val_gamma</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">Tuple</span><span class="p">(</span><span class="n">List</span><span class="p">,</span><span class="n">List</span><span class="p">,</span><span class="n">List</span><span class="p">):</span>
    <span class="n">s</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">d_mask</span><span class="p">,</span><span class="n">sp</span><span class="o">=</span><span class="p">[],[],[],[],[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">exp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
        <span class="n">s</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">exp</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">exp</span><span class="p">)</span>
        <span class="n">a</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">exp</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span> <span class="c1"># TODO can we change this to toggle between discrete and continuous actions?</span>
        <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">exp</span><span class="o">.</span><span class="n">r</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">exp</span><span class="o">.</span><span class="n">d</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">d_mask</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">sp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">exp</span><span class="o">.</span><span class="n">sp</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">s_t</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">a_t</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">r_np</span><span class="o">=</span><span class="n">r_estimate</span><span class="p">(</span><span class="n">sp</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">d_mask</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">last_val_gamma</span><span class="p">,</span><span class="n">device</span><span class="p">)</span>
<span class="c1">#     print(str(r),&#39;\n\n&#39;,str(r_np))</span>
    <span class="n">estimated_r</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">r_np</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s_t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="n">a_t</span><span class="p">,</span><span class="n">estimated_r</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">unbatch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Experience(s=tensor([[-0.0285,  0.1640, -0.0033, -0.3421]]), sp=tensor([[-0.0285,  0.1640, -0.0033, -0.3421]]), a=tensor([1]), r=tensor([1.]), d=tensor([0.]), agent_s=tensor([[[0.]]]))
Experience(s=tensor([[-0.0252, -0.0311, -0.0101, -0.0504]]), sp=tensor([[-0.0252, -0.0311, -0.0101, -0.0504]]), a=tensor([0]), r=tensor([1.]), d=tensor([0.]), agent_s=tensor([[[0.]]]))
Experience(s=tensor([[-0.0258, -0.2261, -0.0111,  0.2391]]), sp=tensor([[-0.0258, -0.2261, -0.0111,  0.2391]]), a=tensor([0]), r=tensor([1.]), d=tensor([0.]), agent_s=tensor([[[0.]]]))
Experience(s=tensor([[-0.0517, -0.2260,  0.0195,  0.2377]]), sp=tensor([[-0.0517, -0.2260,  0.0195,  0.2377]]), a=tensor([1]), r=tensor([1.]), d=tensor([0.]), agent_s=tensor([[[0.]]]))
Experience(s=tensor([[-0.0562, -0.4214,  0.0242,  0.5365]]), sp=tensor([[-0.0562, -0.4214,  0.0242,  0.5365]]), a=tensor([0]), r=tensor([1.]), d=tensor([0.]), agent_s=tensor([[[0.]]]))
Experience(s=tensor([[-0.0647, -0.6169,  0.0349,  0.8367]]), sp=tensor([[-0.0647, -0.6169,  0.0349,  0.8367]]), a=tensor([0]), r=tensor([1.]), d=tensor([1.]), agent_s=tensor([[[0.]]]))
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([[-0.0285,  0.1640, -0.0033, -0.3421],
         [-0.0252, -0.0311, -0.0101, -0.0504],
         [-0.0258, -0.2261, -0.0111,  0.2391],
         [-0.0517, -0.2260,  0.0195,  0.2377],
         [-0.0562, -0.4214,  0.0242,  0.5365],
         [-0.0647, -0.6169,  0.0349,  0.8367]]),
 tensor([1, 0, 0, 1, 0, 0]),
 tensor([0.9193, 0.8519, 0.8118, 0.8016, 0.7556, 1.0000]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="A3CTrainer" class="doc_header"><code>class</code> <code>A3CTrainer</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/a3c/a3c_data.py#L71" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>A3CTrainer</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <code>LearnerCallback</code></p>
</blockquote>
<p>Base class for creating callbacks for a <code>Learner</code>.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">)</span>

<span class="n">data</span><span class="o">=</span><span class="n">AsyncExperienceSourceDataBunch</span><span class="o">.</span><span class="n">from_env</span><span class="p">(</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">,</span><span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">firstlast</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">add_valid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">skip_n_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">n_processes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_envs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">=</span><span class="n">LinearA2C</span><span class="p">((</span><span class="mi">4</span><span class="p">,),</span><span class="mi">2</span><span class="p">)</span>
<span class="n">agent</span><span class="o">=</span><span class="n">PolicyAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
<span class="n">learn</span><span class="o">=</span><span class="n">A3CLearner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">callback_fns</span><span class="o">=</span><span class="p">[</span><span class="n">A3CTrainer</span><span class="p">,</span><span class="n">RewardMetric</span><span class="p">])</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span><span class="n">wd</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-6-774584aa5dbd&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> 
<span class="ansi-green-intense-fg ansi-bold">      5</span> data<span class="ansi-blue-fg">=</span>AsyncExperienceSourceDataBunch<span class="ansi-blue-fg">.</span>from_env<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;CartPole-v1&#39;</span><span class="ansi-blue-fg">,</span>display<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>firstlast<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span>add_valid<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>skip_n_steps<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">4</span><span class="ansi-blue-fg">,</span>n_processes<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span>n_envs<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span>bs<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 6</span><span class="ansi-red-fg"> </span>model<span class="ansi-blue-fg">=</span>LinearA2C<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">4</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> agent<span class="ansi-blue-fg">=</span>PolicyAgent<span class="ansi-blue-fg">(</span>model<span class="ansi-blue-fg">=</span>model<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      8</span> learn<span class="ansi-blue-fg">=</span>A3CLearner<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">,</span>model<span class="ansi-blue-fg">,</span>agent<span class="ansi-blue-fg">=</span>agent<span class="ansi-blue-fg">,</span>callback_fns<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span>A3CTrainer<span class="ansi-blue-fg">,</span>RewardMetric<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NameError</span>: name &#39;LinearA2C&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

