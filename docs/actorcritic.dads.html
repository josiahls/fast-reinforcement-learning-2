---

title: DADS


keywords: fastai
sidebar: home_sidebar

summary: "Diversity Is All You Need"
description: "Diversity Is All You Need"
nb_path: "nbs/14c_actorcritic.dads.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/14c_actorcritic.dads.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_LAUNCH_BLOCKING&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Discriminator" class="doc_header"><code>class</code> <code>Discriminator</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/actorcritic/diayn.py#L35" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Discriminator</code>(<strong><code>num_inputs</code></strong>, <strong><code>num_actions</code></strong>, <strong><code>num_skills</code></strong>, <strong><code>hidden_dim</code></strong>) :: <code>Module</code></p>
</blockquote>
<p><code>Module</code> for storing skills. Receives input (<code>num_inputs</code>+<code>num_actions</code>) -&gt; <code>num_skills</code>.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DADS" class="doc_header"><code>class</code> <code>DADS</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/actorcritic/dads.py#L52" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DADS</code>(<strong><code>num_inputs</code></strong>, <strong><code>action_space</code></strong>, <strong><code>discriminator</code></strong>:<code>Module</code>=<em><code>None</code></em>, <strong><code>num_skills</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>find_best_skill_interval</code></strong>:<code>int</code>=<em><code>10</code></em>, <strong><code>scale_entropy</code></strong>:<code>float</code>=<em><code>1</code></em>, <strong><code>best_skill_n_rollouts</code></strong>:<code>int</code>=<em><code>10</code></em>, <strong><code>include_actions</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>learn_p_z</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>add_p_z</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>hidden_size</code></strong>=<em><code>100</code></em>, <strong><code>lr</code></strong>=<em><code>0.003</code></em>, <strong><code>gamma</code></strong>=<em><code>0.99</code></em>, <strong><code>tau</code></strong>=<em><code>0.005</code></em>, <strong><code>alpha</code></strong>=<em><code>0.2</code></em>, <strong><code>policy</code></strong>=<em><code>'gaussian'</code></em>, <strong><code>automatic_entropy_tuning</code></strong>=<em><code>True</code></em>, <strong><code>target_update_interval</code></strong>=<em><code>1</code></em>) :: <a href="/fast-reinforcement-learning-2/actorcritic.sac.html#SAC"><code>SAC</code></a></p>
</blockquote>
<p>BaseAgent(model: torch.nn.modules.module.Module = None)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DiscriminatorTrainer" class="doc_header"><code>class</code> <code>DiscriminatorTrainer</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/actorcritic/diayn.py#L199" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DiscriminatorTrainer</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/fast-reinforcement-learning-2/qlearning.dqn.html#ExperienceReplay"><code>ExperienceReplay</code></a></p>
</blockquote>
<p>Subclasses ExperienceReplay for augmenting experience, and toggling the agent's skill thats,
being used, and also does training of the discriminator.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pybulletgym.envs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">env</span><span class="o">=</span><span class="s1">&#39;InvertedPendulumPyBulletEnv-v0&#39;</span>
<span class="n">agent</span><span class="o">=</span><span class="n">DADS</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span><span class="n">tau</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span><span class="n">num_skills</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">block</span><span class="o">=</span><span class="n">FirstLastExperienceBlock</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">exclude_nones</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">dls_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;bs&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;indexed&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;shuffle_train&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">})</span>
<span class="n">blk</span><span class="o">=</span><span class="n">IterableDataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">block</span><span class="p">),</span><span class="n">splitter</span><span class="o">=</span><span class="n">FuncSplitter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="kc">False</span><span class="p">))</span>
<span class="n">dls</span><span class="o">=</span><span class="n">blk</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">([</span><span class="n">env</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">())</span>

<span class="n">learner</span><span class="o">=</span><span class="n">SACLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">DiscriminatorTrainer</span><span class="p">(</span><span class="n">sz</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span><span class="n">starting_els</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">_max_episode_steps</span><span class="p">),</span>
                                        <span class="n">SACCriticTrainer</span><span class="p">],</span>
                   <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">AvgEpisodeRewardMetric</span><span class="p">(</span><span class="n">experience_cls</span><span class="o">=</span><span class="n">ExperienceFirstLast</span><span class="p">)])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.003</span><span class="p">,</span><span class="n">wd</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/conda/envs/fastrl/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_avg_episode_r</th>
      <th>valid_loss</th>
      <th>valid_avg_episode_r</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>-8.251103</td>
      <td>32.944444</td>
      <td>None</td>
      <td>32.944444</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>1</td>
      <td>-12.576365</td>
      <td>60.250000</td>
      <td>None</td>
      <td>60.250000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>2</td>
      <td>-16.996841</td>
      <td>80.304348</td>
      <td>None</td>
      <td>80.304348</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>3</td>
      <td>-21.833347</td>
      <td>97.000000</td>
      <td>None</td>
      <td>97.000000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>4</td>
      <td>-25.853008</td>
      <td>108.935484</td>
      <td>None</td>
      <td>108.935484</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>5</td>
      <td>-28.367571</td>
      <td>116.828571</td>
      <td>None</td>
      <td>116.828571</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>6</td>
      <td>-31.477066</td>
      <td>122.487179</td>
      <td>None</td>
      <td>122.487179</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>7</td>
      <td>-35.102928</td>
      <td>127.023256</td>
      <td>None</td>
      <td>127.023256</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>8</td>
      <td>-36.533272</td>
      <td>132.255319</td>
      <td>None</td>
      <td>132.255319</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>9</td>
      <td>-38.640102</td>
      <td>136.176471</td>
      <td>None</td>
      <td>136.176471</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>10</td>
      <td>-40.701740</td>
      <td>138.345455</td>
      <td>None</td>
      <td>138.345455</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>11</td>
      <td>-43.090706</td>
      <td>141.898305</td>
      <td>None</td>
      <td>141.898305</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>12</td>
      <td>-46.214668</td>
      <td>144.064516</td>
      <td>None</td>
      <td>144.064516</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>13</td>
      <td>-45.044010</td>
      <td>146.218750</td>
      <td>None</td>
      <td>146.218750</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>14</td>
      <td>-44.164463</td>
      <td>149.515152</td>
      <td>None</td>
      <td>149.515152</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>15</td>
      <td>-31.805542</td>
      <td>149.515152</td>
      <td>None</td>
      <td>149.515152</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>16</td>
      <td>-48.658085</td>
      <td>151.159420</td>
      <td>None</td>
      <td>151.159420</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>17</td>
      <td>-44.126305</td>
      <td>151.859155</td>
      <td>None</td>
      <td>151.859155</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>18</td>
      <td>-43.932556</td>
      <td>151.630137</td>
      <td>None</td>
      <td>151.630137</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>19</td>
      <td>-50.073730</td>
      <td>156.283784</td>
      <td>None</td>
      <td>156.283784</td>
      <td>00:18</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

