---

title: Noisy DQN


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/20e_qlearning.dqn_noisy.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/20e_qlearning.dqn_noisy.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="NoisyLinear" class="doc_header"><code>class</code> <code>NoisyLinear</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn_noisy.py#L31" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>NoisyLinear</code>(<strong><code>in_features</code></strong>, <strong><code>out_features</code></strong>, <strong><code>sigma_init</code></strong>=<em><code>0.017</code></em>, <strong><code>bias</code></strong>=<em><code>True</code></em>) :: <code>Linear</code></p>
</blockquote>
<p>Applies a linear transformation to the incoming data: :math:<code>y = xA^T + b</code></p>
<p>This module supports :ref:<code>TensorFloat32&lt;tf32_on_ampere&gt;</code>.</p>
<p>Args:
    in_features: size of each input sample
    out_features: size of each output sample
    bias: If set to <code>False</code>, the layer will not learn an additive bias.
        Default: <code>True</code></p>
<p>Shape:</p>

<pre><code>- Input: :math:`(N, *, H_{in})` where :math:`*` means any number of
  additional dimensions and :math:`H_{in} = \text{in\_features}`
- Output: :math:`(N, *, H_{out})` where all but the last dimension
  are the same shape as the input and :math:`H_{out} = \text{out\_features}`.

</code></pre>
<p>Attributes:
    weight: the learnable weights of the module of shape
        :math:<code>(\text{out\_features}, \text{in\_features})</code>. The values are
        initialized from :math:<code>\mathcal{U}(-\sqrt{k}, \sqrt{k})</code>, where
        :math:<code>k = \frac{1}{\text{in\_features}}</code>
    bias:   the learnable bias of the module of shape :math:<code>(\text{out\_features})</code>.
            If :attr:<code>bias</code> is <code>True</code>, the values are initialized from
            :math:<code>\mathcal{U}(-\sqrt{k}, \sqrt{k})</code> where
            :math:<code>k = \frac{1}{\text{in\_features}}</code></p>
<p>Examples::</p>

<pre><code>&gt;&gt;&gt; m = nn.Linear(20, 30)
&gt;&gt;&gt; input = torch.randn(128, 20)
&gt;&gt;&gt; output = m(input)
&gt;&gt;&gt; print(output.size())
torch.Size([128, 30])</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="NoisyFactorizedLinear" class="doc_header"><code>class</code> <code>NoisyFactorizedLinear</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn_noisy.py#L56" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>NoisyFactorizedLinear</code>(<strong><code>in_features</code></strong>, <strong><code>out_features</code></strong>, <strong><code>sigma_zero</code></strong>=<em><code>0.4</code></em>, <strong><code>bias</code></strong>=<em><code>True</code></em>) :: <code>Linear</code></p>
</blockquote>
<p>Applies a linear transformation to the incoming data: :math:<code>y = xA^T + b</code></p>
<p>This module supports :ref:<code>TensorFloat32&lt;tf32_on_ampere&gt;</code>.</p>
<p>Args:
    in_features: size of each input sample
    out_features: size of each output sample
    bias: If set to <code>False</code>, the layer will not learn an additive bias.
        Default: <code>True</code></p>
<p>Shape:</p>

<pre><code>- Input: :math:`(N, *, H_{in})` where :math:`*` means any number of
  additional dimensions and :math:`H_{in} = \text{in\_features}`
- Output: :math:`(N, *, H_{out})` where all but the last dimension
  are the same shape as the input and :math:`H_{out} = \text{out\_features}`.

</code></pre>
<p>Attributes:
    weight: the learnable weights of the module of shape
        :math:<code>(\text{out\_features}, \text{in\_features})</code>. The values are
        initialized from :math:<code>\mathcal{U}(-\sqrt{k}, \sqrt{k})</code>, where
        :math:<code>k = \frac{1}{\text{in\_features}}</code>
    bias:   the learnable bias of the module of shape :math:<code>(\text{out\_features})</code>.
            If :attr:<code>bias</code> is <code>True</code>, the values are initialized from
            :math:<code>\mathcal{U}(-\sqrt{k}, \sqrt{k})</code> where
            :math:<code>k = \frac{1}{\text{in\_features}}</code></p>
<p>Examples::</p>

<pre><code>&gt;&gt;&gt; m = nn.Linear(20, 30)
&gt;&gt;&gt; input = torch.randn(128, 20)
&gt;&gt;&gt; output = m(input)
&gt;&gt;&gt; print(output.size())
torch.Size([128, 30])</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="NoisyDQN" class="doc_header"><code>class</code> <code>NoisyDQN</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn_noisy.py#L81" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>NoisyDQN</code>(<strong><code>input_shape</code></strong>, <strong><code>n_actions</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TargetDQNLearner" class="doc_header"><code>class</code> <code>TargetDQNLearner</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn_target.py#L64" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TargetDQNLearner</code>(<strong><code>dls</code></strong>, <strong><code>agent</code></strong>:<a href="/fast-reinforcement-learning-2/basic_agents.html#BaseAgent"><code>BaseAgent</code></a>=<em><code>BaseAgent(model=None)</code></em>, <strong><code>model</code></strong>=<em><code>None</code></em>, <strong><code>use_train_mets</code></strong>=<em><code>True</code></em>, <strong><code>loss_func</code></strong>=<em><code>None</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>lr</code></strong>=<em><code>0.001</code></em>, <strong><code>splitter</code></strong>=<em><code>trainable_params</code></em>, <strong><code>cbs</code></strong>=<em><code>None</code></em>, <strong><code>metrics</code></strong>=<em><code>None</code></em>, <strong><code>path</code></strong>=<em><code>None</code></em>, <strong><code>model_dir</code></strong>=<em><code>'models'</code></em>, <strong><code>wd</code></strong>=<em><code>None</code></em>, <strong><code>wd_bn_bias</code></strong>=<em><code>False</code></em>, <strong><code>train_bn</code></strong>=<em><code>True</code></em>, <strong><code>moms</code></strong>=<em><code>(0.95, 0.85, 0.95)</code></em>) :: <a href="/fast-reinforcement-learning-2/learner.html#AgentLearner"><code>AgentLearner</code></a></p>
</blockquote>
<p>Base Learner for all reinforcement learning agents</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TestArgmaxActionSelector</span><span class="p">(</span><span class="n">ArgmaxActionSelector</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">scores</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
        <span class="n">o</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#         print(o)</span>
        <span class="k">return</span> <span class="n">o</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span><span class="o">=</span><span class="s1">&#39;CartPole-v1&#39;</span>
<span class="n">model</span><span class="o">=</span><span class="n">NoisyDQN</span><span class="p">((</span><span class="mi">4</span><span class="p">,),</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agent</span><span class="o">=</span><span class="n">DiscreteAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">default_device</span><span class="p">()),</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">(),</span>
                    <span class="n">a_selector</span><span class="o">=</span><span class="n">TestArgmaxActionSelector</span><span class="p">())</span>

<span class="n">block</span><span class="o">=</span><span class="n">FirstLastExperienceBlock</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">dls_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;bs&#39;</span><span class="p">:</span><span class="mi">32</span><span class="p">,</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;indexed&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;shuffle_train&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">})</span>
<span class="n">blk</span><span class="o">=</span><span class="n">IterableDataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">block</span><span class="p">),</span>
                      <span class="n">splitter</span><span class="o">=</span><span class="n">FuncSplitter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="kc">False</span><span class="p">),</span>
                     <span class="p">)</span>
<span class="n">dls</span><span class="o">=</span><span class="n">blk</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">([</span><span class="n">env</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">32</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">())</span>

<span class="n">learner</span><span class="o">=</span><span class="n">TargetDQNLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">wd_bn_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">cbs</span><span class="o">=</span><span class="p">[</span>
                                        <span class="n">ExperienceReplay</span><span class="p">(</span><span class="n">sz</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">starting_els</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">_max_episode_steps</span><span class="p">),</span>
                                        <span class="n">TargetDQNTrainer</span><span class="p">],</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">AvgEpisodeRewardMetric</span><span class="p">(</span><span class="n">experience_cls</span><span class="o">=</span><span class="n">ExperienceFirstLast</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0083, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0168, device=&#39;cuda:0&#39;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span><span class="n">wd</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_avg_episode_r</th>
      <th>valid_loss</th>
      <th>valid_avg_episode_r</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.874034</td>
      <td>30.895833</td>
      <td>None</td>
      <td>30.895833</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.524404</td>
      <td>25.115000</td>
      <td>None</td>
      <td>25.115000</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.288265</td>
      <td>14.123333</td>
      <td>None</td>
      <td>14.123333</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.905628</td>
      <td>9.263333</td>
      <td>None</td>
      <td>9.263333</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.413778</td>
      <td>9.005000</td>
      <td>None</td>
      <td>9.005000</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.043012</td>
      <td>9.000000</td>
      <td>None</td>
      <td>9.000000</td>
      <td>00:13</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0352, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0138, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0496, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0159, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0180, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0335, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0087, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0086, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0351, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0176, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0083, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0081, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0241, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0232, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0230, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0332, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0175, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0728, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0407, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0089, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0517, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0430, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0437, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0032, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0185, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0423, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0064, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0061, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0257, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0213, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0057, device=&#39;cuda:0&#39;)
tensor(0.0169, device=&#39;cuda:0&#39;) tensor(-0.0347, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0005, device=&#39;cuda:0&#39;)
tensor(0.0169, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0060, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0211, device=&#39;cuda:0&#39;)
tensor(0.0169, device=&#39;cuda:0&#39;) tensor(0.0547, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0089, device=&#39;cuda:0&#39;)
tensor(0.0169, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0066, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0091, device=&#39;cuda:0&#39;)
tensor(0.0169, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0050, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0141, device=&#39;cuda:0&#39;)
tensor(0.0168, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0495, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0030, device=&#39;cuda:0&#39;)
tensor(0.0168, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0119, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0087, device=&#39;cuda:0&#39;)
tensor(0.0168, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0154, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0057, device=&#39;cuda:0&#39;)
tensor(0.0168, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0174, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0242, device=&#39;cuda:0&#39;)
tensor(0.0168, device=&#39;cuda:0&#39;) tensor(0.0659, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0207, device=&#39;cuda:0&#39;)
tensor(0.0168, device=&#39;cuda:0&#39;) tensor(0.0003, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0274, device=&#39;cuda:0&#39;)
tensor(0.0168, device=&#39;cuda:0&#39;) tensor(0.0211, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0098, device=&#39;cuda:0&#39;)
tensor(0.0167, device=&#39;cuda:0&#39;) tensor(0.0329, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0071, device=&#39;cuda:0&#39;)
tensor(0.0167, device=&#39;cuda:0&#39;) tensor(-0.0063, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0460, device=&#39;cuda:0&#39;)
tensor(0.0167, device=&#39;cuda:0&#39;) tensor(0.0235, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0034, device=&#39;cuda:0&#39;)
tensor(0.0167, device=&#39;cuda:0&#39;) tensor(-0.0155, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0050, device=&#39;cuda:0&#39;)
tensor(0.0167, device=&#39;cuda:0&#39;) tensor(0.0076, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0004, device=&#39;cuda:0&#39;)
tensor(0.0167, device=&#39;cuda:0&#39;) tensor(-0.0334, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0034, device=&#39;cuda:0&#39;)
tensor(0.0167, device=&#39;cuda:0&#39;) tensor(0.0278, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(-0.0238, device=&#39;cuda:0&#39;)
tensor(0.0166, device=&#39;cuda:0&#39;) tensor(-0.0141, device=&#39;cuda:0&#39;)
tensor(0.0170, device=&#39;cuda:0&#39;) tensor(0.0821, device=&#39;cuda:0&#39;)
tensor(0.0166, device=&#39;cuda:0&#39;) tensor(-0.0334, device=&#39;cuda:0&#39;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[(</span><span class="n">o</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">o</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="n">o</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(tensor(-0.8769, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;),
  tensor(0.8870, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;),
  tensor(0.0080, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;)),
 (tensor(-0.8642, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;),
  tensor(0.8924, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;),
  tensor(-0.0181, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;)),
 (tensor(0.0059, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;),
  tensor(0.0307, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;),
  tensor(0.0170, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;)),
 (tensor(0.0051, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;),
  tensor(0.0342, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;),
  tensor(0.0169, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;)),
 (tensor(-0.1084, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;),
  tensor(0.1220, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;),
  tensor(0.0075, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;)),
 (tensor(0.0870, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;),
  tensor(0.1134, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;),
  tensor(0.1002, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;)),
 (tensor(0.0086, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;),
  tensor(0.0234, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;),
  tensor(0.0166, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;)),
 (tensor(0.0148, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;),
  tensor(0.0159, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;),
  tensor(0.0154, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;))]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

