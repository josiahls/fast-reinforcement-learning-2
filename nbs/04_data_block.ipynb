{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data_block\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Block\n",
    "\n",
    "> Primary handlers for interfacing the openai gym envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.torch_core import *\n",
    "from fastrl.basic_train import *\n",
    "from fastrl.wrappers import *\n",
    "from dataclasses import asdict\n",
    "from fastprogress.fastprogress import IN_NOTEBOOK\n",
    "import torch.multiprocessing as mp\n",
    "import logging\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s line:%(lineno)d %(levelname)s - %(message)s',\n",
    "                    datefmt='%m-%d %H:%M:%S')\n",
    "_logger=logging.getLogger(__name__)\n",
    "_logger.setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "`Dataset` instances are going to be a little different from the typically classification dataset that you might use in pytorch. Commonly, datasets have:\n",
    "- A known size to iter through\n",
    "- Maintain their state during the training sequence\n",
    "- Randomly sample their dataset\n",
    "- Have a common `x`/`y` or `input`/`target` data format\n",
    "\n",
    "For our `ExperienceSourceDataset`, most of this is going to be different. \n",
    "- We can have multiple sources (envs)\n",
    "\n",
    "You could think of a traditional dataset approach as being a mix of a `ExperienceSourceDataset` and a form of `ExperienceReplay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fix_s(x):\n",
    "    \"Flatten `x` to `(1,-1)` where `1` is the batch dim (B) unless **seems** to be an image e.g. has 3 dims (W,H,C), then it will attempt (B,W,H,C).\"\n",
    "    return (x if x.shape[0]==1 else \n",
    "            x.reshape(1,-1) if len(x.shape)==2 else\n",
    "            np.expand_dims(x,0))\n",
    "\n",
    "@dataclass\n",
    "class Experience(object):\n",
    "    s:np.array\n",
    "    sp:np.array\n",
    "    a:np.array\n",
    "    r:np.array\n",
    "    d:np.array\n",
    "    agent_s:np.array\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        for k,v in asdict(self).items():\n",
    "            setattr(self,k,fix_s(v) if k in ['s','sp'] else np.array(v,dtype=float).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': array([[2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2]]),\n",
       " 'sp': array([[1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2]]),\n",
       " 'a': array([[1., 1.]]),\n",
       " 'r': array([[2., 1., 1., 2., 2., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 2., 1., 2., 1., 2.]]),\n",
       " 'd': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 'agent_s': array([[5., 5., 1., 3., 4.]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp=Experience(s=np.random.randint(1,3,(5,5)),\n",
    "               sp=np.random.randint(1,3,(5,5)),\n",
    "               a=np.random.randint(1,3,(1,2)),\n",
    "               r=np.random.randint(1,3,(1,20)),\n",
    "               d=np.random.randint(0,1,(5,5)),\n",
    "               agent_s=np.random.randint(0,6,(1,5)))\n",
    "asdict(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceSourceDataset(Dataset):\n",
    "    \"Similar to fastai's `LabelList`, iters in-order samples from `1->len(envs)` `envs`.\"\n",
    "    def __init__(self,envs:Tuple[gym.Env,list,tuple],steps=1,max_episode_step=None):\n",
    "        self.envs=listify(envs)\n",
    "        self.steps=steps\n",
    "        self.max_episode_step=max_episode_step\n",
    "        self.d=np.zeros((len(self.envs),))+1\n",
    "        self.s=np.zeros((len(self.envs),*self.envs[0].observation_space.sample().shape))\n",
    "        self.interation=np.zeros((len(self.envs)))\n",
    "        self.total_r=[]\n",
    "        self.total_steps=[]\n",
    "        self.learner=None\n",
    "        \n",
    "    def __len__(self): return ifnone(self.max_episode_step,self.envs[0].spec.max_episode_steps)\n",
    "    \n",
    "    def __getitem__(self,idx)->Tuple[Tuple[np.array],Dict]:\n",
    "        idx=idx%len(self.envs)\n",
    "        if idx==0 and self.interation[idx]==0:\n",
    "            for i,e in enumerate(self.envs): self.s[i]=e.reset()                                   # There is the possiblity this will equal None (and crash)?\n",
    "            self.interation=np.zeros((len(self.envs)))\n",
    "        \n",
    "        exps:List[Experience]=[]\n",
    "        while True:\n",
    "            a,agent_s=self.learner.predict(None,None)\n",
    "            sp,r,self.d[idx],_=self.envs[idx].step(a)\n",
    "            self.total_r.append(r)\n",
    "            self.total_steps.append(self.interation[idx])\n",
    "            exps.append(Experience(self.s[idx],sp,a,r,self.d[idx],agent_s=agent_s))\n",
    "            self.s[idx]=sp\n",
    "            self.interation[idx]+=1\n",
    "            if len(exps)%self.steps==0:break\n",
    "            if self.d[idx] or self.interation[idx]>=len(self):\n",
    "                self.interation[idx]=0\n",
    "                break\n",
    "        return [e.s for e in exps],[asdict(e) for e in exps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([15, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([15, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([6, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([15, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([15, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([12, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([15, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([15, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([15, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:54] p134 line:9 CRITICAL - xb: torch.Size([6, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# make_env = lambda: gym.make(\"Acrobot-v1\")\n",
    "make_env = lambda: gym.make(\"CartPole-v1\")\n",
    "envs=[make_env() for _ in range(3)]\n",
    "ds=ExperienceSourceDataset(envs,max_episode_step=50,steps=5)\n",
    "dl=DataLoader(ds,batch_size=len(envs),num_workers=0)#len(envs))\n",
    "ds.learner=AgentLearner(DataBunch(dl,dl),nn.Sequential(nn.Linear(5,5),nn.ReLU(),nn.Linear(5,5)))\n",
    "for xb,yb in dl:\n",
    "    _logger.critical('xb: %s, yb: %s',torch.cat(xb).shape,yb[0].keys())\n",
    "    assert torch.cat(xb).shape[0]<=5*3\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06-17 17:05:55] p134 line:10 CRITICAL - xb: torch.Size([15, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:55] p134 line:10 CRITICAL - xb: torch.Size([15, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:55] p134 line:10 CRITICAL - xb: torch.Size([3, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "[06-17 17:05:55] p134 line:10 CRITICAL - xb: torch.Size([3, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:56] p134 line:10 CRITICAL - xb: torch.Size([15, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:56] p134 line:10 CRITICAL - xb: torch.Size([15, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:56] p134 line:10 CRITICAL - xb: torch.Size([15, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:56] p134 line:10 CRITICAL - xb: torch.Size([3, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:56] p134 line:10 CRITICAL - xb: torch.Size([3, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:56] p134 line:10 CRITICAL - xb: torch.Size([3, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:56] p134 line:10 CRITICAL - xb: torch.Size([15, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:56] p134 line:10 CRITICAL - xb: torch.Size([15, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:56] p134 line:10 CRITICAL - xb: torch.Size([9, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:10 CRITICAL - xb: torch.Size([15, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:10 CRITICAL - xb: torch.Size([15, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:10 CRITICAL - xb: torch.Size([3, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:10 CRITICAL - xb: torch.Size([2, 1, 400, 600, 3]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n"
     ]
    }
   ],
   "source": [
    "def make_env():\n",
    "    env=gym.make(\"CartPole-v1\")\n",
    "    env.reset()\n",
    "    return env\n",
    "envs=[PixelObservationWrapper(make_env()) for _ in range(3)]\n",
    "ds=ExperienceSourceDataset(envs,max_episode_step=50,steps=5)\n",
    "dl=DataLoader(ds,batch_size=len(envs),num_workers=0)#len(envs))\n",
    "ds.learner=AgentLearner(DataBunch(dl,dl),nn.Sequential(nn.Linear(5,5),nn.ReLU(),nn.Linear(5,5)))\n",
    "for xb,yb in dl:\n",
    "    _logger.critical('xb: %s, yb: %s',torch.cat(xb).shape,yb[0].keys())\n",
    "    assert torch.cat(xb).shape[0]<=5*3\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class FirstLastExperienceSourceDataset(ExperienceSourceDataset):\n",
    "    \"Similar to `ExperienceSourceDataset` but only keeps the first and last parts of a step. Can be seen as frame skipping.\"\n",
    "    def __getitem__(self,idx)->Tuple[Tuple[np.array],Dict]:\n",
    "        s,exps=super(FirstLastExperienceSourceDataset,self).__getitem__(idx)\n",
    "        exp=exps[-1]\n",
    "        exp['s']=exps[0]['s']\n",
    "        return [exps[0]['s']],[exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([3, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n",
      "[06-17 17:05:57] p134 line:8 CRITICAL - xb: torch.Size([2, 1, 4]), yb: dict_keys(['s', 'sp', 'a', 'r', 'd', 'agent_s'])\n"
     ]
    }
   ],
   "source": [
    "make_env = lambda: gym.make(\"CartPole-v1\")\n",
    "envs=[make_env() for _ in range(3)]\n",
    "ds=FirstLastExperienceSourceDataset(envs,max_episode_step=50,steps=5)\n",
    "dl=DataLoader(ds,batch_size=len(envs),num_workers=0)#len(envs))\n",
    "ds.learner=AgentLearner(DataBunch(dl,dl),nn.Sequential(nn.Linear(5,5),nn.ReLU(),nn.Linear(5,5)))\n",
    "index=0\n",
    "for xb,yb in dl:\n",
    "    _logger.critical('xb: %s, yb: %s',torch.cat(xb).shape,yb[0].keys())\n",
    "    assert torch.cat(xb).shape[0]<=3\n",
    "    sys.stdout.flush()\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AsyncExperienceSourceCallback(LearnerCallback):\n",
    "    _order = -11\n",
    "    \n",
    "    def on_epoch_begin(self,**kwargs):\n",
    "        if not self.learn.data.empty_val:\n",
    "            ds=(self.learn.data.train_ds if self.learn.model.training else\n",
    "                self.learn.data.valid_ds)\n",
    "            ds.pause_event.clear()\n",
    "\n",
    "            if len(ds.data_proc_list)==0:\n",
    "                for proc_idx in range(ds.n_processes):\n",
    "                    data_proc=mp.Process(target=getattr(self.learn,'grad_fitter',grad_fitter), \n",
    "                                         args=(self.learn.model,self.learn.data.device,\n",
    "                                               ds.grad_queue,ds.loss_queue,ds.pause_event,ds.cancel_event))\n",
    "                    data_proc.start()\n",
    "                    ds.data_proc_list.append(data_proc)\n",
    "\n",
    "    def on_batch_end(self,**kwargs):\n",
    "        if not self.learn.data.empty_val:\n",
    "            # If not training, pause train ds, otherwise pause valid ds\n",
    "            ds=(self.learn.data.train_ds if not self.learn.model.training else\n",
    "                self.learn.data.valid_ds)\n",
    "            ds.pause_event.set()\n",
    "    \n",
    "    def on_train_end(self,**kwargs):\n",
    "        _logger.info('Canceling Processes')\n",
    "        for ds in [self.learn.data.train_ds,None if self.learn.data.empty_val else self.learn.data.valid_ds]:\n",
    "            if ds is None: continue\n",
    "            ds.cancel_event.set()\n",
    "            while not ds.grad_queue.empty(): ds.grad_queue.get()\n",
    "            while not ds.loss_queue.empty(): ds.loss_queue.get()\n",
    "            _logger.info('Joining Processes')\n",
    "            for proc in ds.data_proc_list: proc.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def grad_fitter(model:nn.Module,ds:ExperienceSourceDataset,grad_queue:mp.JoinableQueue,loss_queue:mp.JoinableQueue,pause_event:mp.Event,cancel_event:mp.Event):\n",
    "    \"Updates a `train_queue` with `model.parameters()` and `loss_queue` with the loss. Note that this is only an example grad_fitter.\"\n",
    "    _logger.warning('Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.')\n",
    "    while not cancel_event.is_set(): # We are expecting the  grad_fitter to loop unless cancel_event is set\n",
    "        grad_queue.put(None)        #  Adding `None` to `train_queue` will trigger an eventual ending of training\n",
    "        loss_queue.put(None)\n",
    "        if pause_event.is_set():     # There needs to be the ability for the grad_fitter to pause e.g. if waiting for validation to end.\n",
    "            cancel_event.wait(0.1)   # Using cancel_event to wait allows the main process to end this Process.\n",
    "\n",
    "class AsyncGradExperienceSourceDataset(ExperienceSourceDataset):\n",
    "    \"Contains dataloaders of multiple sub-datasets and executes them using `n_processes`. `xb` is the gradients from the agents, `yb` is the loss.\"\n",
    "    def __init__(self,envs,n_processes,learner_cls=AgentLearner,ds_cls=ExperienceSourceDataset,max_episode_step=None,*args,**kwargs):\n",
    "        self.n_processes=n_processes\n",
    "        self.envs=envs\n",
    "        self.pause_event=mp.Event()                               # If the event is set, then the Process will freeze.\n",
    "        self.cancel_event=mp.Event()                              # If the event is set, then the Process will freeze.\n",
    "        self.max_episode_step=max_episode_step\n",
    "        self.grad_queue=mp.JoinableQueue(maxsize=self.n_processes)\n",
    "        self.loss_queue=mp.JoinableQueue(maxsize=self.n_processes)\n",
    "        self.data_proc_list=[]\n",
    "        \n",
    "    def __getitem__(self,idx)->Tuple[Tuple[np.array],Dict]:\n",
    "        if len(self.data_proc_list)==0: raise StopIteration()\n",
    "        train_entry=self.grad_queue.get()\n",
    "\n",
    "        if train_entry is None:\n",
    "            raise StopIteration()\n",
    "        \n",
    "        train_loss_entry=self.loss_queue.get()\n",
    "        return train_entry,[train_loss_entry]      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06-17 17:05:57] p211 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p214 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p219 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p222 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p225 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p228 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p231 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p235 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p239 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p233 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p243 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p134 line:27 INFO - Canceling Processes\n",
      "[06-17 17:05:57] p246 line:4 WARNING - Using the `test_fitter` function. Make sure your `AgentLearner` has a `grad_fitter`.\n",
      "[06-17 17:05:57] p134 line:33 INFO - Joining Processes\n",
      "[06-17 17:05:57] p134 line:33 INFO - Joining Processes\n"
     ]
    }
   ],
   "source": [
    "make_env = lambda: gym.make(\"CartPole-v1\")\n",
    "envs=[make_env() for _ in range(3)]\n",
    "ds=AsyncGradExperienceSourceDataset(envs,12,max_episode_step=50,steps=5)\n",
    "dl=DataLoader(ds,batch_size=len(envs),num_workers=0)#len(envs))\n",
    "learner=AgentLearner(DataBunch(dl,dl),nn.Sequential(nn.Linear(5,5),nn.ReLU(),nn.Linear(5,5)))\n",
    "callback=AsyncExperienceSourceCallback(learner)\n",
    "index=0\n",
    "callback.on_epoch_begin()\n",
    "for xb,yb in dl:\n",
    "    _logger.critical('xb: %s, yb: %s',torch.cat(xb).shape,yb[0].keys())\n",
    "    assert torch.cat(xb).shape[0]<=3\n",
    "    sys.stdout.flush()\n",
    "    index+=1\n",
    "callback.on_train_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Shower\n",
    "We can define a wrapper around a dataset which will show up to `rows * cols` environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DatasetDisplayWrapper(object):\n",
    "    def __init__(self,ds,rows=2,cols=2,max_w=800):\n",
    "        \"Wraps a ExperienceSourceDataset instance showing multiple envs in a `rows` by `cols` grid in a Jupyter notebook.\"\n",
    "        # Ref: https://stackoverflow.com/questions/1443129/completely-wrap-an-object-in-python\n",
    "        # We are basically Wrapping any instance of ExperienceSourceDataset (kind of cool right?)\n",
    "        self.__class__ = type(ds.__class__.__name__,(self.__class__, ds.__class__),{})\n",
    "        self.__dict__=ds.__dict__\n",
    "        self.rows,self.cols,self.max_w=rows,cols,max_w\n",
    "        self.current_display=None\n",
    "        if not IN_NOTEBOOK: \n",
    "            _logger.warning('It seems you are not running in a notebook. Nothing is going to be displayed.')\n",
    "            return\n",
    "        \n",
    "        if self.envs[0].render('rgb_array') is None: self.envs[0].reset()\n",
    "        rdr=self.envs[0].render('rgb_array')\n",
    "        if rdr.shape[1]*self.cols>max_w:\n",
    "            _logger.warning('Max Width is %s but %s*%s is greater than. Decreasing the number of cols to %s, rows increase by %s',\n",
    "                            max_w,rdr.shape[1],self.cols,max_w%rdr.shape[1],max_w%rdr.shape[1])\n",
    "            self.cols=max_w%rdr.shape[1]\n",
    "            self.rows+=max_w%rdr.shape[1]\n",
    "\n",
    "        self.current_display=np.zeros(shape=(self.rows*rdr.shape[0],self.cols*rdr.shape[1],rdr.shape[2])).astype('uint8')\n",
    "        display.display(PIL.Image.fromarray(self.current_display))\n",
    "        _logger.critical('%s, %s, %s, %s, %s',0,0//self.cols,0%self.cols,rdr.shape,self.current_display.shape)\n",
    "\n",
    "    def __getitem__(self,idx)->Tuple[Tuple[np.array],Dict]:\n",
    "        o=super(DatasetDisplayWrapper,self).__getitem__(idx)\n",
    "        idx=idx%len(self.envs)\n",
    "        if self.current_display is not None and idx<self.rows*self.cols:\n",
    "            display.clear_output(wait=True)\n",
    "            im=self.envs[idx].render(mode='rgb_array')\n",
    "            self.current_display[(idx//self.cols)*im.shape[0]:(idx//self.cols)*im.shape[0]+im.shape[0],\n",
    "                                 (idx%self.cols)*im.shape[1]:(idx%self.cols)*im.shape[1]+im.shape[1],:]=im\n",
    "            new_im=PIL.Image.fromarray(self.current_display)\n",
    "            display.display(new_im)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1800x800 at 0x7FEA0ABA4950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "make_env = lambda: gym.make(\"CartPole-v1\")\n",
    "envs=[make_env() for _ in range(6)]\n",
    "ds=ExperienceSourceDataset(envs,max_episode_step=50,steps=5)\n",
    "ds=DatasetDisplayWrapper(ds,cols=3,rows=2,max_w=8000)\n",
    "dl=DataLoader(ds,batch_size=len(envs),num_workers=0)#len(envs))\n",
    "ds.learner=AgentLearner(DataBunch(dl,dl),nn.Sequential(nn.Linear(5,5),nn.ReLU(),nn.Linear(5,5)))\n",
    "for xb,yb in dl:\n",
    "    assert torch.cat(xb).shape[0]<=5*6\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 02_basic_train.ipynb.\n",
      "Converted 04_data_block.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted notes.ipynb.\n",
      "converting: /opt/project/nbs/04_data_block.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()\n",
    "notebook2html(n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
