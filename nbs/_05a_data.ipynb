{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Blocks\n",
    "\n",
    "> Iterable datasets for returning environment outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need `TfmdSourceDL` to trigger some cleanup before doing an iteration. \n",
    "\n",
    "TODO: (Josiah): Is there a way to override the `before_iter` in the DataBlock instead? The main issue is that we need to be able to reference `self` which isn't possible when passing methods through the `DataLoader` params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_single_nested_tuple(b):return isinstance(b,tuple) and len(b)==1 and isinstance(b[0],tuple)\n",
    "    \n",
    "class TfmdSourceDL(TfmdDL):\n",
    "    def before_iter(self):\n",
    "        super().before_iter()\n",
    "        self.dataset.reset_src()\n",
    "        \n",
    "    def create_item(self,b):\n",
    "        b=super().create_item(b)\n",
    "        return b[0] if is_single_nested_tuple(b) else b\n",
    "\n",
    "    def after_iter(self):\n",
    "        super().after_iter()\n",
    "        self.dataset.close_src()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TfmdSource` has an adjustable `__len__`. Unlike the `TfmdLists`, `TfmdSource` iters on a single item until the item raises a `SourceExhausted` exception. This means that the soruces `items` are being tracked by a separate index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SourceExhausted(Exception):pass\n",
    "\n",
    "@delegates(TfmdLists)\n",
    "class TfmdSource(TfmdLists):\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of sources called `items`. Only swtches between them if they get exhausted.\"\n",
    "    def __init__(self,items, tfms,n:int=None,cycle_srcs=True,verbose=False,**kwargs):\n",
    "        self.n=n;self.cycle_srcs=cycle_srcs;self.source_idx=0;self.verbose=verbose;self.res_buffer=deque([]);self.extra_len=0\n",
    "        super().__init__(items,tfms,**kwargs)\n",
    "#         store_attr('n,cycle_srcs', self) TODO (Josiah): Does not seem to work?\n",
    "    \n",
    "    def __enter__(self):                             self.cycle_srcs=False\n",
    "    def __exit__(self,exc_type,exc_value,traceback): self.cycle_srcs=True\n",
    "        \n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: Cycling sources: {self.cycle_srcs}\\n{self.items}\\ntfms - {self.tfms.fs}\"\n",
    "    def close_src(self):\n",
    "        [t.close(self) for t in self.tfms if hasattr(t,'close')]\n",
    "        self.res_buffer.clear()\n",
    "        \n",
    "    def reset_src(self): \n",
    "        [t.reset(self) for t in self.tfms if hasattr(t,'reset')]\n",
    "        self.res_buffer.clear()\n",
    "        \n",
    "    def setup(self,train_setup=True):super().setup(train_setup);self.reset_src()\n",
    "     \n",
    "    def __len__(self):\n",
    "#         return ifnone(self.n,super().__len__()) TODO (Josiah): self.n is not settable in DataBlock, and since TfmdLists gets reinit, this will not persist\n",
    "        if len(self.items)!=0 and isinstance(self.items[0],gym.Env) and self.cycle_srcs:\n",
    "            self.reset_src()\n",
    "            return self.items[0].spec.max_episode_steps+self.extra_len # TODO(Josiah): This is the only OpenAI dependent code. How do we have htis set in setup?\n",
    "        if self.n is not None: return self.n\n",
    "        if len(self.items)!=0 and hasattr(self.items[0],'n'):\n",
    "            return self.items[0].n # TODO(Josiah): Possible solution to make this more generic?\n",
    "        return super().__len__()\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if len(self.res_buffer)!=0:return self.res_buffer.popleft()\n",
    "        \n",
    "        try:res=super().__getitem__(self.source_idx if self.cycle_srcs else idx)\n",
    "        except (IndexError,SourceExhausted) as e:\n",
    "            if not self.cycle_srcs:raise\n",
    "            if type(e)==SourceExhausted: \n",
    "                self.source_idx+=1;  pv(f'SourceExhausted, incrementing to idx {self.source_idx}',verbose=self.verbose) \n",
    "                if len(self.items)<=self.source_idx:e=IndexError(f'Index {self.source_idx} from SourceExhausted except is out of bounds.')\n",
    "            if type(e)==IndexError:      \n",
    "                self.source_idx=0;   pv(f'IndexError, setting idx to {self.source_idx}',verbose=self.verbose)\n",
    "                self.reset_src()\n",
    "            res=self.__getitem__(self.source_idx)\n",
    "        \n",
    "        if is_listy(res):\n",
    "            self.res_buffer=deque(res)\n",
    "            return self.res_buffer.popleft()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IterableDataBlock(DataBlock):\n",
    "    tls_type=TfmdSource\n",
    "    def datasets(self, source, verbose=False):\n",
    "        self.source = source                     ; pv(f\"Collecting items from {source}\", verbose)\n",
    "        items = (self.get_items or noop)(source) ; pv(f\"Found {len(items)} items\", verbose)\n",
    "        splits = (self.splitter or RandomSplitter())(items)\n",
    "        pv(f\"{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}\", verbose)\n",
    "        tls=L([self.tls_type(items, t,verbose=verbose) for t in L(ifnone(self._combine_type_tfms(),[None]))])\n",
    "        return Datasets(items,tls=tls,splits=splits, dl_type=self.dl_type, n_inp=self.n_inp, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MakeTfm(Transform):\n",
    "    def setup(self,items:TfmdSource,train_setup=False):\n",
    "        with items: \n",
    "            for i in range(len(items)):items[i]=gym.make(items[i])\n",
    "        return super().setup(items,train_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export    \n",
    "def env_display(env:gym.Env):\n",
    "    img=env.render('rgb_array')\n",
    "    try:display.clear_output(wait=True)\n",
    "    except AttributeError:pass\n",
    "    new_im=PIL.Image.fromarray(img)\n",
    "    display.display(new_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class Experience():\n",
    "    d:bool;s:np.ndarray;sp:np.ndarray;r:float;a:Any;eid:int=0;episode_r:float=0;absolute_end:bool=False\n",
    "                                    \n",
    "    def __repr__(self):return f'Experience({\",\".join([f\"{f.name}={getattr(self,f.name).numpy()}\" for f in fields(self)])})'\n",
    "    @classmethod\n",
    "    def from_batch(cls,b):\n",
    "        if isinstance(b,tuple):b=b[0]\n",
    "        bs=max(len(e) for e in b.values())\n",
    "        return L([cls(**{k:v[i] for k,v in b.items()}) for i in range(bs)])\n",
    "                                    \n",
    "def envlen(o:gym.Env):return o.spec.max_episode_steps\n",
    "\n",
    "@dataclass\n",
    "class ResetAndStepTfm(Transform):\n",
    "    def __init__(self,seed:int=None,agent:object=None,n_steps:int=1,steps_delta:int=1,a:Any=None,history:deque=None,\n",
    "                 s:dict=None,steps:dict=None,maxsteps:int=None,display:bool=False,hist2dict:bool=True):\n",
    "        self.seed=seed;self.agent=agent;self.n_steps=n_steps;self.steps_delta=steps_delta;self.a=a;self.history=history;self.hist2dict=hist2dict\n",
    "        self.maxsteps=maxsteps;self.display=display\n",
    "        self.s=ifnone(s,{})\n",
    "        self.steps=ifnone(steps,{})\n",
    "        # store_attr('n,cycle_srcs', self) TODO (Josiah): Does not seem to work?\n",
    "            \n",
    "    def setup(self,items:TfmdSource,train_setup=False):\n",
    "        self.reset(items)\n",
    "        self.history=deque(maxlen=self.n_steps)\n",
    "        return super().setup(items,train_setup)\n",
    "    \n",
    "    def reset(self,items):\n",
    "        if len(items.items)==0:return\n",
    "        if items.extra_len==0:\n",
    "            items.extra_len=items.items[0].spec.max_episode_steps*(self.n_steps-1) # Extra steps to unwrap done\n",
    "        with items:\n",
    "            self.s={id(o):o.reset() for o in items.items if o.seed(self.seed) or True}\n",
    "            self.steps={id(o):0 for o in items.items}\n",
    "            self.maxsteps=ifnone(self.maxsteps,envlen(items.items[0]))\n",
    "            if self.history is not None:self.history.clear()\n",
    "        \n",
    "    def queue2dict(self,q:deque):return [asdict(hist) for hist in tuple(copy(q))]\n",
    "    def encodes(self,o:gym.Env):\n",
    "        # If history has finished, then instead we try emptying the environment\n",
    "        if self.history and self.history[-1].d:\n",
    "            self.history.popleft()\n",
    "            if len(self.history)==0:raise SourceExhausted\n",
    "            if len(self.history)==1:self.history[-1].absolute_end=True\n",
    "            return self.queue2dict(self.history) if self.hist2dict else copy(self.history)\n",
    "        \n",
    "        while True:\n",
    "            a=ifnone(self.a,o.action_space.sample()) if self.agent is None else self.agent(self.s[id(o)])[0]\n",
    "            sp,r,d,_=o.env.step(a)\n",
    "            if self.display:env_display(o)\n",
    "                \n",
    "            self.steps[id(o)]+=1\n",
    "            d=self.steps[id(o)]>=self.maxsteps if not d else d\n",
    "    \n",
    "            self.history.append(Experience(d=d,s=self.s[id(o)].copy(),sp=sp.copy(),r=r,a=a,eid=id(o),\n",
    "                                episode_r=r+(self.history[-1].episode_r if self.history else 0)))\n",
    "            self.s[id(o)]=sp.copy()\n",
    "            \n",
    "            if self.steps[id(o)]%self.steps_delta!=0: continue # TODO(Josiah): if `steps_delta`!=1, it may skip the first state. Is this ok?\n",
    "            if len(self.history)!=self.n_steps:       continue\n",
    "            break\n",
    "        \n",
    "        if self.history[-1].d and len(self.history)==1:self.history[-1].absolute_end=True\n",
    "        return self.queue2dict(self.history) if self.hist2dict else copy(self.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(ResetAndStepTfm)\n",
    "def ExperienceBlock(dls_kwargs=None,**kwargs):\n",
    "    return TransformBlock(type_tfms=[MakeTfm(),ResetAndStepTfm(**kwargs)],dl_type=TfmdSourceDL,dls_kwargs=dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ptan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperienceFirstLast(state=array([-0.04456399,  0.04653909,  0.01326909, -0.02099827]), action=0, reward=1.0, last_state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]))\n",
      "ExperienceFirstLast(state=array([-0.04456399,  0.04653909,  0.01326909, -0.02099827]), action=0, reward=1.0, last_state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]))\n",
      "ExperienceFirstLast(state=array([-0.04456399,  0.04653909,  0.01326909, -0.02099827]), action=0, reward=1.0, last_state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]))\n",
      "ExperienceFirstLast(state=array([-0.04456399,  0.04653909,  0.01326909, -0.02099827]), action=0, reward=1.0, last_state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]))\n",
      "ExperienceFirstLast(state=array([-0.04456399,  0.04653909,  0.01326909, -0.02099827]), action=0, reward=1.0, last_state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]))\n",
      "ExperienceFirstLast(state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]), action=0, reward=1.0, last_state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]))\n",
      "ExperienceFirstLast(state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]), action=0, reward=1.0, last_state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]))\n",
      "ExperienceFirstLast(state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]), action=0, reward=1.0, last_state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]))\n",
      "ExperienceFirstLast(state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]), action=0, reward=1.0, last_state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]))\n",
      "ExperienceFirstLast(state=array([-0.04363321, -0.14877061,  0.01284913,  0.2758415 ]), action=0, reward=1.0, last_state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]))\n",
      "ExperienceFirstLast(state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]), action=0, reward=1.0, last_state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]))\n",
      "ExperienceFirstLast(state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]), action=0, reward=1.0, last_state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]))\n",
      "ExperienceFirstLast(state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]), action=0, reward=1.0, last_state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]))\n",
      "ExperienceFirstLast(state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]), action=0, reward=1.0, last_state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]))\n",
      "ExperienceFirstLast(state=array([-0.04660862, -0.3440735 ,  0.01836596,  0.5725492 ]), action=0, reward=1.0, last_state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]))\n",
      "ExperienceFirstLast(state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]), action=0, reward=1.0, last_state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]))\n",
      "ExperienceFirstLast(state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]), action=0, reward=1.0, last_state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]))\n",
      "ExperienceFirstLast(state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]), action=0, reward=1.0, last_state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]))\n",
      "ExperienceFirstLast(state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]), action=0, reward=1.0, last_state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]))\n",
      "ExperienceFirstLast(state=array([-0.05349009, -0.5394481 ,  0.02981694,  0.87096095]), action=0, reward=1.0, last_state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]))\n",
      "ExperienceFirstLast(state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]), action=0, reward=1.0, last_state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]))\n",
      "ExperienceFirstLast(state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]), action=0, reward=1.0, last_state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]))\n",
      "ExperienceFirstLast(state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]), action=0, reward=1.0, last_state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]))\n",
      "ExperienceFirstLast(state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]), action=0, reward=1.0, last_state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]))\n",
      "ExperienceFirstLast(state=array([-0.06427906, -0.73496263,  0.04723616,  1.17286728]), action=0, reward=1.0, last_state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]))\n",
      "ExperienceFirstLast(state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]), action=0, reward=1.0, last_state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]))\n",
      "ExperienceFirstLast(state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]), action=0, reward=1.0, last_state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]))\n",
      "ExperienceFirstLast(state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]), action=0, reward=1.0, last_state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]))\n",
      "ExperienceFirstLast(state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]), action=0, reward=1.0, last_state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]))\n",
      "ExperienceFirstLast(state=array([-0.07897831, -0.93066572,  0.07069351,  1.47997674]), action=0, reward=1.0, last_state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]))\n",
      "ExperienceFirstLast(state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]), action=0, reward=1.0, last_state=array([-0.12012314, -1.32266817,  0.13617053,  2.11597167]))\n",
      "ExperienceFirstLast(state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]), action=0, reward=1.0, last_state=array([-0.12012314, -1.32266817,  0.13617053,  2.11597167]))\n",
      "ExperienceFirstLast(state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]), action=0, reward=1.0, last_state=array([-0.12012314, -1.32266817,  0.13617053,  2.11597167]))\n",
      "ExperienceFirstLast(state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]), action=0, reward=1.0, last_state=array([-0.12012314, -1.32266817,  0.13617053,  2.11597167]))\n",
      "ExperienceFirstLast(state=array([-0.09759162, -1.12657568,  0.10029304,  1.79387427]), action=0, reward=1.0, last_state=array([-0.12012314, -1.32266817,  0.13617053,  2.11597167]))\n",
      "ExperienceFirstLast(state=array([-0.12012314, -1.32266817,  0.13617053,  2.11597167]), action=0, reward=1.0, last_state=array([-0.1465765 , -1.51886144,  0.17848996,  2.44744788]))\n",
      "ExperienceFirstLast(state=array([-0.1465765 , -1.51886144,  0.17848996,  2.44744788]), action=0, reward=1.0, last_state=None)\n",
      "ExperienceFirstLast(state=array([-0.12012314, -1.32266817,  0.13617053,  2.11597167]), action=0, reward=1.0, last_state=array([-0.1465765 , -1.51886144,  0.17848996,  2.44744788]))\n",
      "ExperienceFirstLast(state=array([-0.1465765 , -1.51886144,  0.17848996,  2.44744788]), action=0, reward=1.0, last_state=None)\n"
     ]
    }
   ],
   "source": [
    "# envs=[gym.make('MountainCar-v0') for _ in range(5)]\n",
    "envs=[gym.make('CartPole-v1') for _ in range(5)]\n",
    "for e in envs:e.seed(0)\n",
    "class TestAgent(ptan.agent.BaseAgent):\n",
    "    def __call__(self,s,ss):return [0]*len(s),[0]*len(s)\n",
    "\n",
    "exp_src=ptan.experience.ExperienceSourceFirstLast(envs, TestAgent(), gamma=0.99, steps_count=1)\n",
    "# exp_src=ptan.experience.ExperienceSource(envs, TestAgent(), steps_count=1)\n",
    "\n",
    "for i,e in enumerate(exp_src):\n",
    "    print(e)\n",
    "    if i==38:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experience():\n",
    "    d:bool;s:np.ndarray;sp:np.ndarray;r:float;a:Any;eid:int=0;episode_r:float=0;absolute_end:bool=False\n",
    "                                    \n",
    "    def __repr__(self):return f'Experience({\",\".join([f\"{f.name}={getattr(self,f.name).numpy()}\" for f in fields(self)])})'\n",
    "    @classmethod\n",
    "    def from_batch(cls,b):\n",
    "        if isinstance(b,tuple):b=b[0]\n",
    "        bs=max(len(e) for e in b.values())\n",
    "        return L([cls(**{k:v[i] for k,v in b.items()}) for i in range(bs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#1) [Experience(d=False,s=[-0.04456399  0.04653909  0.01326909 -0.02099827],sp=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],r=1.0,a=0,eid=140362763841488,episode_r=1.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],sp=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],r=1.0,a=0,eid=140362763841488,episode_r=2.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],sp=[-0.05349009 -0.5394481   0.02981694  0.87096095],r=1.0,a=0,eid=140362763841488,episode_r=3.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.05349009 -0.5394481   0.02981694  0.87096095],sp=[-0.06427906 -0.73496263  0.04723616  1.17286728],r=1.0,a=0,eid=140362763841488,episode_r=4.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.06427906 -0.73496263  0.04723616  1.17286728],sp=[-0.07897831 -0.93066572  0.07069351  1.47997674],r=1.0,a=0,eid=140362763841488,episode_r=5.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.07897831 -0.93066572  0.07069351  1.47997674],sp=[-0.09759162 -1.12657568  0.10029304  1.79387427],r=1.0,a=0,eid=140362763841488,episode_r=6.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.09759162 -1.12657568  0.10029304  1.79387427],sp=[-0.12012314 -1.32266817  0.13617053  2.11597167],r=1.0,a=0,eid=140362763841488,episode_r=7.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.12012314 -1.32266817  0.13617053  2.11597167],sp=[-0.1465765  -1.51886144  0.17848996  2.44744788],r=1.0,a=0,eid=140362763841488,episode_r=8.0,absolute_end=False)]\n",
      "(#1) [Experience(d=True,s=[-0.1465765  -1.51886144  0.17848996  2.44744788],sp=[-0.17695373 -1.71499924  0.22743892  2.78917835],r=1.0,a=0,eid=140362763841488,episode_r=9.0,absolute_end=True)]\n",
      "(#1) [Experience(d=False,s=[-0.04456399  0.04653909  0.01326909 -0.02099827],sp=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],r=1.0,a=0,eid=140362763841488,episode_r=1.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],sp=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],r=1.0,a=0,eid=140362763841488,episode_r=2.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],sp=[-0.05349009 -0.5394481   0.02981694  0.87096095],r=1.0,a=0,eid=140362763841488,episode_r=3.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.05349009 -0.5394481   0.02981694  0.87096095],sp=[-0.06427906 -0.73496263  0.04723616  1.17286728],r=1.0,a=0,eid=140362763841488,episode_r=4.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.06427906 -0.73496263  0.04723616  1.17286728],sp=[-0.07897831 -0.93066572  0.07069351  1.47997674],r=1.0,a=0,eid=140362763841488,episode_r=5.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.07897831 -0.93066572  0.07069351  1.47997674],sp=[-0.09759162 -1.12657568  0.10029304  1.79387427],r=1.0,a=0,eid=140362763841488,episode_r=6.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.09759162 -1.12657568  0.10029304  1.79387427],sp=[-0.12012314 -1.32266817  0.13617053  2.11597167],r=1.0,a=0,eid=140362763841488,episode_r=7.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.12012314 -1.32266817  0.13617053  2.11597167],sp=[-0.1465765  -1.51886144  0.17848996  2.44744788],r=1.0,a=0,eid=140362763841488,episode_r=8.0,absolute_end=False)]\n",
      "(#1) [Experience(d=True,s=[-0.1465765  -1.51886144  0.17848996  2.44744788],sp=[-0.17695373 -1.71499924  0.22743892  2.78917835],r=1.0,a=0,eid=140362763841488,episode_r=9.0,absolute_end=True)]\n",
      "(#1) [Experience(d=False,s=[-0.04456399  0.04653909  0.01326909 -0.02099827],sp=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],r=1.0,a=0,eid=140362763841488,episode_r=1.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],sp=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],r=1.0,a=0,eid=140362763841488,episode_r=2.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],sp=[-0.05349009 -0.5394481   0.02981694  0.87096095],r=1.0,a=0,eid=140362763841488,episode_r=3.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.05349009 -0.5394481   0.02981694  0.87096095],sp=[-0.06427906 -0.73496263  0.04723616  1.17286728],r=1.0,a=0,eid=140362763841488,episode_r=4.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.06427906 -0.73496263  0.04723616  1.17286728],sp=[-0.07897831 -0.93066572  0.07069351  1.47997674],r=1.0,a=0,eid=140362763841488,episode_r=5.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.07897831 -0.93066572  0.07069351  1.47997674],sp=[-0.09759162 -1.12657568  0.10029304  1.79387427],r=1.0,a=0,eid=140362763841488,episode_r=6.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.09759162 -1.12657568  0.10029304  1.79387427],sp=[-0.12012314 -1.32266817  0.13617053  2.11597167],r=1.0,a=0,eid=140362763841488,episode_r=7.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.12012314 -1.32266817  0.13617053  2.11597167],sp=[-0.1465765  -1.51886144  0.17848996  2.44744788],r=1.0,a=0,eid=140362763841488,episode_r=8.0,absolute_end=False)]\n",
      "(#1) [Experience(d=True,s=[-0.1465765  -1.51886144  0.17848996  2.44744788],sp=[-0.17695373 -1.71499924  0.22743892  2.78917835],r=1.0,a=0,eid=140362763841488,episode_r=9.0,absolute_end=True)]\n",
      "(#1) [Experience(d=False,s=[-0.04456399  0.04653909  0.01326909 -0.02099827],sp=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],r=1.0,a=0,eid=140362763841488,episode_r=1.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],sp=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],r=1.0,a=0,eid=140362763841488,episode_r=2.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],sp=[-0.05349009 -0.5394481   0.02981694  0.87096095],r=1.0,a=0,eid=140362763841488,episode_r=3.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.05349009 -0.5394481   0.02981694  0.87096095],sp=[-0.06427906 -0.73496263  0.04723616  1.17286728],r=1.0,a=0,eid=140362763841488,episode_r=4.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.06427906 -0.73496263  0.04723616  1.17286728],sp=[-0.07897831 -0.93066572  0.07069351  1.47997674],r=1.0,a=0,eid=140362763841488,episode_r=5.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.07897831 -0.93066572  0.07069351  1.47997674],sp=[-0.09759162 -1.12657568  0.10029304  1.79387427],r=1.0,a=0,eid=140362763841488,episode_r=6.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.09759162 -1.12657568  0.10029304  1.79387427],sp=[-0.12012314 -1.32266817  0.13617053  2.11597167],r=1.0,a=0,eid=140362763841488,episode_r=7.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.12012314 -1.32266817  0.13617053  2.11597167],sp=[-0.1465765  -1.51886144  0.17848996  2.44744788],r=1.0,a=0,eid=140362763841488,episode_r=8.0,absolute_end=False)]\n",
      "(#1) [Experience(d=True,s=[-0.1465765  -1.51886144  0.17848996  2.44744788],sp=[-0.17695373 -1.71499924  0.22743892  2.78917835],r=1.0,a=0,eid=140362763841488,episode_r=9.0,absolute_end=True)]\n",
      "(#1) [Experience(d=False,s=[-0.04456399  0.04653909  0.01326909 -0.02099827],sp=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],r=1.0,a=0,eid=140362763841488,episode_r=1.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04363321 -0.14877061  0.01284913  0.2758415 ],sp=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],r=1.0,a=0,eid=140362763841488,episode_r=2.0,absolute_end=False)]\n",
      "(#1) [Experience(d=False,s=[-0.04660862 -0.3440735   0.01836596  0.5725492 ],sp=[-0.05349009 -0.5394481   0.02981694  0.87096095],r=1.0,a=0,eid=140362763841488,episode_r=3.0,absolute_end=False)]\n"
     ]
    }
   ],
   "source": [
    "blk=IterableDataBlock(blocks=(ExperienceBlock(n_steps=1,steps_delta=1,a=0,seed=0)),\n",
    "            splitter=FuncSplitter(lambda x:False))\n",
    "\n",
    "dls=blk.dataloaders(['CartPole-v1']*1,bs=1,num_workers=0,verbose=False,\n",
    "                      indexed=True,shuffle_train=False)\n",
    "for i,x in enumerate(dls[0]):\n",
    "    print(Experience.from_batch(x))\n",
    "    if i==38:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "@delegates(ResetAndStepTfm)\n",
    "def test_block(n_steps=1,steps_delta=1,block=ExperienceBlock,**kwargs):\n",
    "    for env in ['MountainCar-v0','CartPole-v1']:\n",
    "        blk=IterableDataBlock(blocks=(block(n_steps=n_steps,steps_delta=steps_delta,**kwargs)),\n",
    "                    splitter=FuncSplitter(lambda x:False))\n",
    "\n",
    "        dls=blk.dataloaders([env]*5,bs=1,num_workers=0,verbose=False,\n",
    "                              indexed=True,shuffle_train=False)\n",
    "\n",
    "\n",
    "        states={\n",
    "            'MountainCar-v0':['tensor([[-0.5891,  0.0000]], dtype=torch.float64)','tensor([[-0.7105,  0.0043]], dtype=torch.float64)'],\n",
    "            'CartPole-v1':['tensor([[-0.0446,  0.0465,  0.0133, -0.0210]], dtype=torch.float64)',\n",
    "                           'tensor([[-0.1770, -1.7150,  0.2274,  2.7892]], dtype=torch.float64)']\n",
    "        }\n",
    "\n",
    "        print('Starting Iteration')\n",
    "        counter=0\n",
    "        counters=[]\n",
    "        for epoch in range(3):\n",
    "            dones=0\n",
    "            for x in dls[0]:\n",
    "#                 print('\\nResult',x)\n",
    "                if counter==0 and steps_delta==0: test_eq(str(x[0]['s']),states[env][0])\n",
    "                if x[0]['d']:\n",
    "#                     print(len(dls[0]),dones)\n",
    "                    dones+=1\n",
    "                    if dones==n_steps:\n",
    "                        test_eq(str(x[0]['sp']),states[env][1])\n",
    "                        print(counter)\n",
    "                        # TODO(Josiah): Figure out why this differs between runs.\n",
    "                        if env=='MountainCar-v0':test_eq(counter,pytest.approx(200*n_steps-n_steps*(0+1),10))\n",
    "                        counters.append(counter)\n",
    "                        counter=0\n",
    "                else:\n",
    "                    counter+=1\n",
    "            test_ne(counters[-1],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all defaults work as expected. That an episode completes, and that the expected final state gets reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Iteration\n",
      "199\n",
      "199\n",
      "199\n",
      "Starting Iteration\n",
      "8\n",
      "445\n",
      "445\n"
     ]
    }
   ],
   "source": [
    "test_block(a=0,seed=0,n_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Iteration\n",
      "594\n",
      "597\n",
      "597\n",
      "Starting Iteration\n",
      "21\n",
      "1314\n",
      "1314\n"
     ]
    }
   ],
   "source": [
    "test_block(a=0,seed=0,n_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Iteration\n",
      "199\n",
      "590\n",
      "590\n",
      "Starting Iteration\n",
      "9\n",
      "1125\n",
      "1125\n"
     ]
    }
   ],
   "source": [
    "test_block(a=0,seed=0,n_steps=3,steps_delta=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class FirstLastTfm(Transform):\n",
    "    def __init__(self,discount=0.99):self.discount=discount\n",
    "    \n",
    "    def reset(self,items):\n",
    "        if items.extra_len!=0:items.extra_len=0\n",
    "    \n",
    "    def encodes(self,o):\n",
    "        first_o=o[0]\n",
    "        first_o.sp=o[-1].sp\n",
    "        total_reward=first_o.r\n",
    "        elms=list(o)[:-1]\n",
    "\n",
    "        for exp in reversed(elms):\n",
    "            total_reward*=self.discount\n",
    "            total_reward+=exp.r\n",
    "        first_o.r=total_reward\n",
    "        return asdict(first_o)\n",
    "\n",
    "\n",
    "@delegates(ResetAndStepTfm)\n",
    "def FirstLastExperienceBlock(dls_kwargs=None,**kwargs):\n",
    "    return TransformBlock(type_tfms=[MakeTfm(),ResetAndStepTfm(hist2dict=False,**kwargs),FirstLastTfm],dl_type=TfmdSourceDL,dls_kwargs=dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Iteration\n",
      "\n",
      "Result ((tensor([[-0.5891,  0.0000]], dtype=torch.float64), {'d': tensor([False]), 's': tensor([[-0.5891,  0.0000]], dtype=torch.float64), 'sp': tensor([[-0.5922, -0.0015]], dtype=torch.float64), 'r': tensor([-2.9701], dtype=torch.float64), 'a': tensor([0]), 'eid': tensor([140262333237328]), 'episode_r': tensor([-1.], dtype=torch.float64), 'absolute_end': tensor([False])}),)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c3f194ea713e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mcounter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mtest_ne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mfl_test_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-c3f194ea713e>\u001b[0m in \u001b[0;36mfl_test_block\u001b[0;34m(n_steps, block, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nResult'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#                     print(len(dls[0]),dones)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "@delegates(ResetAndStepTfm)\n",
    "def fl_test_block(n_steps,block=FirstLastExperienceBlock,**kwargs):\n",
    "    for env in ['MountainCar-v0','CartPole-v1']:\n",
    "        blk=IterableDataBlock(blocks=(block(n_steps=n_steps,**kwargs)),\n",
    "                    splitter=FuncSplitter(lambda x:False),batch_tfms=lambda x:(x['s'],x))\n",
    "\n",
    "        dls=blk.dataloaders([env]*5,bs=1,num_workers=0,verbose=False,\n",
    "                              indexed=True,shuffle_train=False)\n",
    "\n",
    "\n",
    "        states={\n",
    "            'MountainCar-v0':['tensor([[-0.5891,  0.0000]], dtype=torch.float64)','tensor([[-0.7105,  0.0043]], dtype=torch.float64)'],\n",
    "            'CartPole-v1':['tensor([[-0.0446,  0.0465,  0.0133, -0.0210]], dtype=torch.float64)',\n",
    "                           'tensor([[-0.1770, -1.7150,  0.2274,  2.7892]], dtype=torch.float64)']\n",
    "        }\n",
    "\n",
    "        print('Starting Iteration')\n",
    "        counter=0\n",
    "        counters=[]\n",
    "        for epoch in range(3):\n",
    "            dones=0\n",
    "            for x in dls[0]:\n",
    "                print('\\nResult',x)\n",
    "                if counter==0: test_eq(str(x[0]['s']),states[env][0])\n",
    "                if x[0]['d']:\n",
    "#                     print(len(dls[0]),dones)\n",
    "                    dones+=1\n",
    "                    test_eq(str(x[0]['sp']),states[env][1])\n",
    "#                     print(counter)\n",
    "                    # TODO(Josiah): Figure out why this differs between runs.\n",
    "                    if env=='MountainCar-v0':test_eq(counter,pytest.approx(200*n_steps-n_steps*(0+1),1))\n",
    "                    counters.append(counter)\n",
    "                    counter=0\n",
    "                else:\n",
    "                    counter+=1\n",
    "            test_ne(counters[-1],0)\n",
    "fl_test_block(a=0,seed=0,n_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_learner.ipynb.\n",
      "Converted 05a_data.ipynb.\n",
      "Converted 05b_async_data.ipynb.\n",
      "Converted 06_basic_train.ipynb.\n",
      "Converted 13_metrics.ipynb.\n",
      "Converted 14_actorcritic.sac.ipynb.\n",
      "Converted 15_actorcritic.a3c_data.ipynb.\n",
      "Converted 16_actorcritic.a2c.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: /opt/project/fastrl/nbs/05a_data.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()\n",
    "notebook2html(n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
