{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp a3c.a3c_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3C Data\n",
    "\n",
    "> A decoupled actor critic agent which trains on data collected from environments running in a completely separate process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# from fastai.basic_data import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callbacks import *\n",
    "from fastrl.wrappers import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.basic_train import *\n",
    "from fastrl.data_block import *\n",
    "from fastrl.metrics import *\n",
    "from fastai.basic_train import *\n",
    "from dataclasses import asdict\n",
    "from functools import partial\n",
    "from fastprogress.fastprogress import IN_NOTEBOOK\n",
    "from fastcore.utils import *\n",
    "import torch.multiprocessing as mp\n",
    "from queue import Empty\n",
    "import textwrap\n",
    "import logging\n",
    "import gym\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s line:%(lineno)d %(levelname)s - %(message)s',\n",
    "                    datefmt='%m-%d %H:%M:%S')\n",
    "_logger=logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "_logger.setLevel('INFO')\n",
    "from fastcore.foundation import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@safe_fit\n",
    "def a3c_data_fitter(model,agent,ds,data_queue,pause_event,\n",
    "                    cancel_event,metric_queue):\n",
    "    dataset=ds()\n",
    "    while not cancel_event.is_set():\n",
    "        for xb,yb in dataset:\n",
    "            data_queue.put(yb)\n",
    "            if pause_event.is_set():cancel_event.wait(0.1)\n",
    "            if cancel_event.is_set():break\n",
    "        if cancel_event.is_set():break\n",
    "        if metric_queue is not None:\n",
    "            rs=dataset.pop_total_r()\n",
    "            if len(rs)!=0:metric_queue.put(TotalRewards(np.mean(rs)))\n",
    "\n",
    "@dataclass\n",
    "class A3CLearner(AgentLearner):\n",
    "    fitter:Callable=a3c_data_fitter\n",
    "    batch_sz:int=100\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        super(A3CLearner,self).__post_init__()\n",
    "        if self.model is None:self.model=self.agent.model\n",
    "        if self.agent.model is None: self.agent.model=self.model\n",
    "        self.model.share_memory()\n",
    "        \n",
    "    def predict(self,s):\n",
    "        out=self.model(s)\n",
    "        if type(out)==tuple:return out[0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=[\n",
    " Experience(s=tensor([[-0.0285,  0.1640, -0.0033, -0.3421]]),sp=tensor([[-0.0285,  0.1640, -0.0033, -0.3421]]),\n",
    "            a=tensor([1]),r=tensor([1.]),d=tensor([0.]),agent_s=tensor([[[0.]]])),\n",
    " Experience(s=tensor([[-0.0252, -0.0311, -0.0101, -0.0504]]),sp=tensor([[-0.0252, -0.0311, -0.0101, -0.0504]]),\n",
    "            a=tensor([0]),r=tensor([1.]),d=tensor([0.]),agent_s=tensor([[[0.]]])),\n",
    " Experience(s=tensor([[-0.0258, -0.2261, -0.0111,  0.2391]]),sp=tensor([[-0.0258, -0.2261, -0.0111,  0.2391]]),\n",
    "            a=tensor([0]),r=tensor([1.]),d=tensor([0.]),agent_s=tensor([[[0.]]])),\n",
    " Experience(s=tensor([[-0.0517, -0.2260,  0.0195,  0.2377]]),sp=tensor([[-0.0517, -0.2260,  0.0195,  0.2377]]),\n",
    "            a=tensor([1]),r=tensor([1.]),d=tensor([0.]),agent_s=tensor([[[0.]]])),\n",
    " Experience(s=tensor([[-0.0562, -0.4214,  0.0242,  0.5365]]),sp=tensor([[-0.0562, -0.4214,  0.0242,  0.5365]]),\n",
    "            a=tensor([0]),r=tensor([1.]),d=tensor([0.]),agent_s=tensor([[[0.]]])),\n",
    " Experience(s=tensor([[-0.0647, -0.6169,  0.0349,  0.8367]]),sp=tensor([[-0.0647, -0.6169,  0.0349,  0.8367]]),\n",
    "            a=tensor([0]),r=tensor([1.]),d=tensor([1.]),agent_s=tensor([[[0.]]]))\n",
    "]\n",
    "class LinearA2C(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(LinearA2C, self).__init__()\n",
    "\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o=self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        fx=x.float()\n",
    "        return self.policy(fx),self.value(fx)\n",
    "model=LinearA2C((4,),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_estimate(s,r,d_mask,model,val_gamma,device):\n",
    "    \"Returns rewards `r` estimated direction by `model` from states `s`\"\n",
    "    r_np=np.array(r,dtype=np.float32)\n",
    "    if d_mask:\n",
    "        s_v=torch.FloatTensor(s).to(device)\n",
    "        v=model(s_v)[1] # Remember that models are going to return the actions and the values\n",
    "        v_np=v.data.cpu().numpy()[:,0]\n",
    "        r_np[d_mask]+=val_gamma*v_np\n",
    "    return r_np\n",
    "\n",
    "def unbatch(batch,model,last_val_gamma,device='cpu')->Tuple(List,List,List):\n",
    "    s,a,r,d_mask,sp=[],[],[],[],[]\n",
    "    for i,exp in enumerate(batch):\n",
    "        s.append(exp.s.numpy())\n",
    "        a.append(int(exp.a.numpy())) # TODO can we change this to toggle between discrete and continuous actions?\n",
    "        r.append(exp.r.numpy().astype(np.float32))\n",
    "        if int(exp.d)==0:\n",
    "            d_mask.append(i)\n",
    "            sp.append(exp.sp.numpy())\n",
    "    s_t=torch.FloatTensor(s).to(device)\n",
    "    a_t=torch.LongTensor(a).to(device)\n",
    "    \n",
    "    r_np=r_estimate(sp,r,d_mask,model,last_val_gamma,device)\n",
    "    estimated_r=torch.FloatTensor(r_np).to(device)\n",
    "    return s_t,a_t,estimated_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0285,  0.1640, -0.0033, -0.3421]],\n",
       " \n",
       "         [[-0.0252, -0.0311, -0.0101, -0.0504]],\n",
       " \n",
       "         [[-0.0258, -0.2261, -0.0111,  0.2391]],\n",
       " \n",
       "         [[-0.0517, -0.2260,  0.0195,  0.2377]],\n",
       " \n",
       "         [[-0.0562, -0.4214,  0.0242,  0.5365]],\n",
       " \n",
       "         [[-0.0647, -0.6169,  0.0349,  0.8367]]]),\n",
       " tensor([1, 0, 0, 1, 0, 0]),\n",
       " tensor([[1.2883],\n",
       "         [1.2978],\n",
       "         [1.3391],\n",
       "         [1.3321],\n",
       "         [1.3981],\n",
       "         [1.0000]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbatch(batch,model,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class A3CTrainer(LearnerCallback):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super(A3CTrainer,self).__init__(*args,**kwargs)\n",
    "        self.batch=[]\n",
    "    \n",
    "    def on_train_begin(self,**kwargs):\n",
    "        self.batch.clear()\n",
    "    \n",
    "    def on_batch_begin(self,last_target,**kwargs):\n",
    "        self.batch.extend([Experience(**o) for o in last_target])\n",
    "        if len(self.batch)<self.learn.batch_sz:return\n",
    "        \n",
    "    def on_backward_begin(self,*args,**kwargs): return {'skip_bwd':True,'skip_validate':True}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_reward</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytest\n",
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',display=False,firstlast=True,add_valid=False,max_steps=100,n_processes=1,n_envs=1)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=PolicyAgent(model=model)\n",
    "learn=A3CLearner(data,model,agent=agent,callback_fns=[A3CTrainer,RewardMetric],loss_func=fake_loss)\n",
    "learn.fit(3,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_reward</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',display=False,firstlast=False,add_valid=False,max_steps=50,n_processes=1,n_envs=1)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=PolicyAgent(model=model)\n",
    "learn=A3CLearner(data,model,agent=agent,callback_fns=[A3CTrainer,RewardMetric],loss_func=fake_loss)\n",
    "learn.fit(10,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 02_callbacks.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted 05_data_block.ipynb.\n",
      "Converted 06_basic_train.ipynb.\n",
      "Converted 12_a3c.a3c_data.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted notes.ipynb.\n",
      "converting: /opt/project/fastrl/nbs/12_a3c.a3c_data.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/jupyter_client/manager.py:358: FutureWarning: Method cleanup(connection_file=True) is deprecated, use cleanup_resources(restart=False).\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: /opt/project/fastrl/nbs/05_data_block.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()\n",
    "notebook2html(n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
