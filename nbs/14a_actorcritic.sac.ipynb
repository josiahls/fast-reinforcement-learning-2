{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp actorcritic.sac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn.utils as nn_utils\n",
    "from fastai.torch_basics import *\n",
    "import torch.nn.functional as F\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "import torch.multiprocessing as mp\n",
    "from torch.optim import *\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from fastrl.data import *\n",
    "from fastrl.async_data import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.learner import *\n",
    "from fastrl.metrics import *\n",
    "from fastai.callback.progress import *\n",
    "from fastrl.ptan_extension import *\n",
    "\n",
    "from torch.distributions import *\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAC\n",
    "\n",
    "> Soft Actor Critic\n",
    "\n",
    "Most of the code pre-refactor is thanks to: https://github.com/pranz24/pytorch-soft-actor-critic/blob/master/LICENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Initialize Policy weights\n",
    "def weights_init_(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_dim):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "\n",
    "        # Q1 architecture\n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Q2 architecture\n",
    "        self.linear4 = nn.Linear(num_inputs + num_actions, hidden_dim)\n",
    "        self.linear5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear6 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        xu = torch.cat([state.float(), action.float()], 1)\n",
    "\n",
    "        x1 = F.relu(self.linear1(xu))\n",
    "        x1 = F.relu(self.linear2(x1))\n",
    "        x1 = self.linear3(x1)\n",
    "\n",
    "        x2 = F.relu(self.linear4(xu))\n",
    "        x2 = F.relu(self.linear5(x2))\n",
    "        x2 = self.linear6(x2)\n",
    "\n",
    "        return x1, x2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_dim, action_space=None):\n",
    "        super(GaussianPolicy, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.mean_linear = nn.Linear(hidden_dim, num_actions)\n",
    "        self.log_std_linear = nn.Linear(hidden_dim, num_actions)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "        # action rescaling\n",
    "        if action_space is None:\n",
    "            self.action_scale = torch.tensor(1.)\n",
    "            self.action_bias = torch.tensor(0.)\n",
    "        else:\n",
    "            self.action_scale = torch.FloatTensor(\n",
    "                (action_space.high - action_space.low) / 2.)\n",
    "            self.action_bias = torch.FloatTensor(\n",
    "                (action_space.high + action_space.low) / 2.)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mean = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, min=LOG_SIG_MIN, max=LOG_SIG_MAX)\n",
    "        return mean, log_std\n",
    "\n",
    "    def sample(self, state):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        normal = Normal(mean, std)\n",
    "        x_t = normal.rsample()  # for reparameterization trick (mean + std * N(0,1))\n",
    "        y_t = torch.tanh(x_t)\n",
    "        action = y_t * self.action_scale + self.action_bias\n",
    "        log_prob = normal.log_prob(x_t)\n",
    "        # Enforcing Action Bound\n",
    "        log_prob -= torch.log(self.action_scale * (1 - y_t.pow(2)) + epsilon)\n",
    "        log_prob = log_prob.sum(1, keepdim=True)\n",
    "        mean = torch.tanh(mean) * self.action_scale + self.action_bias\n",
    "        return action, log_prob, mean\n",
    "\n",
    "    def to(self, device):\n",
    "        self.action_scale = self.action_scale.to(device)\n",
    "        self.action_bias = self.action_bias.to(device)\n",
    "        return super(GaussianPolicy, self).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DeterministicPolicy(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_dim, action_space=None):\n",
    "        super(DeterministicPolicy, self).__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.mean = nn.Linear(hidden_dim, num_actions)\n",
    "        self.noise = torch.Tensor(num_actions)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "        # action rescaling\n",
    "        if action_space is None:\n",
    "            self.action_scale = 1.\n",
    "            self.action_bias = 0.\n",
    "        else:\n",
    "            self.action_scale = torch.FloatTensor(\n",
    "                (action_space.high - action_space.low) / 2.)\n",
    "            self.action_bias = torch.FloatTensor(\n",
    "                (action_space.high + action_space.low) / 2.)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mean = torch.tanh(self.mean(x)) * self.action_scale + self.action_bias\n",
    "        return mean\n",
    "\n",
    "    def sample(self, state):\n",
    "        mean = self.forward(state)\n",
    "        noise = self.noise.normal_(0., std=0.1)\n",
    "        noise = noise.clamp(-0.25, 0.25)\n",
    "        action = mean + noise\n",
    "        return action, torch.tensor(0.), mean\n",
    "\n",
    "    def to(self, device):\n",
    "        self.action_scale = self.action_scale.to(device)\n",
    "        self.action_bias = self.action_bias.to(device)\n",
    "        self.noise = self.noise.to(device)\n",
    "        return super(DeterministicPolicy, self).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_log_gaussian(mean, log_std, t):\n",
    "    quadratic = -((0.5 * (t - mean) / (log_std.exp())).pow(2))\n",
    "    l = mean.shape\n",
    "    log_z = log_std\n",
    "    z = l[-1] * math.log(2 * math.pi)\n",
    "    log_p = quadratic.sum(dim=-1) - log_z.sum(dim=-1) - 0.5 * z\n",
    "    return log_p\n",
    "\n",
    "def logsumexp(inputs, dim=None, keepdim=False):\n",
    "    if dim is None:\n",
    "        inputs = inputs.view(-1)\n",
    "        dim = 0\n",
    "    s, _ = torch.max(inputs, dim=dim, keepdim=True)\n",
    "    outputs = s + (inputs - s).exp().sum(dim=dim, keepdim=True).log()\n",
    "    if not keepdim:\n",
    "        outputs = outputs.squeeze(dim)\n",
    "    return outputs\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from pprint import pprint\n",
    "\n",
    "class SAC(BaseAgent):\n",
    "    def __init__(self, num_inputs, action_space,gamma=0.99,tau=0.005,alpha=0.2,policy='gaussian',\n",
    "                automatic_entropy_tuning=True,target_update_interval=1,hidden_size=100,lr=0.0003):\n",
    "        \n",
    "        self.action_space=action_space\n",
    "        self.warming_up=False\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.policy_type = policy\n",
    "        self.target_update_interval = target_update_interval\n",
    "        self.automatic_entropy_tuning = automatic_entropy_tuning\n",
    "\n",
    "        self.device=default_device()\n",
    "        \n",
    "        # qf\n",
    "        self.critic = QNetwork(num_inputs, action_space.shape[0], hidden_size).to(device=self.device)\n",
    "        self.critic_optim = Adam(self.critic.parameters(), lr=lr)\n",
    "\n",
    "        self.critic_target = QNetwork(num_inputs, action_space.shape[0], hidden_size).to(self.device)\n",
    "        hard_update(self.critic_target, self.critic)\n",
    "\n",
    "        if self.policy_type == \"gaussian\":\n",
    "            # Target Entropy = ‚àídim(A) (e.g. , -6 for HalfCheetah-v2) as given in the paper\n",
    "            if self.automatic_entropy_tuning is True:\n",
    "                self.target_entropy = -torch.prod(torch.Tensor(action_space.shape).to(self.device)).item()\n",
    "                self.log_alpha = torch.zeros(1, requires_grad=True, device=self.device)\n",
    "                self.alpha_optim = Adam([self.log_alpha], lr=lr)\n",
    "\n",
    "            self.policy = GaussianPolicy(num_inputs, action_space.shape[0], hidden_size, action_space).to(self.device)\n",
    "            self.policy_optim = Adam(self.policy.parameters(), lr=lr)\n",
    "\n",
    "        else:\n",
    "            self.alpha = 0\n",
    "            self.automatic_entropy_tuning = False\n",
    "            self.policy = DeterministicPolicy(num_inputs, action_space.shape[0], hidden_size, action_space).to(self.device)\n",
    "            self.policy_optim = Adam(self.policy.parameters(), lr=lr)\n",
    "            \n",
    "        self.updates=0\n",
    "\n",
    "    def select_action(self, state, evaluate=False):\n",
    "        if self.warming_up: return self.action_space.sample()\n",
    "        state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "        if evaluate is False:\n",
    "            action, _, _ = self.policy.sample(state)\n",
    "        else:\n",
    "            _, _, action = self.policy.sample(state)\n",
    "        return action.detach().cpu().numpy()[0]\n",
    "    \n",
    "    def __call__(self,s,asl):\n",
    "        action,asl= self.select_action(s),asl\n",
    "        if len(action.shape)==1: action=action.reshape(1,-1)\n",
    "        return action,asl\n",
    "\n",
    "    def update_parameters(self, *yb, learn):\n",
    "        # Sample a batch from memory\n",
    "#         state_batch, action_batch, reward_batch, next_state_batch, mask_batch = learn.memory.sample(batch_size=batch_size)\n",
    "        batch=learn.sample_yb\n",
    "#         pprint(batch)\n",
    "        state_batch=torch.stack([o.state.to(device=default_device()) for o in batch]).float()\n",
    "        next_state_batch=torch.stack([o.last_state.to(device=default_device()) for o in batch]).float()\n",
    "        action_batch=torch.stack([o.action.to(device=default_device()) for o in batch]).float()\n",
    "        reward_batch=torch.stack([o.reward.to(device=default_device()) for o in batch]).float().unsqueeze(1)\n",
    "        mask_batch=torch.stack([o.done.to(device=default_device()) for o in batch]).float().unsqueeze(1)\n",
    "        \n",
    "#         print(state_batch.shape,next_state_batch.shape,action_batch.shape,reward_batch.shape,mask_batch.shape)\n",
    "#         state_batch = torch.FloatTensor(state_batch).to(self.device)\n",
    "#         next_state_batch = torch.FloatTensor(next_state_batch).to(self.device)\n",
    "#         action_batch = torch.FloatTensor(action_batch).to(self.device)\n",
    "#         reward_batch = torch.FloatTensor(reward_batch).to(self.device).unsqueeze(1)\n",
    "#         mask_batch = torch.FloatTensor(mask_batch).to(self.device).unsqueeze(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_state_action, next_state_log_pi, _ = self.policy.sample(next_state_batch)\n",
    "            qf1_next_target, qf2_next_target = self.critic_target(next_state_batch, next_state_action)\n",
    "            min_qf_next_target = torch.min(qf1_next_target, qf2_next_target) - self.alpha * next_state_log_pi\n",
    "            next_q_value = reward_batch + (1-mask_batch) * self.gamma * (min_qf_next_target)\n",
    "        qf1, qf2 = self.critic(state_batch, action_batch)  # Two Q-functions to mitigate positive bias in the policy improvement step\n",
    "        qf1_loss = F.mse_loss(qf1, next_q_value)  # JQ = ùîº(st,at)~D[0.5(Q1(st,at) - r(st,at) - Œ≥(ùîºst+1~p[V(st+1)]))^2]\n",
    "        qf2_loss = F.mse_loss(qf2, next_q_value)  # JQ = ùîº(st,at)~D[0.5(Q1(st,at) - r(st,at) - Œ≥(ùîºst+1~p[V(st+1)]))^2]\n",
    "        qf_loss = qf1_loss + qf2_loss\n",
    "\n",
    "        self.critic_optim.zero_grad()\n",
    "        qf_loss.backward()\n",
    "        self.critic_optim.step()\n",
    "\n",
    "        pi, log_pi, _ = self.policy.sample(state_batch)\n",
    "\n",
    "        qf1_pi, qf2_pi = self.critic(state_batch, pi)\n",
    "        min_qf_pi = torch.min(qf1_pi, qf2_pi)\n",
    "\n",
    "        policy_loss = ((self.alpha * log_pi) - min_qf_pi).mean() # JœÄ = ùîºst‚àºD,Œµt‚àºN[Œ± * logœÄ(f(Œµt;st)|st) ‚àí Q(st,f(Œµt;st))]\n",
    "\n",
    "        self.policy_optim.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.policy_optim.step()\n",
    "\n",
    "        if self.automatic_entropy_tuning:\n",
    "            alpha_loss = -(self.log_alpha * (log_pi + self.target_entropy).detach()).mean()\n",
    "\n",
    "            self.alpha_optim.zero_grad()\n",
    "            alpha_loss.backward()\n",
    "            self.alpha_optim.step()\n",
    "\n",
    "            self.alpha = self.log_alpha.exp()\n",
    "            alpha_tlogs = self.alpha.clone() # For TensorboardX logs\n",
    "        else:\n",
    "            alpha_loss = torch.tensor(0.).to(self.device)\n",
    "            alpha_tlogs = torch.tensor(self.alpha) # For TensorboardX logs\n",
    "\n",
    "\n",
    "        if self.updates % self.target_update_interval == 0:\n",
    "            soft_update(self.critic_target, self.critic, self.tau)\n",
    "        self.updates+=1\n",
    "#         print(self.updates)\n",
    "\n",
    "        return qf1_loss+ qf2_loss+ policy_loss+ alpha_loss+ alpha_tlogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplay(Callback):\n",
    "    def __init__(self,sz=100,bs=128,starting_els=1,max_steps=1):\n",
    "        store_attr()\n",
    "        self.queue=deque(maxlen=int(sz))\n",
    "        self.max_steps=max_steps\n",
    "        \n",
    "    def before_fit(self):\n",
    "        self.learn.agent.warming_up=True\n",
    "        while len(self.queue)<self.starting_els:\n",
    "            for i,o in enumerate(self.dls.train):\n",
    "                batch=[ExperienceFirstLast(state=o[0][i],action=o[1][i],reward=o[2][i],\n",
    "                                    last_state=o[3][i], done=(o[4][i] and self.max_steps!=o[6][i]),episode_reward=o[5][i],steps=o[6][i])\n",
    "                                    for i in range(len(o[0]))]\n",
    "#                 print(self.max_steps,max([o.steps for o in batch]))\n",
    "                for _b in batch: self.queue.append(_b)\n",
    "                if len(self.queue)>self.starting_els:break\n",
    "        self.learn.agent.warming_up=False\n",
    "\n",
    "#     def after_epoch(self):\n",
    "#         print(len(self.queue))\n",
    "    def before_batch(self):\n",
    "#         print(len(self.queue))\n",
    "        b=list(self.learn.xb)+list(self.learn.yb)\n",
    "        batch=[ExperienceFirstLast(state=b[0][i],action=b[1][i],reward=b[2][i],\n",
    "                                last_state=b[3][i], done=(b[4][i] and self.max_steps!=b[6][i]),episode_reward=b[5][i],\n",
    "                                steps=b[6][i])\n",
    "                                for i in range(len(b[0]))]\n",
    "        for _b in batch: self.queue.append(_b)\n",
    "        idxs=np.random.randint(0,len(self.queue), self.bs)\n",
    "        self.learn.sample_yb=[self.queue[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SACCriticTrainer(Callback):\n",
    "    def after_batch(self): \n",
    "        self.learn.dls.bs=1\n",
    "        for d in self.learn.dls.loaders: d.bs=1\n",
    "        \n",
    "    def after_loss(self):raise CancelBatchException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "LOG_SIG_MAX = 2\n",
    "LOG_SIG_MIN = -20\n",
    "epsilon = 1e-6\n",
    "\n",
    "class SACLearner(AgentLearner):\n",
    "    def __init__(self,dls,agent=None,reward_scale=2,**kwargs):\n",
    "        store_attr()\n",
    "#         print(type(self.agent))\n",
    "        super().__init__(dls,agent=agent,\n",
    "                         loss_func=partial(self.agent.update_parameters,learn=self),\n",
    "                         model=agent.policy,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_avg_episode_r</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_avg_episode_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>120.603119</td>\n",
       "      <td>0</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.9422, -0.3350,  0.9308]], dtype=torch.float64),) (tensor([[-1.5522]]), tensor([-15.5913], dtype=torch.float64), tensor([[-0.9259, -0.3779,  0.4724]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([3]))\n",
      "(tensor([[-0.9345, -0.3559,  0.4467]], dtype=torch.float64),) (tensor([[1.9507]]), tensor([-15.2719], dtype=torch.float64), tensor([[-0.9256, -0.3786,  0.0150]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([4]))\n",
      "(tensor([[-0.9259, -0.3779,  0.4724]], dtype=torch.float64),) (tensor([[-1.1597]]), tensor([-15.1137], dtype=torch.float64), tensor([[-0.9310, -0.3649, -0.2945]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([5]))\n",
      "(tensor([[-0.9256, -0.3786,  0.0150]], dtype=torch.float64),) (tensor([[-0.1708]]), tensor([-15.1768], dtype=torch.float64), tensor([[-0.9444, -0.3288, -0.7705]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([6]))\n",
      "(tensor([[-0.9310, -0.3649, -0.2945]], dtype=torch.float64),) (tensor([[-1.3488]]), tensor([-15.5322], dtype=torch.float64), tensor([[-0.9633, -0.2685, -1.2644]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([7]))\n",
      "(tensor([[-0.9444, -0.3288, -0.7705]], dtype=torch.float64),) (tensor([[-1.6486]]), tensor([-16.2521], dtype=torch.float64), tensor([[-0.9821, -0.1883, -1.6463]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([8]))\n",
      "(tensor([[-0.9633, -0.2685, -1.2644]], dtype=torch.float64),) (tensor([[-1.2039]]), tensor([-17.2942], dtype=torch.float64), tensor([[-0.9957, -0.0925, -1.9369]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([9]))\n",
      "(tensor([[-0.9821, -0.1883, -1.6463]], dtype=torch.float64),) (tensor([[-0.9955]]), tensor([-18.5643], dtype=torch.float64), tensor([[-0.9998,  0.0201, -2.2540]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([10]))\n",
      "(tensor([[-0.9957, -0.0925, -1.9369]], dtype=torch.float64),) (tensor([[-1.6517]]), tensor([-19.8269], dtype=torch.float64), tensor([[-0.9930,  0.1178, -1.9604]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([11]))\n",
      "(tensor([[-0.9998,  0.0201, -2.2540]], dtype=torch.float64),) (tensor([[1.8570]]), tensor([-19.6866], dtype=torch.float64), tensor([[-0.9765,  0.2156, -1.9852]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([12]))\n",
      "(tensor([[-0.9930,  0.1178, -1.9604]], dtype=torch.float64),) (tensor([[-0.7541]]), tensor([-18.3855], dtype=torch.float64), tensor([[-0.9486,  0.3165, -2.0929]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([13]))\n",
      "(tensor([[-0.9765,  0.2156, -1.9852]], dtype=torch.float64),) (tensor([[-1.7964]]), tensor([-17.2561], dtype=torch.float64), tensor([[-0.9096,  0.4156, -2.1316]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([14]))\n",
      "(tensor([[-0.9486,  0.3165, -2.0929]], dtype=torch.float64),) (tensor([[-1.8404]]), tensor([-16.1304], dtype=torch.float64), tensor([[-0.8624,  0.5062, -2.0428]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([15]))\n",
      "(tensor([[-0.9096,  0.4156, -2.1316]], dtype=torch.float64),) (tensor([[-1.4858]]), tensor([-14.9817], dtype=torch.float64), tensor([[-0.8098,  0.5867, -1.9251]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([16]))\n",
      "(tensor([[-0.8624,  0.5062, -2.0428]], dtype=torch.float64),) (tensor([[-1.7458]]), tensor([-13.8664], dtype=torch.float64), tensor([[-0.7564,  0.6541, -1.7206]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([17]))\n",
      "(tensor([[-0.8098,  0.5867, -1.9251]], dtype=torch.float64),) (tensor([[-1.5703]]), tensor([-12.8315], dtype=torch.float64), tensor([[-0.7056,  0.7086, -1.4897]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([18]))\n",
      "(tensor([[-0.7564,  0.6541, -1.7206]], dtype=torch.float64),) (tensor([[-1.7316]]), tensor([-11.9052], dtype=torch.float64), tensor([[-0.6787,  0.7344, -0.7470]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([19]))\n",
      "(tensor([[-0.7056,  0.7086, -1.4897]], dtype=torch.float64),) (tensor([[1.4084]]), tensor([-11.1355], dtype=torch.float64), tensor([[-0.6766,  0.7363, -0.0563]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([20]))\n",
      "(tensor([[-0.6787,  0.7344, -0.7470]], dtype=torch.float64),) (tensor([[0.9329]]), tensor([-10.7255], dtype=torch.float64), tensor([[-0.6912,  0.7226,  0.4006]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([21]))\n",
      "(tensor([[-0.6766,  0.7363, -0.0563]], dtype=torch.float64),) (tensor([[-0.6359]]), tensor([-10.7667], dtype=torch.float64), tensor([[-0.7332,  0.6800,  1.1960]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([22]))\n",
      "(tensor([[-0.6912,  0.7226,  0.4006]], dtype=torch.float64),) (tensor([[1.6893]]), tensor([-11.2814], dtype=torch.float64), tensor([[-0.7922,  0.6103,  1.8283]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([23]))\n",
      "(tensor([[-0.7332,  0.6800,  1.1960]], dtype=torch.float64),) (tensor([[0.8154]]), tensor([-12.3193], dtype=torch.float64), tensor([[-0.8582,  0.5134,  2.3463]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([24]))\n",
      "(tensor([[-0.7922,  0.6103,  1.8283]], dtype=torch.float64),) (tensor([[0.4021]]), tensor([-13.7615], dtype=torch.float64), tensor([[-0.9224,  0.3862,  2.8509]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([25]))\n",
      "(tensor([[-0.8582,  0.5134,  2.3463]], dtype=torch.float64),) (tensor([[0.7970]]), tensor([-15.5888], dtype=torch.float64), tensor([[-0.9708,  0.2397,  3.0892]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([26]))\n",
      "(tensor([[-0.9224,  0.3862,  2.8509]], dtype=torch.float64),) (tensor([[-0.3422]]), tensor([-17.6165], dtype=torch.float64), tensor([[-0.9973,  0.0734,  3.3734]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([27]))\n",
      "(tensor([[-0.9708,  0.2397,  3.0892]], dtype=torch.float64),) (tensor([[0.6960]]), tensor([-19.8087], dtype=torch.float64), tensor([[-0.9957, -0.0921,  3.3136]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([28]))\n",
      "(tensor([[-0.9973,  0.0734,  3.3734]], dtype=torch.float64),) (tensor([[-0.7660]]), tensor([-20.8456], dtype=torch.float64), tensor([[-0.9695, -0.2451,  3.1064]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([29]))\n",
      "(tensor([[-0.9957, -0.0921,  3.3136]], dtype=torch.float64),) (tensor([[-0.9206]]), tensor([-19.6442], dtype=torch.float64), tensor([[-0.9226, -0.3857,  2.9685]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([30]))\n",
      "(tensor([[-0.9695, -0.2451,  3.1064]], dtype=torch.float64),) (tensor([[0.3060]]), tensor([-17.6756], dtype=torch.float64), tensor([[-0.8631, -0.5050,  2.6672]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([31]))\n",
      "(tensor([[-0.9226, -0.3857,  2.9685]], dtype=torch.float64),) (tensor([[-0.0802]]), tensor([-15.8802], dtype=torch.float64), tensor([[-0.8043, -0.5942,  2.1382]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([32]))\n",
      "(tensor([[-0.8631, -0.5050,  2.6672]], dtype=torch.float64),) (tensor([[-1.0015]]), tensor([-14.2046], dtype=torch.float64), tensor([[-0.7581, -0.6521,  1.4814]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([33]))\n",
      "(tensor([[-0.8043, -0.5942,  2.1382]], dtype=torch.float64),) (tensor([[-1.4073]]), tensor([-12.8064], dtype=torch.float64), tensor([[-0.7186, -0.6954,  1.1726]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([34]))\n",
      "(tensor([[-0.7581, -0.6521,  1.4814]], dtype=torch.float64),) (tensor([[1.2015]]), tensor([-11.8411], dtype=torch.float64), tensor([[-0.6942, -0.7198,  0.6907]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([35]))\n",
      "(tensor([[-0.7186, -0.6954,  1.1726]], dtype=torch.float64),) (tensor([[0.2643]]), tensor([-11.2261], dtype=torch.float64), tensor([[-0.6878, -0.7259,  0.1774]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([36]))\n",
      "(tensor([[-0.6942, -0.7198,  0.6907]], dtype=torch.float64),) (tensor([[0.1769]]), tensor([-10.8912], dtype=torch.float64), tensor([[-0.6920, -0.7219, -0.1163]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([37]))\n",
      "(tensor([[-0.6878, -0.7259,  0.1774]], dtype=torch.float64),) (tensor([[1.6718]]), tensor([-10.8329], dtype=torch.float64), tensor([[-0.7069, -0.7073, -0.4170]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([38]))\n",
      "(tensor([[-0.6920, -0.7219, -0.1163]], dtype=torch.float64),) (tensor([[1.6050]]), tensor([-10.9691], dtype=torch.float64), tensor([[-0.7347, -0.6784, -0.8033]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([39]))\n",
      "(tensor([[-0.7069, -0.7073, -0.4170]], dtype=torch.float64),) (tensor([[0.9613]]), tensor([-11.3161], dtype=torch.float64), tensor([[-0.7793, -0.6266, -1.3673]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([40]))\n",
      "(tensor([[-0.7347, -0.6784, -0.8033]], dtype=torch.float64),) (tensor([[-0.3682]]), tensor([-12.0049], dtype=torch.float64), tensor([[-0.8283, -0.5603, -1.6490]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([41]))\n",
      "(tensor([[-0.7793, -0.6266, -1.3673]], dtype=torch.float64),) (tensor([[1.2549]]), tensor([-12.9531], dtype=torch.float64), tensor([[-0.8793, -0.4764, -1.9646]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([42]))\n",
      "(tensor([[-0.8283, -0.5603, -1.6490]], dtype=torch.float64),) (tensor([[0.6978]]), tensor([-14.0682], dtype=torch.float64), tensor([[-0.9308, -0.3656, -2.4454]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([43]))\n",
      "(tensor([[-0.8793, -0.4764, -1.9646]], dtype=torch.float64),) (tensor([[-0.8238]]), tensor([-15.5576], dtype=torch.float64), tensor([[-0.9734, -0.2292, -2.8598]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([44]))\n",
      "(tensor([[-0.9308, -0.3656, -2.4454]], dtype=torch.float64),) (tensor([[-0.9351]]), tensor([-17.4539], dtype=torch.float64), tensor([[-0.9960, -0.0894, -2.8350]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([45]))\n",
      "(tensor([[-0.9734, -0.2292, -2.8598]], dtype=torch.float64),) (tensor([[1.3115]]), tensor([-19.3076], dtype=torch.float64), tensor([[-0.9983,  0.0579, -2.9484]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([46]))\n",
      "(tensor([[-0.9960, -0.0894, -2.8350]], dtype=torch.float64),) (tensor([[-0.3091]]), tensor([-20.3960], dtype=torch.float64), tensor([[-0.9817,  0.1905, -2.6747]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([47]))\n",
      "(tensor([[-0.9983,  0.0579, -2.9484]], dtype=torch.float64),) (tensor([[1.5351]]), tensor([-19.7043], dtype=torch.float64), tensor([[-0.9511,  0.3088, -2.4463]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([48]))\n",
      "(tensor([[-0.9817,  0.1905, -2.6747]], dtype=torch.float64),) (tensor([[0.5701]]), tensor([-17.9265], dtype=torch.float64), tensor([[-0.9138,  0.4062, -2.0856]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([49]))\n",
      "(tensor([[-0.9511,  0.3088, -2.4463]], dtype=torch.float64),) (tensor([[0.8607]]), tensor([-16.3681], dtype=torch.float64), tensor([[-0.8715,  0.4904, -1.8868]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([50]))\n",
      "(tensor([[-0.9138,  0.4062, -2.0856]], dtype=torch.float64),) (tensor([[-0.7054]]), tensor([-15.0471], dtype=torch.float64), tensor([[-0.8329,  0.5534, -1.4774]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([51]))\n",
      "(tensor([[-0.8715,  0.4904, -1.8868]], dtype=torch.float64),) (tensor([[0.2769]]), tensor([-13.9504], dtype=torch.float64), tensor([[-0.8104,  0.5859, -0.7903]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([52]))\n",
      "(tensor([[-0.8329,  0.5534, -1.4774]], dtype=torch.float64),) (tensor([[1.8138]]), tensor([-13.0771], dtype=torch.float64), tensor([[-0.8003,  0.5996, -0.3397]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([53]))\n",
      "(tensor([[-0.8104,  0.5859, -0.7903]], dtype=torch.float64),) (tensor([[0.0743]]), tensor([-12.5861], dtype=torch.float64), tensor([[-0.8115,  0.5844,  0.3777]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([54]))\n",
      "(tensor([[-0.8003,  0.5996, -0.3397]], dtype=torch.float64),) (tensor([[1.7848]]), tensor([-12.5465], dtype=torch.float64), tensor([[-0.8339,  0.5519,  0.7889]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([55]))\n",
      "(tensor([[-0.8115,  0.5844,  0.3777]], dtype=torch.float64),) (tensor([[-0.1799]]), tensor([-12.8896], dtype=torch.float64), tensor([[-0.8723,  0.4890,  1.4730]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([56]))\n",
      "(tensor([[-0.8339,  0.5519,  0.7889]], dtype=torch.float64),) (tensor([[1.8007]]), tensor([-13.6706], dtype=torch.float64), tensor([[-0.9098,  0.4150,  1.6611]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([57]))\n",
      "(tensor([[-0.8723,  0.4890,  1.4730]], dtype=torch.float64),) (tensor([[-1.1911]]), tensor([-14.7026], dtype=torch.float64), tensor([[-0.9482,  0.3178,  2.0904]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([58]))\n",
      "(tensor([[-0.9098,  0.4150,  1.6611]], dtype=torch.float64),) (tensor([[0.7868]]), tensor([-15.9358], dtype=torch.float64), tensor([[-0.9789,  0.2046,  2.3479]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([59]))\n",
      "(tensor([[-0.9482,  0.3178,  2.0904]], dtype=torch.float64),) (tensor([[0.1276]]), tensor([-17.4600], dtype=torch.float64), tensor([[-0.9978,  0.0663,  2.7940]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([60]))\n",
      "(tensor([[-0.9789,  0.2046,  2.3479]], dtype=torch.float64),) (tensor([[1.9516]]), tensor([-19.3094], dtype=torch.float64), tensor([[-0.9977, -0.0675,  2.6771]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([61]))\n",
      "(tensor([[-0.9978,  0.0663,  2.7940]], dtype=torch.float64),) (tensor([[-1.1110]]), tensor([-20.3058], dtype=torch.float64), tensor([[-0.9823, -0.1876,  2.4232]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([62]))\n",
      "(tensor([[-0.9977, -0.0675,  2.6771]], dtype=torch.float64),) (tensor([[-1.3549]]), tensor([-19.3842], dtype=torch.float64), tensor([[-0.9577, -0.2877,  2.0621]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([63]))\n",
      "(tensor([[-0.9823, -0.1876,  2.4232]], dtype=torch.float64),) (tensor([[-1.4697]]), tensor([-17.7736], dtype=torch.float64), tensor([[-0.9324, -0.3615,  1.5620]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([64]))\n",
      "(tensor([[-0.9577, -0.2877,  2.0621]], dtype=torch.float64),) (tensor([[-1.8957]]), tensor([-16.3977], dtype=torch.float64), tensor([[-0.9047, -0.4260,  1.4044]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([65]))\n",
      "(tensor([[-0.9324, -0.3615,  1.5620]], dtype=torch.float64),) (tensor([[0.7573]]), tensor([-15.3471], dtype=torch.float64), tensor([[-0.8806, -0.4739,  1.0730]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([66]))\n",
      "(tensor([[-0.9047, -0.4260,  1.4044]], dtype=torch.float64),) (tensor([[-0.0793]]), tensor([-14.5519], dtype=torch.float64), tensor([[-0.8578, -0.5140,  0.9221]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([67]))\n",
      "(tensor([[-0.8806, -0.4739,  1.0730]], dtype=torch.float64),) (tensor([[1.3639]]), tensor([-13.9168], dtype=torch.float64), tensor([[-0.8362, -0.5485,  0.8130]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([68]))\n",
      "(tensor([[-0.8578, -0.5140,  0.9221]], dtype=torch.float64),) (tensor([[1.8426]]), tensor([-13.4173], dtype=torch.float64), tensor([[-0.8291, -0.5591,  0.2558]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([69]))\n",
      "(tensor([[-0.8362, -0.5485,  0.8130]], dtype=torch.float64),) (tensor([[-0.9721]]), tensor([-13.0616], dtype=torch.float64), tensor([[-0.8321, -0.5546, -0.1077]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([70]))\n",
      "(tensor([[-0.8291, -0.5591,  0.2558]], dtype=torch.float64),) (tensor([[0.3717]]), tensor([-12.9587], dtype=torch.float64), tensor([[-0.8422, -0.5392, -0.3680]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([71]))\n",
      "(tensor([[-0.8321, -0.5546, -0.1077]], dtype=torch.float64),) (tensor([[1.0385]]), tensor([-13.0886], dtype=torch.float64), tensor([[-0.8682, -0.4963, -1.0045]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([72]))\n",
      "(tensor([[-0.8422, -0.5392, -0.3680]], dtype=torch.float64),) (tensor([[-1.5477]]), tensor([-13.5406], dtype=torch.float64), tensor([[-0.9044, -0.4268, -1.5677]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([73]))\n",
      "(tensor([[-0.8682, -0.4963, -1.0045]], dtype=torch.float64),) (tensor([[-1.2734]]), tensor([-14.4445], dtype=torch.float64), tensor([[-0.9436, -0.3311, -2.0686]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([74]))\n",
      "(tensor([[-0.9044, -0.4268, -1.5677]], dtype=torch.float64),) (tensor([[-1.2053]]), tensor([-15.7506], dtype=torch.float64), tensor([[-0.9776, -0.2103, -2.5114]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([75]))\n",
      "(tensor([[-0.9436, -0.3311, -2.0686]], dtype=torch.float64),) (tensor([[-1.2964]]), tensor([-17.4150], dtype=torch.float64), tensor([[-0.9964, -0.0849, -2.5392]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([76]))\n",
      "(tensor([[-0.9776, -0.2103, -2.5114]], dtype=torch.float64),) (tensor([[0.8664]]), tensor([-19.1036], dtype=torch.float64), tensor([[-0.9993,  0.0369, -2.4382]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([77]))\n",
      "(tensor([[-0.9964, -0.0849, -2.5392]], dtype=torch.float64),) (tensor([[1.0977]]), tensor([-20.1199], dtype=torch.float64), tensor([[-0.9876,  0.1572, -2.4183]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([78]))\n",
      "(tensor([[-0.9993,  0.0369, -2.4382]], dtype=torch.float64),) (tensor([[-0.0524]]), tensor([-19.6259], dtype=torch.float64), tensor([[-0.9622,  0.2723, -2.3590]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([79]))\n",
      "(tensor([[-0.9876,  0.1572, -2.4183]], dtype=torch.float64),) (tensor([[-0.3904]]), tensor([-18.1698], dtype=torch.float64), tensor([[-0.9248,  0.3805, -2.2911]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([80]))\n",
      "(tensor([[-0.9622,  0.2723, -2.3590]], dtype=torch.float64),) (tensor([[-0.9090]]), tensor([-16.7839], dtype=torch.float64), tensor([[-0.8851,  0.4654, -1.8749]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([81]))\n",
      "(tensor([[-0.9248,  0.3805, -2.2911]], dtype=torch.float64),) (tensor([[0.8717]]), tensor([-15.4366], dtype=torch.float64), tensor([[-0.8528,  0.5222, -1.3061]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([82]))\n",
      "(tensor([[-0.8851,  0.4654, -1.8749]], dtype=torch.float64),) (tensor([[1.4651]]), tensor([-14.2370], dtype=torch.float64), tensor([[-0.8267,  0.5626, -0.9617]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([83]))\n",
      "(tensor([[-0.8528,  0.5222, -1.3061]], dtype=torch.float64),) (tensor([[-0.3151]]), tensor([-13.3903], dtype=torch.float64), tensor([[-0.8156,  0.5785, -0.3889]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([84]))\n",
      "(tensor([[-0.8267,  0.5626, -0.9617]], dtype=torch.float64),) (tensor([[1.0057]]), tensor([-12.8913], dtype=torch.float64), tensor([[-0.8144,  0.5804, -0.0448]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([85]))\n",
      "(tensor([[-0.8156,  0.5785, -0.3889]], dtype=torch.float64),) (tensor([[-0.5988]]), tensor([-12.6897], dtype=torch.float64), tensor([[-0.8207,  0.5713,  0.2215]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([86]))\n",
      "(tensor([[-0.8144,  0.5804, -0.0448]], dtype=torch.float64),) (tensor([[-1.1266]]), tensor([-12.7269], dtype=torch.float64), tensor([[-0.8467,  0.5321,  0.9398]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([87]))\n",
      "(tensor([[-0.8207,  0.5713,  0.2215]], dtype=torch.float64),) (tensor([[1.9321]]), tensor([-13.1101], dtype=torch.float64), tensor([[-0.8868,  0.4622,  1.6131]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([88]))\n",
      "(tensor([[-0.8467,  0.5321,  0.9398]], dtype=torch.float64),) (tensor([[1.8283]]), tensor([-14.0203], dtype=torch.float64), tensor([[-0.9244,  0.3815,  1.7817]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([89]))\n",
      "(tensor([[-0.8868,  0.4622,  1.6131]], dtype=torch.float64),) (tensor([[-1.1873]]), tensor([-15.1467], dtype=torch.float64), tensor([[-0.9611,  0.2761,  2.2320]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([90]))\n",
      "(tensor([[-0.9244,  0.3815,  1.7817]], dtype=torch.float64),) (tensor([[1.0945]]), tensor([-16.4845], dtype=torch.float64), tensor([[-0.9887,  0.1499,  2.5863]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([91]))\n",
      "(tensor([[-0.9611,  0.2761,  2.2320]], dtype=torch.float64),) (tensor([[0.9814]]), tensor([-18.2087], dtype=torch.float64), tensor([[-0.9999,  0.0136,  2.7372]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([92]))\n",
      "(tensor([[-0.9887,  0.1499,  2.5863]], dtype=torch.float64),) (tensor([[0.2566]]), tensor([-20.0456], dtype=torch.float64), tensor([[-0.9935, -0.1137,  2.5515]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([93]))\n",
      "(tensor([[-0.9999,  0.0136,  2.7372]], dtype=torch.float64),) (tensor([[-1.3064]]), tensor([-20.2546], dtype=torch.float64), tensor([[-0.9716, -0.2367,  2.4995]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([94]))\n",
      "(tensor([[-0.9935, -0.1137,  2.5515]], dtype=torch.float64),) (tensor([[0.2219]]), tensor([-18.7783], dtype=torch.float64), tensor([[-0.9403, -0.3402,  2.1644]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([95]))\n",
      "(tensor([[-0.9716, -0.2367,  2.4995]], dtype=torch.float64),) (tensor([[-1.0502]]), tensor([-17.2466], dtype=torch.float64), tensor([[-0.9009, -0.4341,  2.0370]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([96]))\n",
      "(tensor([[-0.9403, -0.3402,  2.1644]], dtype=torch.float64),) (tensor([[0.8518]]), tensor([-15.8667], dtype=torch.float64), tensor([[-0.8583, -0.5131,  1.7955]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([97]))\n",
      "(tensor([[-0.9009, -0.4341,  2.0370]], dtype=torch.float64),) (tensor([[0.5605]]), tensor([-14.6948], dtype=torch.float64), tensor([[-0.8280, -0.5607,  1.1300]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([98]))\n",
      "(tensor([[-0.8583, -0.5131,  1.7955]], dtype=torch.float64),) (tensor([[-1.8714]]), tensor([-13.6482], dtype=torch.float64), tensor([[-0.8007, -0.5991,  0.9422]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([99]))\n",
      "(tensor([[-0.8280, -0.5607,  1.1300]], dtype=torch.float64),) (tensor([[1.5518]]), tensor([-12.8853], dtype=torch.float64), tensor([[-0.7870, -0.6170,  0.4501]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([100]))\n",
      "(tensor([[-0.8007, -0.5991,  0.9422]], dtype=torch.float64),) (tensor([[-0.2853]]), tensor([-12.4295], dtype=torch.float64), tensor([[-0.7938, -0.6082, -0.2229]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([101]))\n",
      "(tensor([[-0.7870, -0.6170,  0.4501]], dtype=torch.float64),) (tensor([[-1.4019]]), tensor([-12.2886], dtype=torch.float64), tensor([[-0.8135, -0.5815, -0.6635]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([102]))\n",
      "(tensor([[-0.7938, -0.6082, -0.2229]], dtype=torch.float64),) (tensor([[0.1034]]), tensor([-12.5302], dtype=torch.float64), tensor([[-0.8463, -0.5327, -1.1761]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([103]))\n",
      "(tensor([[-0.8135, -0.5815, -0.6635]], dtype=torch.float64),) (tensor([[-0.5096]]), tensor([-13.1280], dtype=torch.float64), tensor([[-0.8802, -0.4745, -1.3469]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([104]))\n",
      "(tensor([[-0.8463, -0.5327, -1.1761]], dtype=torch.float64),) (tensor([[1.5246]]), tensor([-13.9168], dtype=torch.float64), tensor([[-0.9116, -0.4110, -1.4179]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([105]))\n",
      "(tensor([[-0.8802, -0.4745, -1.3469]], dtype=torch.float64),) (tensor([[1.8998]]), tensor([-14.7059], dtype=torch.float64), tensor([[-0.9423, -0.3349, -1.6406]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([106]))\n",
      "(tensor([[-0.9116, -0.4110, -1.4179]], dtype=torch.float64),) (tensor([[0.5699]]), tensor([-15.6180], dtype=torch.float64), tensor([[-0.9704, -0.2414, -1.9543]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([107]))\n",
      "(tensor([[-0.9423, -0.3349, -1.6406]], dtype=torch.float64),) (tensor([[-0.4170]]), tensor([-16.8019], dtype=torch.float64), tensor([[-0.9898, -0.1422, -2.0227]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([108]))\n",
      "(tensor([[-0.9704, -0.2414, -1.9543]], dtype=torch.float64),) (tensor([[0.7513]]), tensor([-18.0892], dtype=torch.float64), tensor([[-0.9995, -0.0305, -2.2426]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([109]))\n",
      "(tensor([[-0.9898, -0.1422, -2.0227]], dtype=torch.float64),) (tensor([[-0.7556]]), tensor([-19.4837], dtype=torch.float64), tensor([[-0.9962,  0.0876, -2.3649]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([110]))\n",
      "(tensor([[-0.9995, -0.0305, -2.2426]], dtype=torch.float64),) (tensor([[-0.6625]]), tensor([-19.9696], dtype=torch.float64), tensor([[-0.9780,  0.2084, -2.4451]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([111]))\n",
      "(tensor([[-0.9962,  0.0876, -2.3649]], dtype=torch.float64),) (tensor([[-0.9727]]), tensor([-18.9867], dtype=torch.float64), tensor([[-0.9487,  0.3163, -2.2371]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([112]))\n",
      "(tensor([[-0.9780,  0.2084, -2.4451]], dtype=torch.float64),) (tensor([[0.3440]]), tensor([-17.5610], dtype=torch.float64), tensor([[-0.9083,  0.4184, -2.1974]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([113]))\n",
      "(tensor([[-0.9487,  0.3163, -2.2371]], dtype=torch.float64),) (tensor([[-1.3168]]), tensor([-16.2014], dtype=torch.float64), tensor([[-0.8639,  0.5036, -1.9214]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([114]))\n",
      "(tensor([[-0.9083,  0.4184, -2.1974]], dtype=torch.float64),) (tensor([[-0.2522]]), tensor([-14.9559], dtype=torch.float64), tensor([[-0.8248,  0.5654, -1.4628]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([115]))\n",
      "(tensor([[-0.8639,  0.5036, -1.9214]], dtype=torch.float64),) (tensor([[0.5393]]), tensor([-13.8051], dtype=torch.float64), tensor([[-0.7995,  0.6006, -0.8673]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([116]))\n",
      "(tensor([[-0.8248,  0.5654, -1.4628]], dtype=torch.float64),) (tensor([[1.1434]]), tensor([-12.9191], dtype=torch.float64), tensor([[-0.7850,  0.6195, -0.4760]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([117]))\n",
      "(tensor([[-0.7995,  0.6006, -0.8673]], dtype=torch.float64),) (tensor([[-0.3951]]), tensor([-12.3942], dtype=torch.float64), tensor([[-0.7925,  0.6099,  0.2436]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([118]))\n",
      "(tensor([[-0.7850,  0.6195, -0.4760]], dtype=torch.float64),) (tensor([[1.7004]]), tensor([-12.2669], dtype=torch.float64), tensor([[-0.8105,  0.5857,  0.6036]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([119]))\n",
      "(tensor([[-0.7925,  0.6099,  0.2436]], dtype=torch.float64),) (tensor([[-0.6498]]), tensor([-12.4877], dtype=torch.float64), tensor([[-0.8374,  0.5466,  0.9482]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([120]))\n",
      "(tensor([[-0.8105,  0.5857,  0.6036]], dtype=torch.float64),) (tensor([[-0.6308]]), tensor([-12.9608], dtype=torch.float64), tensor([[-0.8757,  0.4829,  1.4873]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([121]))\n",
      "(tensor([[-0.8374,  0.5466,  0.9482]], dtype=torch.float64),) (tensor([[0.8608]]), tensor([-13.7676], dtype=torch.float64), tensor([[-0.9163,  0.4005,  1.8378]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([122]))\n",
      "(tensor([[-0.8757,  0.4829,  1.4873]], dtype=torch.float64),) (tensor([[-0.0777]]), tensor([-14.8887], dtype=torch.float64), tensor([[-0.9528,  0.3036,  2.0723]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([123]))\n",
      "(tensor([[-0.9163,  0.4005,  1.8378]], dtype=torch.float64),) (tensor([[-0.4391]]), tensor([-16.1622], dtype=torch.float64), tensor([[-0.9835,  0.1809,  2.5312]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([124]))\n",
      "(tensor([[-0.9528,  0.3036,  2.0723]], dtype=torch.float64),) (tensor([[1.5412]]), tensor([-17.7650], dtype=torch.float64), tensor([[-0.9988,  0.0483,  2.6719]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([125]))\n",
      "(tensor([[-0.9835,  0.1809,  2.5312]], dtype=torch.float64),) (tensor([[0.0340]]), tensor([-19.5811], dtype=torch.float64), tensor([[-0.9955, -0.0946,  2.8609]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([126]))\n",
      "(tensor([[-0.9988,  0.0483,  2.6719]], dtype=torch.float64),) (tensor([[1.0183]]), tensor([-20.2854], dtype=torch.float64), tensor([[-0.9707, -0.2403,  2.9590]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([127]))\n",
      "(tensor([[-0.9955, -0.0946,  2.8609]], dtype=torch.float64),) (tensor([[1.1270]]), tensor([-19.2898], dtype=torch.float64), tensor([[-0.9263, -0.3768,  2.8737]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([128]))\n",
      "(tensor([[-0.9707, -0.2403,  2.9590]], dtype=torch.float64),) (tensor([[0.6329]]), tensor([-17.6127], dtype=torch.float64), tensor([[-0.8676, -0.4972,  2.6792]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([129]))\n",
      "(tensor([[-0.9263, -0.3768,  2.8737]], dtype=torch.float64),) (tensor([[0.5875]]), tensor([-15.9302], dtype=torch.float64), tensor([[-0.8053, -0.5929,  2.2855]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([130]))\n",
      "(tensor([[-0.8676, -0.4972,  2.6792]], dtype=torch.float64),) (tensor([[-0.1390]]), tensor([-14.3283], dtype=torch.float64), tensor([[-0.7445, -0.6676,  1.9265]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([131]))\n",
      "(tensor([[-0.8053, -0.5929,  2.2855]], dtype=torch.float64),) (tensor([[0.5712]]), tensor([-12.9294], dtype=torch.float64), tensor([[-0.6890, -0.7247,  1.5943]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([132]))\n",
      "(tensor([[-0.7445, -0.6676,  1.9265]], dtype=torch.float64),) (tensor([[1.1231]]), tensor([-11.8162], dtype=torch.float64), tensor([[-0.6581, -0.7529,  0.8369]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([133]))\n",
      "(tensor([[-0.6890, -0.7247,  1.5943]], dtype=torch.float64),) (tensor([[-1.4256]]), tensor([-10.9467], dtype=torch.float64), tensor([[-0.6447, -0.7644,  0.3527]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([134]))\n",
      "(tensor([[-0.6581, -0.7529,  0.8369]], dtype=torch.float64),) (tensor([[0.5366]]), tensor([-10.4306], dtype=torch.float64), tensor([[-0.6538, -0.7566, -0.2393]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([135]))\n",
      "(tensor([[-0.6447, -0.7644,  0.3527]], dtype=torch.float64),) (tensor([[-0.1243]]), tensor([-10.3400], dtype=torch.float64), tensor([[-0.6872, -0.7264, -0.9011]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([136]))\n",
      "(tensor([[-0.6538, -0.7566, -0.2393]], dtype=torch.float64),) (tensor([[-0.6287]]), tensor([-10.6682], dtype=torch.float64), tensor([[-0.7366, -0.6764, -1.4062]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([137]))\n",
      "(tensor([[-0.6872, -0.7264, -0.9011]], dtype=torch.float64),) (tensor([[0.2646]]), tensor([-11.3956], dtype=torch.float64), tensor([[-0.7990, -0.6014, -1.9517]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([138]))\n",
      "(tensor([[-0.7366, -0.6764, -1.4062]], dtype=torch.float64),) (tensor([[-0.2546]]), tensor([-12.4987], dtype=torch.float64), tensor([[-0.8657, -0.5005, -2.4212]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([139]))\n",
      "(tensor([[-0.7990, -0.6014, -1.9517]], dtype=torch.float64),) (tensor([[-0.1235]]), tensor([-13.9772], dtype=torch.float64), tensor([[-0.9305, -0.3663, -2.9832]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([140]))\n",
      "(tensor([[-0.8657, -0.5005, -2.4212]], dtype=torch.float64),) (tensor([[-1.2441]]), tensor([-15.8978], dtype=torch.float64), tensor([[-0.9764, -0.2159, -3.1485]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([141]))\n",
      "(tensor([[-0.9305, -0.3663, -2.9832]], dtype=torch.float64),) (tensor([[0.7293]]), tensor([-17.9922], dtype=torch.float64), tensor([[-0.9981, -0.0622, -3.1062]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([142]))\n",
      "(tensor([[-0.9764, -0.2159, -3.1485]], dtype=torch.float64),) (tensor([[1.3610]]), tensor([-19.8858], dtype=torch.float64), tensor([[-0.9956,  0.0939, -3.1258]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([143]))\n",
      "(tensor([[-0.9981, -0.0622, -3.1062]], dtype=torch.float64),) (tensor([[0.1805]]), tensor([-20.6099], dtype=torch.float64), tensor([[-0.9712,  0.2383, -2.9319]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([144]))\n",
      "(tensor([[-0.9956,  0.0939, -3.1258]], dtype=torch.float64),) (tensor([[0.8237]]), tensor([-19.4484], dtype=torch.float64), tensor([[-0.9271,  0.3748, -2.8705]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([145]))\n",
      "(tensor([[-0.9712,  0.2383, -2.9319]], dtype=torch.float64),) (tensor([[-0.7822]]), tensor([-17.6190], dtype=torch.float64), tensor([[-0.8710,  0.4913, -2.5892]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([146]))\n",
      "(tensor([[-0.9271,  0.3748, -2.8705]], dtype=torch.float64),) (tensor([[0.0012]]), tensor([-15.9284], dtype=torch.float64), tensor([[-0.8112,  0.5847, -2.2184]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([147]))\n",
      "(tensor([[-0.8710,  0.4913, -2.5892]], dtype=torch.float64),) (tensor([[0.0153]]), tensor([-14.3362], dtype=torch.float64), tensor([[-0.7560,  0.6546, -1.7824]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([148]))\n",
      "(tensor([[-0.8112,  0.5847, -2.2184]], dtype=torch.float64),) (tensor([[-0.0170]]), tensor([-12.9782], dtype=torch.float64), tensor([[-0.7127,  0.7015, -1.2774]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([149]))\n",
      "(tensor([[-0.7560,  0.6546, -1.7824]], dtype=torch.float64),) (tensor([[0.0942]]), tensor([-11.9079], dtype=torch.float64), tensor([[-0.6908,  0.7231, -0.6145]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([150]))\n",
      "(tensor([[-0.7127,  0.7015, -1.2774]], dtype=torch.float64),) (tensor([[0.9113]]), tensor([-11.1824], dtype=torch.float64), tensor([[-0.6960,  0.7181,  0.1445]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([151]))\n",
      "(tensor([[-0.6908,  0.7231, -0.6145]], dtype=torch.float64),) (tensor([[1.4448]]), tensor([-10.9100], dtype=torch.float64), tensor([[-0.7184,  0.6957,  0.6334]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([152]))\n",
      "(tensor([[-0.6960,  0.7181,  0.1445]], dtype=torch.float64),) (tensor([[-0.3309]]), tensor([-11.0926], dtype=torch.float64), tensor([[-0.7626,  0.6468,  1.3186]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([153]))\n",
      "(tensor([[-0.7184,  0.6957,  0.6334]], dtype=torch.float64),) (tensor([[1.0898]]), tensor([-11.7263], dtype=torch.float64), tensor([[-0.8169,  0.5768,  1.7717]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([154]))\n",
      "(tensor([[-0.7626,  0.6468,  1.3186]], dtype=torch.float64),) (tensor([[-0.2139]]), tensor([-12.7515], dtype=torch.float64), tensor([[-0.8798,  0.4754,  2.3895]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([155]))\n",
      "(tensor([[-0.8169,  0.5768,  1.7717]], dtype=torch.float64),) (tensor([[1.2345]]), tensor([-14.1977], dtype=torch.float64), tensor([[-0.9361,  0.3518,  2.7182]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([156]))\n",
      "(tensor([[-0.8798,  0.4754,  2.3895]], dtype=torch.float64),) (tensor([[-0.1853]]), tensor([-15.9680], dtype=torch.float64), tensor([[-0.9785,  0.2063,  3.0335]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([157]))\n",
      "(tensor([[-0.9361,  0.3518,  2.7182]], dtype=torch.float64),) (tensor([[0.3434]]), tensor([-17.9124], dtype=torch.float64), tensor([[-0.9992,  0.0410,  3.3357]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([158]))\n",
      "(tensor([[-0.9785,  0.2063,  3.0335]], dtype=torch.float64),) (tensor([[0.9834]]), tensor([-20.1484], dtype=torch.float64), tensor([[-0.9927, -0.1204,  3.2338]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([159]))\n",
      "(tensor([[-0.9992,  0.0410,  3.3357]], dtype=torch.float64),) (tensor([[-0.8847]]), tensor([-20.7971], dtype=torch.float64), tensor([[-0.9622, -0.2724,  3.1044]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([160]))\n",
      "(tensor([[-0.9927, -0.1204,  3.2338]], dtype=torch.float64),) (tensor([[-0.2601]]), tensor([-19.2564], dtype=torch.float64), tensor([[-0.9101, -0.4144,  3.0275]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([161]))\n",
      "(tensor([[-0.9622, -0.2724,  3.1044]], dtype=torch.float64),) (tensor([[0.8492]]), tensor([-17.3777], dtype=torch.float64), tensor([[-0.8454, -0.5341,  2.7223]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([162]))\n",
      "(tensor([[-0.9101, -0.4144,  3.0275]], dtype=torch.float64),) (tensor([[0.0376]]), tensor([-15.5988], dtype=torch.float64), tensor([[-0.7743, -0.6329,  2.4365]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([163]))\n",
      "(tensor([[-0.8454, -0.5341,  2.7223]], dtype=torch.float64),) (tensor([[0.7649]]), tensor([-13.9507], dtype=torch.float64), tensor([[-0.7035, -0.7107,  2.1052]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([164]))\n",
      "(tensor([[-0.7743, -0.6329,  2.4365]], dtype=torch.float64),) (tensor([[0.9559]]), tensor([-12.5401], dtype=torch.float64), tensor([[-0.6405, -0.7679,  1.7017]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([165]))\n",
      "(tensor([[-0.7035, -0.7107,  2.1052]], dtype=torch.float64),) (tensor([[0.8633]]), tensor([-11.3420], dtype=torch.float64), tensor([[-0.5935, -0.8049,  1.1974]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([166]))\n",
      "(tensor([[-0.6405, -0.7679,  1.7017]], dtype=torch.float64),) (tensor([[0.4778]]), tensor([-10.3857], dtype=torch.float64), tensor([[-0.5640, -0.8258,  0.7216]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([167]))\n",
      "(tensor([[-0.5935, -0.8049,  1.1974]], dtype=torch.float64),) (tensor([[0.8523]]), tensor([-9.7248], dtype=torch.float64), tensor([[-0.5584, -0.8295,  0.1351]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([168]))\n",
      "(tensor([[-0.5640, -0.8258,  0.7216]], dtype=torch.float64),) (tensor([[0.2184]]), tensor([-9.3981], dtype=torch.float64), tensor([[-0.5699, -0.8217, -0.2784]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([169]))\n",
      "(tensor([[-0.5584, -0.8295,  0.1351]], dtype=torch.float64),) (tensor([[1.3916]]), tensor([-9.3848], dtype=torch.float64), tensor([[-0.6106, -0.7920, -1.0066]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([170]))\n",
      "(tensor([[-0.5699, -0.8217, -0.2784]], dtype=torch.float64),) (tensor([[-0.7467]]), tensor([-9.7616], dtype=torch.float64), tensor([[-0.6750, -0.7379, -1.6829]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([171]))\n",
      "(tensor([[-0.6106, -0.7920, -1.0066]], dtype=torch.float64),) (tensor([[-0.5485]]), tensor([-10.6358], dtype=torch.float64), tensor([[-0.7474, -0.6644, -2.0650]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([172]))\n",
      "(tensor([[-0.6750, -0.7379, -1.6829]], dtype=torch.float64),) (tensor([[1.1417]]), tensor([-11.8259], dtype=torch.float64), tensor([[-0.8315, -0.5556, -2.7518]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([173]))\n",
      "(tensor([[-0.7474, -0.6644, -2.0650]], dtype=torch.float64),) (tensor([[-1.2565]]), tensor([-13.4600], dtype=torch.float64), tensor([[-0.9092, -0.4164, -3.1918]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([174]))\n",
      "(tensor([[-0.8315, -0.5556, -2.7518]], dtype=torch.float64),) (tensor([[-0.1558]]), tensor([-15.5634], dtype=torch.float64), tensor([[-0.9674, -0.2531, -3.4716]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([175]))\n",
      "(tensor([[-0.9092, -0.4164, -3.1918]], dtype=torch.float64),) (tensor([[0.2164]]), tensor([-17.8131], dtype=torch.float64), tensor([[-0.9980, -0.0639, -3.8382]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([176]))\n",
      "(tensor([[-0.9674, -0.2531, -3.4716]], dtype=torch.float64),) (tensor([[-1.1780]]), tensor([-20.3694], dtype=torch.float64), tensor([[-0.9916,  0.1292, -3.8703]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([177]))\n",
      "(tensor([[-0.9980, -0.0639, -3.8382]], dtype=torch.float64),) (tensor([[0.1054]]), tensor([-21.4102], dtype=torch.float64), tensor([[-0.9516,  0.3074, -3.6592]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([178]))\n",
      "(tensor([[-0.9916,  0.1292, -3.8703]], dtype=torch.float64),) (tensor([[0.7612]]), tensor([-19.8203], dtype=torch.float64), tensor([[-0.8855,  0.4647, -3.4164]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([179]))\n",
      "(tensor([[-0.9516,  0.3074, -3.6592]], dtype=torch.float64),) (tensor([[0.0815]]), tensor([-17.4941], dtype=torch.float64), tensor([[-0.8026,  0.5965, -3.1170]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([180]))\n",
      "(tensor([[-0.8855,  0.4647, -3.4164]], dtype=torch.float64),) (tensor([[-0.3276]]), tensor([-15.3953], dtype=torch.float64), tensor([[-0.7131,  0.7010, -2.7528]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([181]))\n",
      "(tensor([[-0.8026,  0.5965, -3.1170]], dtype=torch.float64),) (tensor([[-0.5546]]), tensor([-13.5206], dtype=torch.float64), tensor([[-0.6335,  0.7737, -2.1578]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([182]))\n",
      "(tensor([[-0.7131,  0.7010, -2.7528]], dtype=torch.float64),) (tensor([[0.4616]]), tensor([-11.8560], dtype=torch.float64), tensor([[-0.5799,  0.8147, -1.3485]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([183]))\n",
      "(tensor([[-0.6335,  0.7737, -2.1578]], dtype=torch.float64),) (tensor([[1.5265]]), tensor([-10.4879], dtype=torch.float64), tensor([[-0.5448,  0.8386, -0.8513]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([184]))\n",
      "(tensor([[-0.5799,  0.8147, -1.3485]], dtype=torch.float64),) (tensor([[-0.7586]]), tensor([-9.6111], dtype=torch.float64), tensor([[-0.5378,  0.8431, -0.1663]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([185]))\n",
      "(tensor([[-0.5448,  0.8386, -0.8513]], dtype=torch.float64),) (tensor([[0.3742]]), tensor([-9.2133], dtype=torch.float64), tensor([[-0.5637,  0.8260,  0.6206]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([186]))\n",
      "(tensor([[-0.5378,  0.8431, -0.1663]], dtype=torch.float64),) (tensor([[1.0299]]), tensor([-9.2770], dtype=torch.float64), tensor([[-0.6208,  0.7839,  1.4197]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([187]))\n",
      "(tensor([[-0.5637,  0.8260,  0.6206]], dtype=torch.float64),) (tensor([[1.1974]]), tensor([-9.9168], dtype=torch.float64), tensor([[-0.6953,  0.7187,  1.9802]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([188]))\n",
      "(tensor([[-0.6208,  0.7839,  1.4197]], dtype=torch.float64),) (tensor([[-0.1832]]), tensor([-11.0291], dtype=torch.float64), tensor([[-0.7814,  0.6240,  2.5616]], dtype=torch.float64), tensor([False]), tensor([0]), tensor([189]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-775f5c48a163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m learner=SACLearner(dls,agent=agent,cbs=[ExperienceReplay(sz=1000000,bs=64,starting_els=1000,max_steps=gym.make(env)._max_episode_steps),SACCriticTrainer],\n\u001b[1;32m     13\u001b[0m                    metrics=[AvgEpisodeRewardMetric(experience_cls=ExperienceFirstLast)])\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-802ee9451656>\u001b[0m in \u001b[0;36mupdate_parameters\u001b[0;34m(self, learn, *yb)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mpolicy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_pi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_qf_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# JœÄ = ùîºst‚àºD,Œµt‚àºN[Œ± * logœÄ(f(Œµt;st)|st) ‚àí Q(st,f(Œµt;st))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mpolicy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    189\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    951\u001b[0m                           \u001b[0;34m\"non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m                           \"github.com/pytorch/pytorch/pull/30531 for more informations.\", stacklevel=2)\n\u001b[0;32m--> 953\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# env='Pendulum-v0'\n",
    "from pybulletgym.envs import *\n",
    "\n",
    "env='InvertedPendulumPyBulletEnv-v0'\n",
    "agent=SAC(5,gym.make(env).action_space,gamma=0.99,tau=0.005,alpha=0.2)\n",
    "\n",
    "block=FirstLastExperienceBlock(agent=agent,seed=0,n_steps=2,exclude_nones=True,\n",
    "                               dls_kwargs={'bs':1,'num_workers':0,'verbose':False,'indexed':True,'shuffle_train':False})\n",
    "blk=IterableDataBlock(blocks=(block),\n",
    "                      splitter=FuncSplitter(lambda x:False),\n",
    "#                       batch_tfms=lambda x:(x['s'],x),\n",
    "                     )\n",
    "dls=blk.dataloaders([env]*1,n=1000,device=default_device())\n",
    "\n",
    "learner=SACLearner(dls,agent=agent,cbs=[ExperienceReplay(sz=1000000,bs=64,starting_els=1000,max_steps=gym.make(env)._max_episode_steps),SACCriticTrainer],\n",
    "                   metrics=[AvgEpisodeRewardMetric(experience_cls=ExperienceFirstLast)])\n",
    "learner.fit(30,lr=0.001,wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "from nbdev.export2html import *\n",
    "notebook2script()\n",
    "notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
