{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from dataclasses import field,asdict,fields\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Blocks\n",
    "\n",
    "> Iterable datasets for returning environment outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need `TfmdSourceDL` to trigger some cleanup before doing an iteration. \n",
    "\n",
    "TODO: (Josiah): Is there a way to override the `before_iter` in the DataBlock instead? The main issue is that we need to be able to reference `self` which isn't possible when passing methods through the `DataLoader` params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_single_nested_tuple(b):return isinstance(b,tuple) and len(b)==1 and isinstance(b[0],tuple)\n",
    "    \n",
    "class TfmdSourceDL(TfmdDL):\n",
    "    def before_iter(self):\n",
    "        super().before_iter()\n",
    "        self.dataset.reset_src()\n",
    "        \n",
    "    def create_item(self,b):\n",
    "        b=super().create_item(b)\n",
    "        return b[0] if is_single_nested_tuple(b) else b\n",
    "\n",
    "    def after_iter(self):\n",
    "        super().after_iter()\n",
    "        self.dataset.close_src()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TfmdSource` has an adjustable `__len__`. Unlike the `TfmdLists`, `TfmdSource` iters on a single item until the item raises a `SourceExhausted` exception. This means that the soruces `items` are being tracked by a separate index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SourceExhausted(Exception):pass\n",
    "\n",
    "@delegates(TfmdLists)\n",
    "class TfmdSource(TfmdLists):\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of sources called `items`. Only swtches between them if they get exhausted.\"\n",
    "    def __init__(self,items, tfms,n:int=None,cycle_srcs=True,verbose=False,**kwargs):\n",
    "        self.n=n;self.cycle_srcs=cycle_srcs;self.source_idx=0;self.verbose=verbose;self.res_buffer=deque([]);self.extra_len=0;self.n_exhausted_envs=0\n",
    "        super().__init__(items,tfms,**kwargs)\n",
    "#         store_attr('n,cycle_srcs', self) TODO (Josiah): Does not seem to work?\n",
    "    \n",
    "    def __enter__(self):                             self.cycle_srcs=False\n",
    "    def __exit__(self,exc_type,exc_value,traceback): self.cycle_srcs=True\n",
    "        \n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: Cycling sources: {self.cycle_srcs}\\n{self.items}\\ntfms - {self.tfms.fs}\"\n",
    "    def close_src(self):\n",
    "        [t.close(self) for t in self.tfms if hasattr(t,'close')]\n",
    "        self.res_buffer.clear()\n",
    "        \n",
    "    def reset_src(self): \n",
    "        [t.reset(self) for t in self.tfms if hasattr(t,'reset')]\n",
    "        print('clearing buffer: ',self.res_buffer)\n",
    "        self.res_buffer.clear()\n",
    "        \n",
    "    def setup(self,train_setup=True):super().setup(train_setup);self.reset_src()\n",
    "     \n",
    "    def __len__(self):\n",
    "#         return ifnone(self.n,super().__len__()) TODO (Josiah): self.n is not settable in DataBlock, and since TfmdLists gets reinit, this will not persist\n",
    "        if len(self.items)!=0 and isinstance(self.items[0],gym.Env) and self.cycle_srcs:\n",
    "            self.reset_src()\n",
    "            return self.items[0].spec.max_episode_steps+self.extra_len # TODO(Josiah): This is the only OpenAI dependent code. How do we have htis set in setup?\n",
    "        if self.n is not None: return self.n\n",
    "        if len(self.items)!=0 and hasattr(self.items[0],'n'):\n",
    "            return self.items[0].n # TODO(Josiah): Possible solution to make this more generic?\n",
    "        return super().__len__()\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "#         print(self.res_buffer)\n",
    "        if len(self.res_buffer)!=0:return self.res_buffer.popleft()\n",
    "        if len(self.items)<=self.n_exhausted_envs:\n",
    "            self.reset_src()\n",
    "            self.n_exhausted_envs=0\n",
    "        \n",
    "        try:\n",
    "            res=super().__getitem__(self.source_idx if self.cycle_srcs else idx)\n",
    "            self.source_idx+=1\n",
    "        except (IndexError,SourceExhausted) as e:\n",
    "            if not self.cycle_srcs:raise\n",
    "            if type(e)==SourceExhausted: \n",
    "                self.source_idx+=1;  pv(f'SourceExhausted, incrementing to idx {self.source_idx}',verbose=self.verbose) \n",
    "                self.n_exhausted_envs+=1\n",
    "            if type(e)==IndexError: self.source_idx=0;  \n",
    "            res=self.__getitem__(self.source_idx)\n",
    "        \n",
    "        if is_listy(res):\n",
    "#             print(res)\n",
    "            self.res_buffer=deque([])\n",
    "#             print('RES: ',res)\n",
    "            if type(res)==tuple:\n",
    "                for e in res: \n",
    "#                     print('loadin e: ',e)\n",
    "                    self.res_buffer.append([tuple(e)])\n",
    "            else:\n",
    "                self.res_buffer.append([tuple(res)])\n",
    "            return self.res_buffer.popleft()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IterableDataBlock(DataBlock):\n",
    "    tls_type=TfmdSource\n",
    "    def datasets(self, source, verbose=False):\n",
    "        self.source = source                     ; pv(f\"Collecting items from {source}\", verbose)\n",
    "        items = (self.get_items or noop)(source) ; pv(f\"Found {len(items)} items\", verbose)\n",
    "        splits = (self.splitter or RandomSplitter())(items)\n",
    "        pv(f\"{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}\", verbose)\n",
    "        tls=L([self.tls_type(items, t,verbose=verbose) for t in L(ifnone(self._combine_type_tfms(),[None]))])\n",
    "        return Datasets(items,tls=tls,splits=splits, dl_type=self.dl_type, n_inp=self.n_inp, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExperienceBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SeedZeroWrapper(gym.Wrapper):\n",
    "    def reset(self,*args,**kwargs):\n",
    "        self.seed(0)\n",
    "        return super().reset(*args,**kwargs)\n",
    "\n",
    "class MakeTfm(Transform):\n",
    "    def setup(self,items:TfmdSource,train_setup=False):\n",
    "        with items: \n",
    "            for i in range(len(items)):items[i]=SeedZeroWrapper(gym.make(items[i]))\n",
    "        return super().setup(items,train_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export    \n",
    "def env_display(env:gym.Env):\n",
    "    img=env.render('rgb_array')\n",
    "    try:display.clear_output(wait=True)\n",
    "    except AttributeError:pass\n",
    "    new_im=PIL.Image.fromarray(img)\n",
    "    display.display(new_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import ptan\n",
    "\n",
    "\n",
    "class TestAgent(ptan.agent.BaseAgent):\n",
    "    def __call__(self,s,ss):return [0]*len(s),[0]*len(s)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Experience():\n",
    "    d:bool;s:np.ndarray;sp:np.ndarray;r:float;a:Any;eid:int=0;episode_r:float=0;absolute_end:bool=False\n",
    "                                    \n",
    "    def __str__(self):return self.__repr__()\n",
    "    def __repr__(self):return f'Experience({\",\".join([f\"{f.name}={getattr(self,f.name).numpy() if isinstance(getattr(self,f.name),Tensor) else getattr(self,f.name)}\" for f in fields(self)])})'\n",
    "    @classmethod\n",
    "    def from_batch(cls,b):\n",
    "        if isinstance(b,tuple):b=b[0]\n",
    "        bs=max(len(e) for e in b.values())\n",
    "        return L([cls(**{k:v[i] for k,v in b.items()}) for i in range(bs)])\n",
    "                                    \n",
    "def envlen(o:gym.Env):return o.spec.max_episode_steps\n",
    "\n",
    "@dataclass\n",
    "class ResetAndStepTfm(Transform):\n",
    "    def __init__(self,seed:int=None,agent:object=None,n_steps:int=1,steps_delta:int=1,a:Any=None,histories:Dict[str,deque]=None,\n",
    "                 s:dict=None,steps:dict=None,maxsteps:int=None,display:bool=False,hist2dict:bool=True):\n",
    "        self.seed=seed;self.agent=agent;self.n_steps=n_steps;self.steps_delta=steps_delta;self.a=a;self.histories=histories;self.hist2dict=hist2dict\n",
    "        self.maxsteps=maxsteps;self.display=display\n",
    "        self.s=ifnone(s,{})\n",
    "        self.steps=ifnone(steps,{})\n",
    "        self._exhausted=False\n",
    "        self.exp_src=None\n",
    "        # store_attr('n,cycle_srcs', self) TODO (Josiah): Does not seem to work?\n",
    "            \n",
    "    def setup(self,items:TfmdSource,train_setup=False):\n",
    "#         self.reset(items)\n",
    "        self.exp_src=iter(ptan.experience.ExperienceSource(items.items, TestAgent(), steps_count=self.n_steps,steps_delta=self.steps_delta))\n",
    "        return super().setup(items,train_setup)\n",
    "    \n",
    "    def reset(self,items):\n",
    "        print('reset')\n",
    "        if len(items.items)==0:return\n",
    "        if items.extra_len==0:\n",
    "            items.extra_len=items.items[0].spec.max_episode_steps*(self.n_steps-1) # Extra steps to unwrap done\n",
    "        self.exp_src=iter(ptan.experience.ExperienceSource(items.items, TestAgent(), steps_count=self.n_steps,steps_delta=self.steps_delta))\n",
    "#         with items:\n",
    "#             self.s={id(o):o.reset() for o in items.items if o.seed(self.seed) or True}\n",
    "#             self.steps={id(o):0 for o in items.items}\n",
    "#             self.maxsteps=ifnone(self.maxsteps,envlen(items.items[0]))\n",
    "#             if self.histories is not None and self.histories:\n",
    "#                 for o in items.items: self.histories[id(o)].clear()\n",
    "#             else:\n",
    "#                  self.histories={id(o):deque(maxlen=self.n_steps) for o in items}\n",
    "        \n",
    "#     def queue2dict(self,q:deque):return [asdict(hist) for hist in tuple(copy(q))]\n",
    "#     def encodes(self,o:gym.Env):\n",
    "#         if self._exhausted:\n",
    "#             self._exhausted=False\n",
    "#             raise SourceExhausted()\n",
    "#         # If history has finished, then instead we try emptying the environment\n",
    "#         if self.histories[id(o)] and self.histories[id(o)][-1].d:\n",
    "            \n",
    "#             if len(self.histories[id(o)])==1:\n",
    "#                 self.histories[id(o)][-1].absolute_end=True\n",
    "# #                 print('returning')\n",
    "#                 h=deepcopy(self.histories[id(o)])\n",
    "#                 self.histories[id(o)].popleft()\n",
    "#                 self._exhausted=True\n",
    "#                 return self.queue2dict(h) if self.hist2dict else copy(h)\n",
    "#             else:\n",
    "#                 self.histories[id(o)].popleft()\n",
    "# #             print('hello2',self.histories[id(o)])\n",
    "#             if len(self.histories[id(o)])==0:\n",
    "# #                 print('resiting')\n",
    "#                 raise SourceExhausted\n",
    "#             return self.queue2dict(self.histories[id(o)]) if self.hist2dict else copy(self.histories[id(o)])\n",
    "        \n",
    "#         while True:\n",
    "#             a=ifnone(self.a,o.action_space.sample()) if self.agent is None else self.agent(self.s[id(o)])[0]\n",
    "#             sp,r,d,_=o.env.step(a)\n",
    "# #             print(self.s[id(o)])\n",
    "#             if self.display:env_display(o)\n",
    "                \n",
    "#             self.steps[id(o)]+=1\n",
    "#             d=self.steps[id(o)]>=self.maxsteps if not d else d\n",
    "# #             if d:print('done detected trololol')\n",
    "    \n",
    "#             self.histories[id(o)].append(Experience(d=d,s=self.s[id(o)].copy(),sp=sp.copy(),r=r,a=a,eid=id(o),\n",
    "#                                          episode_r=r+(self.histories[id(o)][-1].episode_r if self.histories[id(o)] else 0)))\n",
    "#             self.s[id(o)]=sp.copy()\n",
    "            \n",
    "#             if self.steps[id(o)]%self.steps_delta!=0:          continue # TODO(Josiah): if `steps_delta`!=1, it may skip the first state. Is this ok?\n",
    "# #             print(len(self.histories[id(o)]))\n",
    "#             if len(self.histories[id(o)])!=self.n_steps:       continue\n",
    "#             break\n",
    "        \n",
    "#         if self.histories[id(o)][-1].d and len(self.histories[id(o)])==1:self.histories[id(o)][-1].absolute_end=True\n",
    "# #         print('hello1',self.histories[id(o)])\n",
    "#         return self.queue2dict(self.histories[id(o)]) if self.hist2dict else copy(self.histories[id(o)])\n",
    "\n",
    "    def try_hist2dict(self,o,n_pop=1): \n",
    "        out=self.queue2dict(self.histories[id(o)]) if self.hist2dict else copy(self.histories[id(o)])\n",
    "        for _ in range(n_pop):self.histories[id(o)].popleft()\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def encodes(self,o:gym.Env):\n",
    "        exps=next(self.exp_src)\n",
    "#         print(exps)\n",
    "        \n",
    "#         print(exps)\n",
    "        return exps\n",
    "#         a=ifnone(self.a,o.action_space.sample()) if self.agent is None else self.agent(self.s[id(o)])[0]\n",
    "#         sp,r,d,_=o.env.step(a)\n",
    "#         if d:raise SourceExhausted()\n",
    "#         self.histories[id(o)].append(Experience(d=d,s=self.s[id(o)].copy(),sp=sp.copy(),r=r,a=a,eid=id(o),\n",
    "#                                      episode_r=r+(self.histories[id(o)][-1].episode_r if self.histories[id(o)] else 0)))\n",
    "#         self.s[id(o)]=sp.copy()\n",
    "        \n",
    "#         return self.try_hist2dict(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(ResetAndStepTfm)\n",
    "def ExperienceBlock(dls_kwargs=None,**kwargs):\n",
    "    return TransformBlock(type_tfms=[MakeTfm(),ResetAndStepTfm(**kwargs)],dl_type=TfmdSourceDL,dls_kwargs=dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/bin/bash -c \"source activate fastrl && pip install ptan --no-dependencies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "clearing buffer:  deque([])\n",
      "reset\n",
      "clearing buffer:  deque([])\n",
      "starting\n",
      "reset\n",
      "clearing buffer:  deque([])\n",
      "reset\n",
      "clearing buffer:  deque([])\n",
      "([((tensor([[-0.0446,  0.0465,  0.0133, -0.0210],\n",
      "        [-0.0436, -0.1488,  0.0128,  0.2758],\n",
      "        [-0.0466, -0.3441,  0.0184,  0.5725]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False, False])),)],)\n",
      "([((tensor([[-0.0535, -0.5394,  0.0298,  0.8710],\n",
      "        [-0.0643, -0.7350,  0.0472,  1.1729],\n",
      "        [-0.0790, -0.9307,  0.0707,  1.4800]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False, False])),)],)\n",
      "([((tensor([[-0.0976, -1.1266,  0.1003,  1.7939],\n",
      "        [-0.1201, -1.3227,  0.1362,  2.1160],\n",
      "        [-0.1466, -1.5189,  0.1785,  2.4474]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False,  True])),)],)\n",
      "([((tensor([[-0.0446,  0.0465,  0.0133, -0.0210],\n",
      "        [-0.0436, -0.1488,  0.0128,  0.2758],\n",
      "        [-0.0466, -0.3441,  0.0184,  0.5725]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False, False])),)],)\n",
      "([((tensor([[-0.0535, -0.5394,  0.0298,  0.8710],\n",
      "        [-0.0643, -0.7350,  0.0472,  1.1729],\n",
      "        [-0.0790, -0.9307,  0.0707,  1.4800]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False, False])),)],)\n",
      "([((tensor([[-0.0976, -1.1266,  0.1003,  1.7939],\n",
      "        [-0.1201, -1.3227,  0.1362,  2.1160],\n",
      "        [-0.1466, -1.5189,  0.1785,  2.4474]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False,  True])),)],)\n",
      "([((tensor([[-0.0446,  0.0465,  0.0133, -0.0210],\n",
      "        [-0.0436, -0.1488,  0.0128,  0.2758],\n",
      "        [-0.0466, -0.3441,  0.0184,  0.5725]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False, False])),)],)\n",
      "([((tensor([[-0.0535, -0.5394,  0.0298,  0.8710],\n",
      "        [-0.0643, -0.7350,  0.0472,  1.1729],\n",
      "        [-0.0790, -0.9307,  0.0707,  1.4800]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False, False])),)],)\n",
      "([((tensor([[-0.0976, -1.1266,  0.1003,  1.7939],\n",
      "        [-0.1201, -1.3227,  0.1362,  2.1160],\n",
      "        [-0.1466, -1.5189,  0.1785,  2.4474]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False,  True])),)],)\n",
      "([((tensor([[-0.0446,  0.0465,  0.0133, -0.0210],\n",
      "        [-0.0436, -0.1488,  0.0128,  0.2758],\n",
      "        [-0.0466, -0.3441,  0.0184,  0.5725]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False, False])),)],)\n",
      "([((tensor([[-0.0535, -0.5394,  0.0298,  0.8710],\n",
      "        [-0.0643, -0.7350,  0.0472,  1.1729],\n",
      "        [-0.0790, -0.9307,  0.0707,  1.4800]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False, False])),)],)\n",
      "([((tensor([[-0.0976, -1.1266,  0.1003,  1.7939],\n",
      "        [-0.1201, -1.3227,  0.1362,  2.1160],\n",
      "        [-0.1466, -1.5189,  0.1785,  2.4474]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False,  True])),)],)\n",
      "([((tensor([[-0.0446,  0.0465,  0.0133, -0.0210],\n",
      "        [-0.0436, -0.1488,  0.0128,  0.2758],\n",
      "        [-0.0466, -0.3441,  0.0184,  0.5725]], dtype=torch.float64), tensor([0, 0, 0]), tensor([1., 1., 1.], dtype=torch.float64), tensor([False, False, False])),)],)\n",
      "([((tensor([[-0.0535, -0.5394,  0.0298,  0.8710]], dtype=torch.float64), tensor([0]), tensor([1.], dtype=torch.float64), tensor([False])),)],)\n"
     ]
    }
   ],
   "source": [
    "n_steps=1\n",
    "steps_delta=1\n",
    "\n",
    "blk=IterableDataBlock(blocks=(ExperienceBlock(n_steps=n_steps,steps_delta=steps_delta,a=0,seed=0)),\n",
    "                              splitter=FuncSplitter(lambda x:False))\n",
    "dls=blk.dataloaders(['CartPole-v1'],bs=3,num_workers=0,verbose=False,\n",
    "                      indexed=True,shuffle_train=False,n=40)\n",
    "print('starting')\n",
    "for e in dls[0]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "clearing buffer:  deque([])\n",
      "reset\n",
      "clearing buffer:  deque([])\n",
      "reset\n",
      "clearing buffer:  deque([])\n",
      "reset\n",
      "clearing buffer:  deque([])\n",
      "[-0.04456399  0.04653909  0.01326909 -0.02099827] [-0.04456399  0.04653909  0.01326909 -0.02099827]\n",
      "[-0.04363321 -0.14877061  0.01284913  0.2758415 ] [-0.04363321 -0.14877061  0.01284913  0.2758415 ]\n",
      "[-0.04660862 -0.3440735   0.01836596  0.5725492 ] [-0.04660862 -0.3440735   0.01836596  0.5725492 ]\n",
      "[-0.05349009 -0.5394481   0.02981694  0.87096095] [-0.05349009 -0.5394481   0.02981694  0.87096095]\n",
      "[-0.06427906 -0.73496263  0.04723616  1.17286728] [-0.06427906 -0.73496263  0.04723616  1.17286728]\n",
      "[-0.07897831 -0.93066572  0.07069351  1.47997674] [-0.07897831 -0.93066572  0.07069351  1.47997674]\n",
      "[-0.09759162 -1.12657568  0.10029304  1.79387427] [-0.09759162 -1.12657568  0.10029304  1.79387427]\n",
      "[-0.12012314 -1.32266817  0.13617053  2.11597167] [-0.12012314 -1.32266817  0.13617053  2.11597167]\n",
      "[-0.1465765  -1.51886144  0.17848996  2.44744788] [-0.1465765  -1.51886144  0.17848996  2.44744788]\n",
      "[-0.04456399  0.04653909  0.01326909 -0.02099827] [-0.04456399  0.04653909  0.01326909 -0.02099827]\n",
      "[-0.04363321 -0.14877061  0.01284913  0.2758415 ] [-0.04363321 -0.14877061  0.01284913  0.2758415 ]\n",
      "[-0.04660862 -0.3440735   0.01836596  0.5725492 ] [-0.04660862 -0.3440735   0.01836596  0.5725492 ]\n",
      "[-0.05349009 -0.5394481   0.02981694  0.87096095] [-0.05349009 -0.5394481   0.02981694  0.87096095]\n",
      "[-0.06427906 -0.73496263  0.04723616  1.17286728] [-0.06427906 -0.73496263  0.04723616  1.17286728]\n",
      "[-0.07897831 -0.93066572  0.07069351  1.47997674] [-0.07897831 -0.93066572  0.07069351  1.47997674]\n",
      "[-0.09759162 -1.12657568  0.10029304  1.79387427] [-0.09759162 -1.12657568  0.10029304  1.79387427]\n",
      "[-0.12012314 -1.32266817  0.13617053  2.11597167] [-0.12012314 -1.32266817  0.13617053  2.11597167]\n",
      "[-0.1465765  -1.51886144  0.17848996  2.44744788] [-0.1465765  -1.51886144  0.17848996  2.44744788]\n",
      "[-0.04456399  0.04653909  0.01326909 -0.02099827] [-0.04456399  0.04653909  0.01326909 -0.02099827]\n",
      "[-0.04363321 -0.14877061  0.01284913  0.2758415 ] [-0.04363321 -0.14877061  0.01284913  0.2758415 ]\n",
      "[-0.04660862 -0.3440735   0.01836596  0.5725492 ] [-0.04660862 -0.3440735   0.01836596  0.5725492 ]\n",
      "[-0.05349009 -0.5394481   0.02981694  0.87096095] [-0.05349009 -0.5394481   0.02981694  0.87096095]\n",
      "[-0.06427906 -0.73496263  0.04723616  1.17286728] [-0.06427906 -0.73496263  0.04723616  1.17286728]\n",
      "[-0.07897831 -0.93066572  0.07069351  1.47997674] [-0.07897831 -0.93066572  0.07069351  1.47997674]\n",
      "[-0.09759162 -1.12657568  0.10029304  1.79387427] [-0.09759162 -1.12657568  0.10029304  1.79387427]\n",
      "[-0.12012314 -1.32266817  0.13617053  2.11597167] [-0.12012314 -1.32266817  0.13617053  2.11597167]\n",
      "[-0.1465765  -1.51886144  0.17848996  2.44744788] [-0.1465765  -1.51886144  0.17848996  2.44744788]\n",
      "[-0.04456399  0.04653909  0.01326909 -0.02099827] [-0.04456399  0.04653909  0.01326909 -0.02099827]\n",
      "[-0.04363321 -0.14877061  0.01284913  0.2758415 ] [-0.04363321 -0.14877061  0.01284913  0.2758415 ]\n",
      "[-0.04660862 -0.3440735   0.01836596  0.5725492 ] [-0.04660862 -0.3440735   0.01836596  0.5725492 ]\n",
      "[-0.05349009 -0.5394481   0.02981694  0.87096095] [-0.05349009 -0.5394481   0.02981694  0.87096095]\n",
      "[-0.06427906 -0.73496263  0.04723616  1.17286728] [-0.06427906 -0.73496263  0.04723616  1.17286728]\n",
      "[-0.07897831 -0.93066572  0.07069351  1.47997674] [-0.07897831 -0.93066572  0.07069351  1.47997674]\n",
      "[-0.09759162 -1.12657568  0.10029304  1.79387427] [-0.09759162 -1.12657568  0.10029304  1.79387427]\n",
      "[-0.12012314 -1.32266817  0.13617053  2.11597167] [-0.12012314 -1.32266817  0.13617053  2.11597167]\n",
      "[-0.1465765  -1.51886144  0.17848996  2.44744788] [-0.1465765  -1.51886144  0.17848996  2.44744788]\n",
      "[-0.04456399  0.04653909  0.01326909 -0.02099827] [-0.04456399  0.04653909  0.01326909 -0.02099827]\n",
      "[-0.04363321 -0.14877061  0.01284913  0.2758415 ] [-0.04363321 -0.14877061  0.01284913  0.2758415 ]\n",
      "[-0.04660862 -0.3440735   0.01836596  0.5725492 ] [-0.04660862 -0.3440735   0.01836596  0.5725492 ]\n",
      "[-0.05349009 -0.5394481   0.02981694  0.87096095] [-0.05349009 -0.5394481   0.02981694  0.87096095]\n"
     ]
    }
   ],
   "source": [
    "n_steps=1\n",
    "steps_delta=1\n",
    "\n",
    "\n",
    "blk=IterableDataBlock(blocks=(ExperienceBlock(n_steps=n_steps,steps_delta=steps_delta,a=0,seed=0)),\n",
    "                              splitter=FuncSplitter(lambda x:False))\n",
    "\n",
    "envs=[gym.make('CartPole-v1')]\n",
    "envs=[SeedZeroWrapper(e) for e in envs]\n",
    "exp_src=ptan.experience.ExperienceSource(envs, TestAgent(), steps_count=n_steps)\n",
    "\n",
    "dls=blk.dataloaders(['CartPole-v1'],bs=n_steps,num_workers=0,verbose=False,\n",
    "                      indexed=True,shuffle_train=False,n=40)\n",
    "\n",
    "fastrl_exp=[]\n",
    "ptan_exps=[]\n",
    "\n",
    "for i,(x,e) in enumerate(zip(dls[0],exp_src)):\n",
    "    un_batch_x=[]\n",
    "#     print(x[0][0][0][1])\n",
    "#     print(x[0][0][0][1].shape[0])\n",
    "    for i in range(x[0][0][0][1].shape[0]):\n",
    "#         print(i,x[0][0])\n",
    "        un_batch_x.append(ptan.experience.Experience(*tuple(el[i].numpy() for el in x[0][0][0])))\n",
    "#     print(tuple(un_batch_x),'\\n',e)\n",
    "    for fastrl_e,ptan_e in zip(un_batch_x,e):\n",
    "        print(fastrl_e.state,ptan_e.state)\n",
    "        test_eq(fastrl_e.state,ptan_e.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FirstLastExperienceBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class FirstLastTfm(Transform):\n",
    "    def __init__(self,discount=0.99):self.discount=discount\n",
    "    \n",
    "    def reset(self,items):\n",
    "        if items.extra_len!=0:items.extra_len=0\n",
    "    \n",
    "    def encodes(self,o):\n",
    "        first_o=o[0]\n",
    "        first_o.sp=o[-1].sp\n",
    "        total_reward=first_o.r\n",
    "        elms=list(o)[:-1]\n",
    "\n",
    "        for exp in reversed(elms):\n",
    "            total_reward*=self.discount\n",
    "            total_reward+=exp.r\n",
    "        first_o.r=total_reward\n",
    "        return asdict(first_o)\n",
    "\n",
    "\n",
    "@delegates(ResetAndStepTfm)\n",
    "def FirstLastExperienceBlock(dls_kwargs=None,**kwargs):\n",
    "    return TransformBlock(type_tfms=[MakeTfm(),ResetAndStepTfm(hist2dict=False,**kwargs),FirstLastTfm],dl_type=TfmdSourceDL,dls_kwargs=dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "@delegates(ResetAndStepTfm)\n",
    "def fl_test_block(n_steps,block=FirstLastExperienceBlock,**kwargs):\n",
    "    for env in ['MountainCar-v0','CartPole-v1']:\n",
    "        blk=IterableDataBlock(blocks=(block(n_steps=n_steps,**kwargs)),\n",
    "                    splitter=FuncSplitter(lambda x:False),batch_tfms=lambda x:(x['s'],x))\n",
    "\n",
    "        dls=blk.dataloaders([env]*5,bs=1,num_workers=0,verbose=False,\n",
    "                              indexed=True,shuffle_train=False)\n",
    "\n",
    "\n",
    "        states={\n",
    "            'MountainCar-v0':['tensor([[-0.5891,  0.0000]], dtype=torch.float64)','tensor([[-0.7105,  0.0043]], dtype=torch.float64)'],\n",
    "            'CartPole-v1':['tensor([[-0.0446,  0.0465,  0.0133, -0.0210]], dtype=torch.float64)',\n",
    "                           'tensor([[-0.1770, -1.7150,  0.2274,  2.7892]], dtype=torch.float64)']\n",
    "        }\n",
    "\n",
    "        print('Starting Iteration')\n",
    "        counter=0\n",
    "        counters=[]\n",
    "        for epoch in range(3):\n",
    "            dones=0\n",
    "            for x in dls[0]:\n",
    "                print('\\nResult',x)\n",
    "                if counter==0: test_eq(str(x[0]['s']),states[env][0])\n",
    "                if x[0]['d']:\n",
    "#                     print(len(dls[0]),dones)\n",
    "                    dones+=1\n",
    "                    test_eq(str(x[0]['sp']),states[env][1])\n",
    "#                     print(counter)\n",
    "                    # TODO(Josiah): Figure out why this differs between runs.\n",
    "                    if env=='MountainCar-v0':test_eq(counter,pytest.approx(200*n_steps-n_steps*(0+1),1))\n",
    "                    counters.append(counter)\n",
    "                    counter=0\n",
    "                else:\n",
    "                    counter+=1\n",
    "            test_ne(counters[-1],0)\n",
    "fl_test_block(a=0,seed=0,n_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()\n",
    "notebook2html(n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
