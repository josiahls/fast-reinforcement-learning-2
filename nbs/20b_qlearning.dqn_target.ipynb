{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp qlearning.dqn_n_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn.utils as nn_utils\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "import torch.multiprocessing as mp\n",
    "from torch.optim import *\n",
    "\n",
    "from fastrl.data import *\n",
    "from fastrl.async_data import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.learner import *\n",
    "from fastrl.metrics import *\n",
    "from fastrl.ptan_extension import *\n",
    "from fastrl.qlearning.dqn import *\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TargetDQNTrainer(Callback):\n",
    "    def __init__(self,n_batch=0): store_attr()\n",
    "    def after_pred(self):\n",
    "        s,a,r,sp,d,er,steps=(self.learn.xb+self.learn.yb)\n",
    "        exps=[ExperienceFirstLast(*o) for o in zip(*(self.learn.xb+self.learn.yb))]\n",
    "        batch_targets=[calc_target(self.learn.model, exp.reward, exp.last_state,exp.done,self.learn.discount**self.learn.n_steps)\n",
    "                         for exp in exps]\n",
    "        \n",
    "\n",
    "        state_action_values = self.learn.model(s.float()).gather(1, a.unsqueeze(-1)).squeeze(-1)\n",
    "        next_state_values = self.learn.target_model(sp.float()).max(1)[0]\n",
    "        next_state_values[d] = 0.0\n",
    "\n",
    "        expected_state_action_values=next_state_values.detach()*(self.learn.discount**self.learn.n_steps)+r\n",
    "#         print(*self.learn.yb,self.learn.pred)\n",
    "#         print(self.learn.pred,self.learn.yb)\n",
    "#         print(self.learn._yb,self.learn.yb[0])\n",
    "        self.learn._yb=self.learn.yb\n",
    "        self.learn.yb=(expected_state_action_values.float(),)\n",
    "        self.learn.pred=state_action_values\n",
    "    \n",
    "    def after_loss(self):\n",
    "        self.learn.yb=self.learn._yb\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if self.n_batch%self.learn.target_sync==0:\n",
    "            self.learn.target_model.load_state_dict(self.learn.model.state_dict())\n",
    "        self.n_batch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TargetDQNLearner(AgentLearner):\n",
    "    def __init__(self,dls,discount=0.99,n_steps=3,target_sync=300,**kwargs):\n",
    "        store_attr()\n",
    "        self.target_q_v=[]\n",
    "        super().__init__(dls,loss_func=nn.MSELoss(),**kwargs)\n",
    "        self.target_model=deepcopy(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_avg_episode_r</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_avg_episode_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.488254</td>\n",
       "      <td>21.196809</td>\n",
       "      <td>None</td>\n",
       "      <td>21.196809</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.196225</td>\n",
       "      <td>21.565000</td>\n",
       "      <td>None</td>\n",
       "      <td>21.565000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121115</td>\n",
       "      <td>23.971667</td>\n",
       "      <td>None</td>\n",
       "      <td>23.971667</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.652146</td>\n",
       "      <td>24.961667</td>\n",
       "      <td>None</td>\n",
       "      <td>24.961667</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.471985</td>\n",
       "      <td>25.873333</td>\n",
       "      <td>None</td>\n",
       "      <td>25.873333</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.393460</td>\n",
       "      <td>26.045000</td>\n",
       "      <td>None</td>\n",
       "      <td>26.045000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.685860</td>\n",
       "      <td>27.056667</td>\n",
       "      <td>None</td>\n",
       "      <td>27.056667</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.844604</td>\n",
       "      <td>28.356667</td>\n",
       "      <td>None</td>\n",
       "      <td>28.356667</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.761524</td>\n",
       "      <td>28.880000</td>\n",
       "      <td>None</td>\n",
       "      <td>28.880000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.480243</td>\n",
       "      <td>32.986667</td>\n",
       "      <td>None</td>\n",
       "      <td>32.986667</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.549649</td>\n",
       "      <td>32.661667</td>\n",
       "      <td>None</td>\n",
       "      <td>32.661667</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.347267</td>\n",
       "      <td>36.226667</td>\n",
       "      <td>None</td>\n",
       "      <td>36.226667</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.219996</td>\n",
       "      <td>38.730000</td>\n",
       "      <td>None</td>\n",
       "      <td>38.730000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.552105</td>\n",
       "      <td>45.400000</td>\n",
       "      <td>None</td>\n",
       "      <td>45.400000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.054687</td>\n",
       "      <td>46.605000</td>\n",
       "      <td>None</td>\n",
       "      <td>46.605000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env='CartPole-v1'\n",
    "model=LinearDQN((4,),2)\n",
    "agent=DiscreteAgent(model=model.to(default_device()),device=default_device(),\n",
    "                    a_selector=EpsilonGreedyActionSelector())\n",
    "\n",
    "block=FirstLastExperienceBlock(agent=agent,seed=0,n_steps=3,dls_kwargs={'bs':32,'num_workers':0,'verbose':False,'indexed':True,'shuffle_train':False})\n",
    "blk=IterableDataBlock(blocks=(block),\n",
    "                      splitter=FuncSplitter(lambda x:False),\n",
    "#                       batch_tfms=lambda x:(x['s'],x),\n",
    "                     )\n",
    "dls=blk.dataloaders([env]*1,n=32*100,device=default_device())\n",
    "\n",
    "learner=TargetDQNLearner(dls,agent=agent,n_steps=3,cbs=[EpsilonTracker,\n",
    "                                        ExperienceReplay(sz=50000,bs=32,starting_els=32,max_steps=gym.make(env)._max_episode_steps),\n",
    "                                        TargetDQNTrainer],metrics=[AvgEpisodeRewardMetric(experience_cls=ExperienceFirstLast)])\n",
    "learner.fit(15,lr=0.01,wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "from nbdev.export2html import *\n",
    "notebook2script()\n",
    "notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
