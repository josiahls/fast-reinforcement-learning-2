{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp metrics\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> Metrics for reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.callback import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.core import *\n",
    "from fastai.torch_core import *\n",
    "from dataclasses import dataclass\n",
    "import torch.multiprocessing as mp\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s line:%(lineno)d %(levelname)s - %(message)s',\n",
    "                    datefmt='%m-%d %H:%M:%S')\n",
    "logging.getLogger('fastrl.data_block').setLevel('CRITICAL')\n",
    "_logger=logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastrl.data_block import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.basic_train import *\n",
    "import sys\n",
    "\n",
    "_logger.setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class TotalRewards(object):\n",
    "    rewards:float\n",
    "\n",
    "class RewardMetric(LearnerCallback):\n",
    "    _order=-20\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        metric_names = ['train_reward'] if self.learn.recorder.no_val or self.learn.data.empty_val else ['train_reward', 'valid_reward']\n",
    "        self.learn.recorder.add_metric_names(metric_names)\n",
    "        for ds in [self.learn.data.train_ds,None if self.learn.data.empty_val else self.learn.data.valid_ds]:\n",
    "            if hasattr(ds,'metric_queue') and ds.metric_queue is None:\n",
    "                ds.metric_queue=mp.JoinableQueue(ds.queue_sz*len(ds)) # Make sure this queue has more space to prevent locking\n",
    "                \n",
    "\n",
    "    def on_epoch_end(self,last_metrics,**kwargs: Any):\n",
    "        rewards=[]\n",
    "        for ds in [self.learn.data.train_ds,None if self.learn.data.empty_val else self.learn.data.valid_ds]:\n",
    "            if ds is None:continue\n",
    "            rs=[]\n",
    "            if hasattr(ds,'metric_queue'): \n",
    "                if ds.metric_queue is not None:\n",
    "                    while not ds.metric_queue.empty():\n",
    "                        rs.append(ds.metric_queue.get().rewards)\n",
    "            else:rs=ds.pop_total_rewards()\n",
    "            rewards.append(np.mean(rs))\n",
    "        return add_metrics(last_metrics,rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @safe_fit\n",
    "def dqn_grad_fitter_2(model:nn.Module,agent:BaseAgent,ds:ExperienceSourceDataset,grad_queue:mp.JoinableQueue,loss_queue:mp.JoinableQueue,\n",
    "                      pause_event:mp.Event,cancel_event:mp.Event,metric_queue:mp.JoinableQueue=None):\n",
    "    dataset=ds()\n",
    "    while not cancel_event.is_set(): \n",
    "        for xb,yb in dataset:\n",
    "            sys.stdout.flush()\n",
    "            grad_queue.put(xb)\n",
    "            loss_queue.put(0.5)\n",
    "            if pause_event.is_set():cancel_event.wait(0.1) \n",
    "            if cancel_event.is_set():break\n",
    "        if metric_queue is not None:\n",
    "            rs=dataset.pop_total_rewards()\n",
    "            if len(rs)!=0:metric_queue.put(TotalRewards(np.mean(rs)))\n",
    "        if cancel_event.is_set():break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_reward</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>21.609756</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>#na#</td>\n",
       "      <td>20.360000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>#na#</td>\n",
       "      <td>20.416667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>#na#</td>\n",
       "      <td>23.190476</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>#na#</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>#na#</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>#na#</td>\n",
       "      <td>18.481481</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>#na#</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>#na#</td>\n",
       "      <td>26.363636</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>#na#</td>\n",
       "      <td>21.391304</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/torch/utils/data/dataloader.py:375: UserWarning: Length of IterableDataset <fastrl.data_block.AsyncGradExperienceSourceDataset object at 0x7f01f1f27410> was reported to be 500 (when accessing len(dataloader)), but 501 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',data_exp=False,display=False,firstlast=True,add_valid=False,n_processes=2,n_envs=2,queue_sz=400)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback,RewardMetric])\n",
    "setattr(learn,'fitter',dqn_grad_fitter_2)\n",
    "learn.fit(10,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 02_callbacks.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted 05_data_block.ipynb.\n",
      "Converted 06_basic_train.ipynb.\n",
      "Converted 12_a3c.a3c_data.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted notes.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: /opt/project/fastrl/nbs/04_metrics.ipynb\n",
      "converting: /opt/project/fastrl/nbs/05_data_block.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()\n",
    "notebook2html(n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}