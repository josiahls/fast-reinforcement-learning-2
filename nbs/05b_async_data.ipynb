{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp async_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "import torch.multiprocessing as mp\n",
    "from fastrl.data import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastcore.all import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "import sys\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from itertools import product\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "\n",
    "from fastrl.learner import *\n",
    "\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async Experience Blocks\n",
    "\n",
    "> Extend traditional experience blocks to run environments asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def template_data_fit(queue:mp.JoinableQueue=None,items:L=None,agent:BaseAgent=None,learner_cls:Learner=None,experience_block:ExperienceBlock=None,\n",
    "             cancel:mp.Event=None):\n",
    "#     print('here',flush=True)\n",
    "    sys.stdout.flush()\n",
    "    blk=IterableDataBlock(blocks=(experience_block(agent=agent)),\n",
    "                          splitter=FuncSplitter(lambda x:False))\n",
    "    dls=blk.dataloaders(items,device='cpu')\n",
    "#     print('Starting iter',flush=True)\n",
    "    sys.stdout.flush()\n",
    "    while True:\n",
    "        for x in dls[0]:\n",
    "#             print('putting',flush=True)\n",
    "            queue.put(x)\n",
    "            if cancel.is_set():\n",
    "                queue.put(None)\n",
    "                return None\n",
    "\n",
    "class DataFitProcess(mp.Process):\n",
    "    \n",
    "    @delegates(template_data_fit,but=['queue','items'])\n",
    "    def __init__(self,n:int=None,start:bool=False,data_fit=None,**kwargs):\n",
    "        self.n=n\n",
    "        super().__init__(target=ifnone(data_fit,template_data_fit),kwargs=kwargs)\n",
    "        if start:\n",
    "            self.start()\n",
    "#             print('starting',data_fit,template_data_fit)\n",
    "        \n",
    "    def termijoin(self):\n",
    "        self.terminate()\n",
    "        self.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiProcessTfm(Transform):\n",
    "    def __init__(self,n:int=1,n_processes:int=1,maxsize:int=1,process_cls=DataFitProcess):\n",
    "        self.n_processes=n_processes;self.process_cls=process_cls;self.n=n;self.maxsize=maxsize\n",
    "        self.queue=mp.JoinableQueue(maxsize=maxsize)\n",
    "        self.cancel=mp.Event()\n",
    "        self.cached_items=[]\n",
    "#         mp.set_start_method('spawn',force=True)\n",
    "        \n",
    "    def setup(self,items:TfmdSource,train_setup=False):\n",
    "#         with items:\n",
    "        if len(items.items)!=0 and not issubclass(items.items[0].__class__,DataFitProcess):\n",
    "            self.cached_items=deepcopy(items.items)\n",
    "        self.reset(items)\n",
    "            \n",
    "    def reset(self,items:TfmdSource,train_setup=False):\n",
    "#         with items:\n",
    "        self.close(items)\n",
    "        self.cancel.clear()\n",
    "        self.queue=mp.JoinableQueue(maxsize=self.maxsize)\n",
    "        items.items=[self.process_cls(n=self.n,start=True,queue=self.queue,items=self.cached_items,cancel=self.cancel) for _ in range(self.n_processes)]\n",
    "\n",
    "    def close(self,items:TfmdSource):\n",
    "#         with items: \n",
    "        self.cancel.set()\n",
    "        try:\n",
    "            while not self.queue.empty():self.queue.get()\n",
    "        except (ConnectionResetError,FileNotFoundError,EOFError,ConnectionRefusedError):pass\n",
    "        [p.termijoin() for p in items.items if issubclass(p.__class__,DataFitProcess)]\n",
    "        items.items.clear()\n",
    "\n",
    "    def encodes(self,o):\n",
    "#         print('waiting')\n",
    "        s=self.queue.get()\n",
    "#         print(s[0])\n",
    "        return [s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(MultiProcessTfm)\n",
    "def AsyncExperienceBlock(experience_block,agent=None,learner_cls=None,data_fit=None,n_processes=1,n=200,bs=1,**kwargs):\n",
    "    process_cls=partial(\n",
    "        DataFitProcess,\n",
    "        agent=agent,\n",
    "        learner_cls=learner_cls,\n",
    "        experience_block=experience_block,\n",
    "        data_fit=data_fit\n",
    "    )\n",
    "    \n",
    "    return TransformBlock(type_tfms=[MultiProcessTfm(process_cls=process_cls,n_processes=n_processes,n=n)],dl_type=TfmdSourceDL,\n",
    "                          dls_kwargs={'bs':bs,'num_workers':0,'verbose':False,'indexed':True,'shuffle_train':False})\n",
    "\n",
    "import ptan\n",
    "class TestAgent(ptan.agent.BaseAgent):\n",
    "    def __call__(self,s,ss):return [0]*len(s),[0]*len(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_envs=15\n",
    "for n_step_param,steps_delta_param in product(range(1,8),range(1,8)):\n",
    "    block=AsyncExperienceBlock(\n",
    "        experience_block=partial(FirstLastExperienceBlock,a=0,seed=0,n_steps=n_step_param,steps_delta=steps_delta_param,\n",
    "                                 dls_kwargs={'bs':1,'num_workers':0,'verbose':False,'indexed':True,'shuffle_train':False}),\n",
    "        n_processes=1,\n",
    "        n=200\n",
    "    )\n",
    "\n",
    "    blk=IterableDataBlock(blocks=(block),splitter=FuncSplitter(lambda x:False))\n",
    "\n",
    "    envs=[gym.make('CartPole-v1') for _ in range(n_envs)]\n",
    "    envs=[SeedZeroWrapper(e) for e in envs]\n",
    "    exp_src=ptan.experience.ExperienceSourceFirstLast(envs, TestAgent(), gamma=0.99,steps_count=n_step_param,steps_delta=steps_delta_param)\n",
    "\n",
    "    dls=blk.dataloaders(['CartPole-v1']*n_envs,bs=n_step_param,num_workers=0,verbose=False,\n",
    "                          indexed=True,shuffle_train=False,n=40)\n",
    "\n",
    "    fastrl_exp=[]\n",
    "    ptan_exps=[]\n",
    "    counter=0\n",
    "\n",
    "    for i,(x,e) in enumerate(zip(dls[0],exp_src)):\n",
    "        for i in range(x[1].shape[0]):\n",
    "#             print(x)\n",
    "            fastrl_exp.append(ExperienceFirstLast(*tuple(el[i].detach().cpu().numpy()[0] if not x[-2][i] or j!=3 else None for j,el in enumerate(x))))\n",
    "        for ptan_e in [e]:\n",
    "            fastrl_e=fastrl_exp[counter]\n",
    "            test_eq(fastrl_e.state,ptan_e.state)\n",
    "            test_eq(fastrl_e.last_state,ptan_e.last_state)\n",
    "            test_eq(fastrl_e.reward,ptan_e.reward)\n",
    "            counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "# agent=DQNAgent(model=model)\n",
    "# learn=AgentLearner(dls,agent=agent,model=model,loss_func=lambda x:0.5)\n",
    "# learn.fit(10,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_learner.ipynb.\n",
      "Converted 05a_data.ipynb.\n",
      "Converted 05b_async_data.ipynb.\n",
      "Converted 06_basic_train.ipynb.\n",
      "Converted 13_metrics.ipynb.\n",
      "Converted 14_actorcritic.sac.ipynb.\n",
      "Converted 15_actorcritic.a3c_data.ipynb.\n",
      "Converted 16_actorcritic.a2c.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: /opt/project/fastrl/nbs/05b_async_data.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "from nbdev.export2html import *\n",
    "notebook2script()\n",
    "notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
