{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp async_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "import torch.multiprocessing as mp\n",
    "from fastrl.data import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastcore.all import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "\n",
    "from fastrl.learner import *\n",
    "\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async Experience Blocks\n",
    "\n",
    "> Extend traditional experience blocks to run environments asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def template_data_fit(queue:mp.JoinableQueue=None,items:L=None,agent:BaseAgent=None,learner_cls:Learner=None,experience_block:ExperienceBlock=None,\n",
    "             cancel:mp.Event=None):\n",
    "    blk=IterableDataBlock(blocks=(experience_block(agent=agent)),\n",
    "                          splitter=FuncSplitter(lambda x:False))\n",
    "    dls=blk.dataloaders(items)\n",
    "    while True:\n",
    "        for x in dls[0]:\n",
    "            queue.put(x)\n",
    "            if cancel.is_set():\n",
    "                queue.put(None)\n",
    "                return None\n",
    "\n",
    "class DataFitProcess(mp.Process):\n",
    "    \n",
    "    @delegates(template_data_fit,but=['queue','items'])\n",
    "    def __init__(self,n:int=None,start:bool=False,data_fit=None,**kwargs):\n",
    "        self.n=n\n",
    "        super().__init__(target=ifnone(data_fit,template_data_fit),kwargs=kwargs)\n",
    "        if start:self.start()\n",
    "        \n",
    "    def termijoin(self):\n",
    "        self.terminate()\n",
    "        self.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiProcessTfm(Transform):\n",
    "    def __init__(self,n:int=1,n_processes:int=1,maxsize:int=1,process_cls=DataFitProcess):\n",
    "        self.n_processes=n_processes;self.process_cls=process_cls;self.n=n;self.maxsize=maxsize\n",
    "        self.queue=mp.JoinableQueue(maxsize=maxsize)\n",
    "        self.cancel=mp.Event()\n",
    "        self.cached_items=[]\n",
    "        \n",
    "    def setup(self,items:TfmdSource,train_setup=False):\n",
    "        with items:\n",
    "            if len(items.items)!=0 and not issubclass(items.items[0].__class__,DataFitProcess):\n",
    "                self.cached_items=deepcopy(items.items)\n",
    "            self.reset(items)\n",
    "            \n",
    "    def reset(self,items:TfmdSource,train_setup=False):\n",
    "        with items:\n",
    "            self.close(items)\n",
    "            self.cancel.clear()\n",
    "            self.queue=mp.JoinableQueue(maxsize=self.maxsize)\n",
    "            items.items=[self.process_cls(n=self.n,start=True,queue=self.queue,items=self.cached_items,cancel=self.cancel) for _ in range(self.n_processes)]\n",
    "\n",
    "    def close(self,items:TfmdSource):\n",
    "        with items: \n",
    "            self.cancel.set()\n",
    "            try:\n",
    "                while not self.queue.empty():self.queue.get()\n",
    "            except (ConnectionResetError,FileNotFoundError,EOFError,ConnectionRefusedError):pass\n",
    "            [p.termijoin() for p in items.items if issubclass(p.__class__,DataFitProcess)]\n",
    "            items.items.clear()\n",
    "\n",
    "    def encodes(self,o):\n",
    "        s=self.queue.get()\n",
    "#         print(s[0])\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(MultiProcessTfm)\n",
    "def AsyncExperienceBlock(experience_block,agent=None,learner_cls=None,data_fit=None,n_processes=1,n=200,bs=1,**kwargs):\n",
    "    process_cls=partial(\n",
    "        DataFitProcess,\n",
    "        agent=agent,\n",
    "        learner_cls=learner_cls,\n",
    "        experience_block=experience_block,\n",
    "        data_fit=data_fit\n",
    "    )\n",
    "    \n",
    "    return TransformBlock(type_tfms=[MultiProcessTfm(process_cls=process_cls,n_processes=n_processes,n=n)],dl_type=TfmdSourceDL,\n",
    "                          dls_kwargs={'bs':bs,'num_workers':0,'verbose':False,'indexed':True,'shuffle_train':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting\n",
      "resetting\n",
      "resetting\n"
     ]
    }
   ],
   "source": [
    "env='MountainCar-v0'\n",
    "\n",
    "block=AsyncExperienceBlock(\n",
    "    experience_block=partial(ExperienceBlock,a=0,seed=0,dls_kwargs={'bs':1,'num_workers':0,'verbose':False,'indexed':True,'shuffle_train':False}),\n",
    "    n_processes=1,\n",
    "    n=200\n",
    ")\n",
    "blk=IterableDataBlock(blocks=block,splitter=FuncSplitter(lambda x:False))\n",
    "dls=blk.dataloaders([env]*5)\n",
    "\n",
    "for i,x in enumerate(dls[0]):\n",
    "#     print(x)\n",
    "    if i==0:test_eq(str(x[0]['s']),str(tensor([[[-0.5891,  0.0000]]]).double()))\n",
    "\n",
    "test_eq(str(x[0]['s']),str(tensor([[[-0.7148,  0.0039]]]).double()))\n",
    "test_eq(i,199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "# agent=DQNAgent(model=model)\n",
    "# learn=AgentLearner(dls,agent=agent,model=model,loss_func=lambda x:0.5)\n",
    "# learn.fit(10,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_learner.ipynb.\n",
      "Converted 05a_data.ipynb.\n",
      "Converted 05b_async_data.ipynb.\n",
      "Converted 06_basic_train.ipynb.\n",
      "Converted 13_metrics.ipynb.\n",
      "Converted 14_actorcritic.sac.ipynb.\n",
      "Converted 15_actorcritic.a3c_data.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: /opt/project/fastrl/nbs/00_core.ipynb\n",
      "converting: /opt/project/fastrl/nbs/05b_async_data.ipynb\n",
      "converting: /opt/project/fastrl/nbs/15_actorcritic.a3c_data.ipynb\n",
      "converting: /opt/project/fastrl/nbs/01_wrappers.ipynb\n",
      "converting: /opt/project/fastrl/nbs/14_actorcritic.sac.ipynb\n",
      "converting: /opt/project/fastrl/nbs/13_metrics.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "from nbdev.export2html import *\n",
    "notebook2script()\n",
    "notebook2html(n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
