{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data_block\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Block\n",
    "\n",
    "> Primary handlers for interfacing the openai gym envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callbacks import *\n",
    "from fastrl.wrappers import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.metrics import *\n",
    "from dataclasses import asdict,dataclass,field\n",
    "from functools import partial\n",
    "from fastprogress.fastprogress import IN_NOTEBOOK\n",
    "from fastcore.utils import *\n",
    "from fastcore.foundation import *\n",
    "from torch.utils.data.dataset import IterableDataset\n",
    "import torch.multiprocessing as mp\n",
    "from functools import wraps\n",
    "from queue import Empty\n",
    "import textwrap\n",
    "import logging\n",
    "import gym\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s line:%(lineno)d %(levelname)s - %(message)s',\n",
    "                    datefmt='%m-%d %H:%M:%S')\n",
    "_logger=logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "_logger.setLevel('INFO')\n",
    "import sys\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "`Dataset` instances are going to be a little different from the typically classification dataset that you might use in pytorch. Commonly, datasets have:\n",
    "- A known size to iter through\n",
    "- Maintain their state during the training sequence\n",
    "- Randomly sample their dataset\n",
    "- Have a common `x`/`y` or `input`/`target` data format\n",
    "\n",
    "For our `ExperienceSourceDataset`, most of this is going to be different. \n",
    "- We can have multiple sources (envs)\n",
    "\n",
    "You could think of a traditional dataset approach as being a mix of a `ExperienceSourceDataset` and a form of `ExperienceReplay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class Experience(object):\n",
    "    s:np.array\n",
    "    sp:np.array\n",
    "    a:np.array\n",
    "    r:np.array\n",
    "    d:np.array\n",
    "    agent_s:np.array\n",
    "        \n",
    "    @property\n",
    "    def x(self):return self.s.copy()\n",
    "    @x.setter\n",
    "    def x(self,v):self.s=v.copy()\n",
    "\n",
    "add_docs(Experience,x='Should return the field for `xb` in the training loop. It must be copied on return or'\n",
    "         ' else there will be strange multiple reference errors.'\n",
    "         'This is intended to be fed directly into a model. The `self.s.copy()` is a single tensor to be directly fed into a regular nn.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': array([[1, 1, 1, 2, 2],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 2, 2, 1, 2],\n",
       "        [2, 1, 1, 2, 2],\n",
       "        [1, 1, 1, 2, 2]]),\n",
       " 'sp': array([[1, 1, 2, 1, 2],\n",
       "        [2, 2, 2, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [2, 1, 1, 2, 2],\n",
       "        [2, 1, 2, 2, 1]]),\n",
       " 'a': array([[1, 1]]),\n",
       " 'r': array([[2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2]]),\n",
       " 'd': array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]]),\n",
       " 'agent_s': array([[1, 3, 0, 2, 5]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp=Experience(s=np.random.randint(1,3,(5,5)),\n",
    "               sp=np.random.randint(1,3,(5,5)),\n",
    "               a=np.random.randint(1,3,(1,2)),\n",
    "               r=np.random.randint(1,3,(1,20)),\n",
    "               d=np.random.randint(0,1,(5,5)),\n",
    "               agent_s=np.random.randint(0,6,(1,5)))\n",
    "asdict(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a couple constraints on what the `ExperienceSourceDataset` is going to look like. For `__getitem__` it should return a tuple of 2 elements:\n",
    "\n",
    "- `xb` which are the elements that are going to be directly fed into the model for getting actions.\n",
    "- `yb` which are all of the elements provided by the environment that we can use for training.\n",
    "\n",
    "Some semantics:\n",
    "- `iter` means what is returned from `next(dataset)` for farthur what is returned from `[o for o in dataset]`.\n",
    "- `step` means an individual step in the env. You can have multiple steps per `iter`.\n",
    "- `batch_size` is the same thing as `step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceSourceCallback(LearnerCallback):\n",
    "    def on_train_begin(self,*args,**kwargs):\n",
    "        self.learn.data.train_dl.dataset.learn=self.learn\n",
    "        if not self.learn.data.empty_val:\n",
    "            self.learn.data.valid_dl.dataset.learn=self.learn\n",
    "\n",
    "@dataclass\n",
    "class ExperienceSourceDataset(IterableDataset):\n",
    "    \"Similar to fastai's `LabelList`, iters in-order samples from `1->len(envs)` `envs`.\"\n",
    "    env:str\n",
    "    n_envs:int=1\n",
    "    learn:Optional[Learner]=None\n",
    "    callback_fns:List[LearnerCallback]=field(default_factory=lambda:[ExperienceSourceCallback])\n",
    "    # Behavior modification fields / param fields.\n",
    "    skip_n_steps:int=1\n",
    "    max_steps:Optional[int]=None\n",
    "    pixels:bool=False\n",
    "    # Env tracking fields\n",
    "    per_env_d:np.array=None\n",
    "    per_env_s:np.array=None\n",
    "    per_env_steps:np.array=None\n",
    "    per_env_rewards:np.array=None\n",
    "    # Metric fields\n",
    "    total_rewards:List=field(default_factory=list)\n",
    "    total_steps:List=field(default_factory=list)\n",
    "    # Private funcational fields.\n",
    "    _env_idx:int=0\n",
    "    _warned:bool=False\n",
    "    _end_interation:bool=False\n",
    "    _getitem_as_exp:bool=False\n",
    "    \n",
    "    \n",
    "#     def __init__(self,env:str,n_envs=1,skip_n_steps=1,max_steps=None,pixels=False):\n",
    "    def __post_init__(self):\n",
    "        def make_env():\n",
    "            env_o=gym.make(self.env)\n",
    "            if self.pixels:env_o.reset()\n",
    "            return env_o\n",
    "            \n",
    "        self.envs=[make_env() for _ in range(self.n_envs)]\n",
    "        if self.pixels:self.envs=[PixelObservationWrapper(e) for e in self.envs]\n",
    "            \n",
    "        self.per_env_d:np.array=np.zeros((len(self.envs),))+1\n",
    "        self.per_env_s:np.array=np.zeros((len(self.envs),*self.envs[0].observation_space.sample().shape))\n",
    "        self.per_env_steps:np.array=np.zeros((len(self.envs)))\n",
    "        self.per_env_rewards:np.array=np.zeros((len(self.envs)))\n",
    "        \n",
    "    def __len__(self): return ifnone(self.max_steps,self.envs[0].spec.max_episode_steps)\n",
    "    @log_args\n",
    "    def is_last_step(self,d,steps,idx,max_steps)->bool:return bool(d) or steps>=max_steps\n",
    "    @log_args\n",
    "    def at_start(self,idx,steps):return idx==0 and steps==0\n",
    "    @log_args\n",
    "    def skip_loop(self,steps,skip_steps,d):return steps%skip_steps!=0 and not d\n",
    "    @log_args\n",
    "    def cycle_env(self,idx,n_envs):self._env_idx=0 if idx==n_envs-1 else idx+1\n",
    "    def stop_loop(self):\n",
    "        self._end_interation=False\n",
    "        raise StopIteration()\n",
    "    @log_args\n",
    "    def reset_envs(self,idx):\n",
    "        for i,e in enumerate(self.envs):self.per_env_s[i]=e.reset() # TODO: There is the possiblity this will equal None (and crash)?\n",
    "        self.per_env_steps=np.zeros((len(self.envs)),dtype=int)\n",
    "        self.per_env_rewards=np.zeros((len(self.envs)))\n",
    "    @log_args\n",
    "    def pick_action(self,idx):\n",
    "        if self.learn is None:\n",
    "            if not self._warned:_logger.warning('`self.learn` is None. will use random actions instead.')\n",
    "            self._warned=True\n",
    "            return self.envs[0].action_space.sample(),np.zeros((1,1))\n",
    "        return self.learn.predict(self.per_env_s[idx])\n",
    "    \n",
    "    def pop_total_rewards(self):\n",
    "        total_rewards=self.total_rewards\n",
    "        if total_rewards:self.total_rewards,self.total_steps=[],[]\n",
    "        return total_rewards\n",
    "\n",
    "    def pop_reward_steps(self):\n",
    "        total_rewards,total_steps=self.total_rewards,self.total_steps\n",
    "        res=list(zip(total_rewards,total_steps))\n",
    "        if res:self.total_rewards,self.total_steps=[],[]\n",
    "        return res\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            try:\n",
    "                o=self.__getitem__(None)\n",
    "                yield o\n",
    "            except StopIteration:\n",
    "                return\n",
    "    \n",
    "    @log_args\n",
    "    def __getitem__(self,_):\n",
    "        idx=self._env_idx  # This is the current env that we are running on\n",
    "        if self._end_interation:self.stop_loop()\n",
    "        if self.at_start(idx,self.per_env_steps[idx]):self.reset_envs(idx)\n",
    "        \n",
    "        while True:\n",
    "            a,agent_s=self.pick_action(idx)\n",
    "            sp,r,d,_=self.envs[idx].step(a)\n",
    "            \n",
    "            exp=Experience(self.per_env_s[idx],sp,a,r,d,agent_s=ifnone(agent_s,[]))\n",
    "            \n",
    "            self.per_env_rewards[idx]+=r\n",
    "            self.per_env_s[idx]=sp\n",
    "            self.per_env_steps[idx]+=1\n",
    "            self.per_env_d[idx]=d\n",
    "            \n",
    "            if self.skip_loop(self.per_env_steps[idx],self.skip_n_steps,d):continue\n",
    "            \n",
    "            if self.is_last_step(self.per_env_d[idx],self.per_env_steps[idx],idx,len(self)):\n",
    "                self.total_rewards.append(self.per_env_rewards[idx])\n",
    "                self.total_steps.append(self.per_env_steps[idx])\n",
    "                self.per_env_steps[idx]=0\n",
    "                \n",
    "                self.cycle_env(idx,len(self.envs))\n",
    "                self._end_interation=True\n",
    "                \n",
    "            if self._getitem_as_exp:return exp\n",
    "            return exp.x,asdict(exp) # Must copy or else torch keeps only last tensor\n",
    "\n",
    "add_docs(ExperienceSourceDataset,\n",
    "         __init__='Provides an easy interface to iterate through an env or list of envs.\\n Some importants notes:\\n'\n",
    "                  'an iteration through a loop. This is the maximum steps, and may be less due to the environment ending early.\\n'\n",
    "                  '- `skip_n_steps` are the number of steps to skip in the returned elements. This can be seen as frame skipping.',\n",
    "        pick_action='Returns the action and learner\\'s `self.learn.model`\\'s state as determined by the learner for a state `self.s`'  \n",
    "                    'belonging to env `idx`. If the `self.learn` is None, a random action using the `action_space` from `self.envs[0]` is used.\\n\\n'\n",
    "                    'For the sake of clarity, the return type is Tuple[Tensor,Tensor] which can be understood as [a,agent_s] or [action, agent state].\\n\\n'\n",
    "                    'While the returned action like `1`,`2` if discrete and `[0.2,0.5,0.2,0.1]` is a continuous action output, the agent state\\n'\n",
    "                    'is simply the raw values are were used to get the action. This information can be useful where for example we have an agent playing\\n'\n",
    "                    'the cartpole game. The action can either be `0` or `1`. This is considered the \"action\".\\n'\n",
    "                    'The agent state is the result of `self.learn.model(self.s)`. This is the raw `nn.Module` output and in the cartpole env case, is likely a\\n'\n",
    "                    'tensor of `Tensor([0.35,0.75])`, which for a discrete agent would an action of `1`. (we do an argmax, thus the action is which ever \\n'\n",
    "                    'neuron has the highest expected reward. This can be used to determine how confident the agent was when taking an action.',\n",
    "        is_last_step='An env has reached it\\'s last step when it is either `d` is true or `steps` is more than or equal to `self.max_steps-1`. '\n",
    "                     'The reason this method has so many parameters is due to the use of `log_args` decorator. Having these all these parameters passed on makes '\n",
    "                     'debugging much easier.',\n",
    "        cycle_env='Increments the private `self._step` field to cyucle through the envs. Requires passing in parameters for easy debugging using `log_args`.',\n",
    "        stop_loop='Raises the `StopIteration` exception and resets the `self._end_interation=False`. Used when the current env is done.',\n",
    "        reset_envs='Performs a very interesting function for reseting all the envs. One might wonder \"why not reset the envs individually?\". The reason\\n '\n",
    "                   'is that performing a reset within a single process for most `gym` envs actually resets the overall renderer. This means that if you reset\\n '\n",
    "                   'one env, it affects all the others that haven\\'t finished yet. In order to avoid this issue,\\n '\n",
    "                   'we only reset when all the envs are ready to be reset. The `idx` is here only for debugging.',\n",
    "        at_start='Similar to `is_last_step`. We determine that the dataset as looped through all the envs and needs to reset them.\\n '\n",
    "                 'We have all the important params passed in for debugging via `log_args`.',\n",
    "        pop_total_rewards='Returns and clears the `total_rewards` fields. Each element of total reward is a single episode or full iteration through an env.',\n",
    "        pop_reward_steps='Returns and clears the `total_rewards` and `total_steps` fields. Each element in each represents data over a single episode.',\n",
    "        skip_loop='If the current step should be skipped per `self.skip-step` and the current step is not done then we have the loop do a pass over.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 01:56:45] p22390 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"CartPole-v1\",n_envs=15,max_steps=50,skip_n_steps=1)\n",
    "bs=10\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "yb_data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "    yb_data.append(yb)\n",
    "assert bool(final_yb['d'][-1])\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 01:56:48] p22390 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=1)\n",
    "bs=10\n",
    "mountain_car_steps=200\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "test_eq(sum([len(o) for o in data]),mountain_car_steps)\n",
    "# assert bool(final_yb['d'][-1]),final_yb['d'][-1] MountainCar will likely not be done without some intervention.\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()\n",
    "\n",
    "r=ds.pop_total_rewards()[0]\n",
    "test_eq(r,-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 01:56:48] p22390 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=2)\n",
    "bs=10\n",
    "mountain_car_steps=200//2 # If we skip 2 steps, this should be 100\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "test_eq(sum([len(o) for o in data]),mountain_car_steps)\n",
    "# assert bool(final_yb['d'][-1]),final_yb['d'][-1] MountainCar will likely not be done without some intervention.\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()\n",
    "\n",
    "r=ds.pop_total_rewards()[0]\n",
    "test_eq(r,-200) # r should still be -200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 01:56:50] p22390 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=1,pixels=True)\n",
    "bs=10\n",
    "mountain_car_steps=200\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "    \n",
    "test_eq(data[0].shape,(bs,400,600,3))\n",
    "test_eq(sum([len(o) for o in data]),mountain_car_steps)\n",
    "# assert bool(final_yb['d'][-1]),final_yb['d'][-1] MountainCar will likely not be done without some intervention.\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()\n",
    "\n",
    "r,steps=ds.pop_reward_steps()[0]\n",
    "test_eq(r,-200)\n",
    "test_eq(steps,200)\n",
    "test_eq(len(ds.pop_reward_steps()),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class FirstLastExperienceSourceDataset(ExperienceSourceDataset):\n",
    "    \"Similar to `ExperienceSourceDataset` but only keeps the first and last parts of a step. Can be seen as frame skipping.\"\n",
    "    def __init__(self,*args,discount=0.99,skip_n_steps=1,**kwargs):\n",
    "        super(FirstLastExperienceSourceDataset,self).__init__(*args,skip_n_steps=1,**kwargs)\n",
    "        self.discount=discount\n",
    "        self.fst_lst_steps=skip_n_steps\n",
    "        self._getitem_as_exp=True\n",
    "    \n",
    "    @log_args\n",
    "    def __getitem__(self,_):\n",
    "        exp_ls=[]\n",
    "        while True:\n",
    "            exp=super(FirstLastExperienceSourceDataset,self).__getitem__(_)\n",
    "            exp_ls.append(exp)\n",
    "            if len(exp_ls)>=self.fst_lst_steps or self._end_interation:break\n",
    "\n",
    "        exp=exp_ls[-1]\n",
    "        exp.x=exp_ls[0].x\n",
    "\n",
    "        total_reward=0.0\n",
    "        for e in reversed(exp_ls):\n",
    "            total_reward*=self.discount\n",
    "            total_reward+=e.r\n",
    "        exp.r=total_reward\n",
    "\n",
    "        return exp.x,asdict(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 01:56:52] p22390 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "ds=FirstLastExperienceSourceDataset(\"CartPole-v1\",n_envs=15,skip_n_steps=4)\n",
    "bs=128\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    test_eq(yb['r'][0],pytest.approx(3.99,0.1))\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 01:56:52] p22390 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=FirstLastExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=1)\n",
    "bs=10\n",
    "mountain_car_steps=200\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "test_eq(sum([len(o) for o in data]),mountain_car_steps) # Should be half since first last by default merges 2 steps\n",
    "# assert bool(final_yb['d'][-1]),final_yb['d'][-1] MountainCar will likely not be done without some intervention.\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()\n",
    "\n",
    "r=ds.pop_total_rewards()[0]\n",
    "test_eq(r,-200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Dataset Shower\n",
    "We can define a wrapper around a dataset which will show up to `rows * cols` environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DatasetDisplayWrapper(object):\n",
    "    def __init__(self,ds,rows=2,cols=2,max_w=800):\n",
    "        \"Wraps a ExperienceSourceDataset instance showing multiple envs in a `rows` by `cols` grid in a Jupyter notebook.\"\n",
    "        # Ref: https://stackoverflow.com/questions/1443129/completely-wrap-an-object-in-python\n",
    "        # We are basically Wrapping any instance of ExperienceSourceDataset (kind of cool right?)\n",
    "        self.__class__=type(ds.__class__.__name__,(self.__class__, ds.__class__),{})\n",
    "        self.__dict__=ds.__dict__\n",
    "        self.rows,self.cols,self.max_w=rows,cols,max_w\n",
    "        self.current_display=None\n",
    "        if not IN_NOTEBOOK: \n",
    "            _logger.warning('It seems you are not running in a notebook. Nothing is going to be displayed.')\n",
    "            return\n",
    "        \n",
    "        if self.envs[0].render('rgb_array') is None: self.envs[0].reset()\n",
    "        rdr=self.envs[0].render('rgb_array')\n",
    "        if rdr.shape[1]*self.cols>max_w:\n",
    "            _logger.warning('Max Width is %s but %s*%s is greater than. Decreasing the number of cols to %s, rows increase by %s',\n",
    "                            max_w,rdr.shape[1],self.cols,max_w%rdr.shape[1],max_w%rdr.shape[1])\n",
    "            self.cols=max_w%rdr.shape[1]\n",
    "            self.rows+=max_w%rdr.shape[1]\n",
    "        self.max_displays=self.cols*self.rows\n",
    "        self.current_display=np.zeros(shape=(self.rows*rdr.shape[0],self.cols*rdr.shape[1],rdr.shape[2])).astype('uint8')\n",
    "        _logger.info('%s, %s, %s, %s, %s',0,0//self.cols,0%self.cols,rdr.shape,self.current_display.shape)\n",
    "\n",
    "    def __getitem__(self,_):\n",
    "        idx=self._env_idx\n",
    "        o=super(DatasetDisplayWrapper,self).__getitem__(idx)\n",
    "        idx=idx%self.max_displays\n",
    "        if self.current_display is not None and idx<self.rows*self.cols:\n",
    "            display.clear_output(wait=True)\n",
    "            im=self.envs[idx].render(mode='rgb_array')\n",
    "            self.current_display[(idx//self.cols)*im.shape[0]:(idx//self.cols)*im.shape[0]+im.shape[0],\n",
    "                                 (idx%self.cols)*im.shape[1]:(idx%self.cols)*im.shape[1]+im.shape[1],:]=im\n",
    "            new_im=PIL.Image.fromarray(self.current_display)\n",
    "            display.display(new_im)\n",
    "        else:\n",
    "            display.display(PIL.Image.fromarray(self.current_display))\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400 at 0x7F68C276A110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=1,pixels=True)\n",
    "ds=DatasetDisplayWrapper(ds,1,1,800)\n",
    "dl=DataLoader(ds,batch_size=1,num_workers=0)\n",
    "for xb,yb in dl:pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExperienceSourceDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceSourceDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    def from_env(cls,env:str,n_envs=1,firstlast=False,display=False,max_steps=None,skip_n_steps=1,path:PathOrStr='.',add_valid=True,\n",
    "                 cols=1,rows=1,max_w=800,bs=1):\n",
    "        def create_ds(make_empty=False):\n",
    "            _ds_cls=FirstLastExperienceSourceDataset if firstlast else ExperienceSourceDataset\n",
    "            _ds=_ds_cls(env,max_steps=0 if make_empty else max_steps,skip_n_steps=skip_n_steps)\n",
    "            if display:_ds=DatasetDisplayWrapper(_ds,cols=cols,rows=rows,max_w=max_w)\n",
    "            return _ds\n",
    "            \n",
    "        dss=(create_ds(),create_ds(not add_valid))\n",
    "        return cls.create(*dss,bs=bs,num_workers=0)\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, train_ds:Dataset, valid_ds:Dataset, test_ds:Optional[Dataset]=None, path:PathOrStr='.', bs:int=64,\n",
    "               val_bs:int=None, num_workers:int=defaults.cpus, dl_tfms:Optional[Collection[Callable]]=None,\n",
    "               device:torch.device=None, collate_fn:Callable=data_collate, no_check:bool=False, **dl_kwargs)->'DataBunch':\n",
    "        \"Create a `DataBunch` from `train_ds`, `valid_ds` and maybe `test_ds` with a batch size of `bs`. Passes `**dl_kwargs` to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        dls = [DataLoader(d, b, shuffle=s, drop_last=s, num_workers=num_workers, **dl_kwargs) for d,b,s in\n",
    "               zip(datasets, (bs,val_bs,val_bs,val_bs), (False,False,False,False)) if d is not None]\n",
    "        return cls(*dls, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 01:56:59] p22390 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "data=ExperienceSourceDataBunch.from_env('CartPole-v1',n_envs=5,display=False,firstlast=False,add_valid=False,bs=5)\n",
    "for xb,yb in data.train_dl:\n",
    "    assert xb.shape[0]<=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGQCAIAAAD9V4nPAAAHS0lEQVR4nO3dy3ETQQBFUUw5CeLAYRCHnYbTsOMgDIiDMIaFKaDAH1kaaab7nrPUQtUr3dL0s3y1LMsHAKj6uPUBAGBLQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghAmhACkCaEAKQJIQBpQghj+P54t/URYE7XWx8AeJ7ywWVcLcuy9RmAX96M3+fbh8ucBDo8GoUd0Tm4PCEEIE0IAUgTQhiJBQ2sTghhX1wTwoUJIQBpQghAmhACkCaEMBh7GViXEMLu2MvAJQkhAGlCCECaEMJ4XBPCioQQ9sg1IVyMEAKQJoQApAkhAGlCCEOyl4G1CCHslL0MXIYQApAmhACkCSEAaUIIo7KXgVUIIeyXvQxcgBACkCaEAKQJIQzMNSGcTghh11wTwrkJIQBpQghAmhACkCaEMDZ7GTiREMLe2cvAWQkhAGlCCECaEMLwXBPCKYQQBuCaEM5HCAFIE0IA0oQQgDQhhBnYy8DRhBDGYC8DZyKEAKQJIQBpQghAmhDCJOxl4DhCCMOwl4FzEEIA0oQQgDQhhHm4JoQjCCGMxDUhrE4IAUgTQgDShBCANCGEqdjLwHsJIQzGXgbWJYQApAkhAGlCCLNxTQjvIoQApAkhjMdeBlYkhACkCSEAaUIIE7KXgcMJIQzJNSGsRQgBSBNCANKEEIA0IYQ52cvAgYQQRmUvA6sQQgDShBCANCGEabkmhEMIIQzMNSGcTggBSBNCANKEEIA0IYSZ2cvAm4QQxmYvAycSQgDShBCANCGEybkmhNcJIQBpQgjDs5eBUwghAGlCCECaEML87GXgFUIIM3BNCEcTQgDShBCANCEEIE0IIcFeBl4ihDAJexk4jhACkCaEAKQJIVS4JoRnCSHMwzUhHEEIAUgTQgDShBCANCGEEHsZ+J8QwlTsZeC9hBCANCEEIE0IAUgTQmixl4F/CCHMxl4G3kUIAUgTQti1q6Oc4z0Pf38YixBCzreH262PADsihDChm7vHrY8Aw7je+gDAeX398e/3vy+fZBL+8I0QZvZ/BV96EbKEEKYleHAIIYSi+/tvWx8B9kIIYU72MnAgIQQgTQihyHAUfhNCmNbrtfNn9fBECGFaN3ePz7bw6UWXiPDkalmWrc8AvOjEH/b8+2vfiuXzucFMhBB2bZ+/cO1zg5l4NAoAAFDl0SjsmkejcG4ejQKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQ5r9PAJDmGyEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACk/QTN8YWGYsFtngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400 at 0x7F6853FF8FD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=ExperienceSourceDataBunch.from_env('CartPole-v1',n_envs=5,display=True,firstlast=True,add_valid=False,bs=5)\n",
    "for xb,yb in data.train_dl:\n",
    "    assert len(xb)<=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async ExperienceSources\n",
    "\n",
    "Async Experience sources have the challenge of running single process ExperienceSources in separate threads. Some questions are how rigid we want to make the actual fit look.\n",
    "\n",
    "There are currently 2 ways to setup an Async dataset:\n",
    "- Agent gets the data collected from the child processes. The model gets updated on the main thread which intern reflects in the child processes.\n",
    "- A sub learner runs inside each process and fits up until the back prop. Instead of doing back prop in the process, we collect the gradients and update them in the main thread. \n",
    "\n",
    "The first one is farely straight forward and only requires the model, the agent, and an uninstantiated Dataset.\n",
    "The second is more complex. We basically have 2 fit procedures shared between the main process and the child processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export            \n",
    "def getattrsoftly(o:Optional[object],name:str,default):return getattr(o,name,default) if o is not None else default\n",
    "def arginpartial(fn,arg_v):return arg_v in fn.args if fn.__class__==partial else False\n",
    "def dequeuesoftly(q:mp.Queue,e:mp.Event,n_attempts=5,warnings=False):\n",
    "    entry=None\n",
    "    count=0\n",
    "    while not e.is_set():\n",
    "        try:\n",
    "            entry=q.get_nowait()\n",
    "            count=0\n",
    "            break\n",
    "        except Empty:\n",
    "            if e.is_set():break\n",
    "            e.wait(count/10)\n",
    "            count+=1\n",
    "            if count>n_attempts:\n",
    "                _logger.warning('Breaking')\n",
    "                break\n",
    "            if warnings:_logger.warning('Queue was empty. At count: %s',count)\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AsyncException(Exception):pass\n",
    "\n",
    "class AsyncExperienceSourceCallback(LearnerCallback):\n",
    "    _order = -11\n",
    "    def current_ds(self):\n",
    "        return (self.learn.data.train_ds if self.learn.model.training or self.learn.data.empty_val else\n",
    "                self.learn.data.valid_ds)\n",
    "    \n",
    "    def on_train_begin(self,**kwargs):\n",
    "        for ds in [self.learn.data.train_ds,None if self.learn.data.empty_val else self.learn.data.valid_ds]:\n",
    "            if ds is not None:\n",
    "                ds.learn=self.learn\n",
    "                ds.start_procs()\n",
    "                \n",
    "                \n",
    "    def on_epoch_begin(self,**kwargs):\n",
    "        if not self.learn.data.empty_val:self.current_ds().unpause()    \n",
    "    def on_batch_end(self,**kwargs):\n",
    "        if not self.learn.data.empty_val:self.current_ds().pause()\n",
    "    def on_train_end(self,**kwargs):\n",
    "        for ds in [self.learn.data.train_ds,None if self.learn.data.empty_val else self.learn.data.valid_ds]:\n",
    "            if ds is not None:ds.end_procs()\n",
    "\n",
    "def _fitter(model:Optional[nn.Module],learner_cls:Optional['AgentLearner'],agent:Optional['BaseAgent'],ds_cls:ExperienceSourceDataset,\n",
    "            pause_event:mp.Event,cancel_event:mp.Event,main_queue:Optional[mp.JoinableQueue],metric_queue:Optional[mp.JoinableQueue]):\n",
    "    \"Default fitter for AsyncExperienceSourceDataset.\"\n",
    "    ds=ds_cls()\n",
    "    dl=DataLoader(ds,batch_size=1,num_workers=0)\n",
    "    if learner_cls is not None:\n",
    "        learn=learner_cls(data=DataBunch(dl,dl),model=model,agent=agent)\n",
    "        ds.learn=learn\n",
    "    try:\n",
    "        while not cancel_event.is_set():\n",
    "            for xb,yb in ds:\n",
    "                while pause_event.is_set() and not self.cancel_event.is_set():cancel_event.wait(0.1)\n",
    "                if main_queue is not None:main_queue.put(yb)\n",
    "            if metric_queue is not None:\n",
    "                total_rewards=ds.pop_total_rewards()\n",
    "                if total_rewards:\n",
    "                    if metric_queue.full():_logger.warning('Metric queue is full. Increase its size,empty it, or set metric_queue to None.')\n",
    "                    metric_queue.put(TotalRewards(total_rewards))                    \n",
    "            while pause_event.is_set():pass\n",
    "    finally:\n",
    "        main_queue.put(None)\n",
    "        metric_queue.put(None)\n",
    "        cancel_event.set()\n",
    "        sys.stdout.flush()\n",
    "\n",
    "@dataclass\n",
    "class AsyncExperienceSourceDataset(Dataset):\n",
    "    env:str\n",
    "    ds_cls:ExperienceSourceDataset.__class__\n",
    "    bs:Optional[int]=1\n",
    "    learn:Optional[Learner]=None\n",
    "    callback_fns:List[LearnerCallback]=field(default_factory=lambda:[AsyncExperienceSourceCallback])\n",
    "    n_processes:int=1\n",
    "    pause_event:mp.Event=mp.Event()\n",
    "    cancel_event:mp.Event=mp.Event()   \n",
    "    queue_sz:Optional[int]=None\n",
    "    main_queue:Optional[mp.JoinableQueue]=None\n",
    "    metric_queue:Optional[mp.JoinableQueue]=None\n",
    "    _proc_list:List[mp.Process]=field(default_factory=list)\n",
    "    fitter_fn:Optional[Callable]=None\n",
    "    fitter_kwargs:Dict=None\n",
    "    ds_kwargs:Dict=field(default_factory=dict)\n",
    "    learner_kwargs:Dict=field(default_factory=dict)\n",
    "    dequeue_warnings:bool=False\n",
    "    dequeue_n_attempts:int=50\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not arginpartial(self.ds_cls,self.env):self.ds_cls=partial(self.ds_cls,self.env)\n",
    "        \n",
    "        self.fitter_fn=self.get_fitter_fn()\n",
    "        self.queue_sz=ifnone(self.queue_sz,self.n_processes)\n",
    "        self.main_queue=ifnone(self.main_queue,mp.JoinableQueue(self.queue_sz))\n",
    "        if self.queue_sz!=0:self.dequeue_n_attempts//=self.queue_sz\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start_procs()\n",
    "        return self\n",
    "    \n",
    "    def __len__(self):return self.bs\n",
    "    \n",
    "    def __exit__(self,*exc):\n",
    "        self.end_procs()\n",
    "        return False\n",
    "    \n",
    "    def get_fitter_fn(self):return getattrsoftly(self.learn,'fitter_fn',ifnone(self.fitter_fn,_fitter))\n",
    "    def init_fitter_kwargs(self):\n",
    "        ds_cls=partial(self.ds_cls,**self.ds_kwargs)\n",
    "        fitter_kwargs=ifnone(self.fitter_kwargs,{'model':getattrsoftly(self.learn,'model',None),\n",
    "                                                 'agent':getattrsoftly(self.learn,'agent',None),\n",
    "                                                 'learner_cls':getattrsoftly(self.learn,'__class__',None),\n",
    "                                                 'ds_cls':ds_cls})\n",
    "        for k,v in zip(('pause_event','cancel_event','main_queue','metric_queue'),\n",
    "                       (self.pause_event,self.cancel_event,self.main_queue,self.metric_queue)):\n",
    "            fitter_kwargs[k]=fitter_kwargs.get(k,v)\n",
    "        if fitter_kwargs['learner_cls'] is not None:\n",
    "            fitter_kwargs['learner_cls']=partial(fitter_kwargs['learner_cls'],**self.learner_kwargs)\n",
    "        return fitter_kwargs\n",
    "        \n",
    "    def start_procs(self):\n",
    "        fitter_kwargs=self.init_fitter_kwargs()\n",
    "        if self.learn is None:                   _logger.warning('`self.learn` is None. Async\\'s ds_cls will likely use random actions.')\n",
    "        elif not hasattr(self.learn,'fitter_fn'):_logger.warning('`self.learn` does not have a `fitter_fn`. Using default.')\n",
    "        for e in (self.cancel_event,self.pause_event):e.clear()\n",
    "        if len(self._proc_list)!=0:raise AsyncException('There are existing processes. Call: `end_procs`')\n",
    "        self.populate_proc_list(self.get_fitter_fn(),fitter_kwargs)\n",
    "        for o in self._proc_list:o.start()\n",
    "            \n",
    "    def populate_proc_list(self,fitter_fn,fitter_kwargs):\n",
    "        self._proc_list=[mp.Process(target=fitter_fn,kwargs=fitter_kwargs) for _ in range(self.n_processes)]\n",
    "        \n",
    "    def end_procs(self):\n",
    "        self.cancel_event.set()\n",
    "        for q in [v for v in self.__dict__.values() if isinstance(mp.JoinableQueue,type(v))]:self.q_empty(q)\n",
    "        for p in self._proc_list:\n",
    "            p.join(timeout=0)\n",
    "            p.terminate()\n",
    "        self._proc_list.clear()\n",
    "        \n",
    "    def pause(self):self.pause_event.set()\n",
    "    def unpause(self):self.pause_event.clear()\n",
    "        \n",
    "    def q_empty(self,q:mp.JoinableQueue):\n",
    "        while not q.empty():q.get()\n",
    "            \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            try:yield self.__getitem__(None)\n",
    "            except StopIteration:return\n",
    "            \n",
    "    def __getitem__(self,_):\n",
    "        if len(self._proc_list)==0:raise StopIteration()\n",
    "        train_entry=dequeuesoftly(self.main_queue,self.cancel_event,self.dequeue_n_attempts,self.dequeue_warnings)\n",
    "        if train_entry is None:raise StopIteration()\n",
    "        return [Experience(**train_entry).x],train_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 02:05:56] p22390 line:106 WARNING - `self.learn` does not have a `fitter_fn`. Using default.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastrl.basic_train import AgentLearner\n",
    "from fastcore.test import test_eq\n",
    "\n",
    "bs=4\n",
    "\n",
    "class FakeRunCallback(LearnerCallback):\n",
    "    def on_backward_begin(self,*args,**kwargs): return {'skip_bwd':True,'skip_validate':True}\n",
    "    def on_batch_begin(self,last_target,last_input,*args,**kwargs):\n",
    "        test_eq(len(last_target['s']),bs)\n",
    "        test_eq(last_input[0].shape[0],bs)\n",
    "\n",
    "ds=AsyncExperienceSourceDataset('CartPole-v1',ExperienceSourceDataset,bs=bs,n_processes=4,dequeue_warnings=False)\n",
    "ds_empty=AsyncExperienceSourceDataset('CartPole-v1',ExperienceSourceDataset,bs=0,n_processes=0,dequeue_warnings=False)\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "dl_empty=DataLoader(ds_empty,batch_size=bs,num_workers=0)\n",
    "data=DataBunch(dl,dl_empty)\n",
    "\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback])\n",
    "learn.fit(10,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 02:06:04] p22390 line:105 WARNING - `self.learn` is None. Async's ds_cls will likely use random actions.\n",
      "[08-21 02:06:04] p22548 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "bs=40\n",
    "ds=AsyncExperienceSourceDataset('CartPole-v1',ExperienceSourceDataset,bs=bs,n_processes=1,dequeue_warnings=False)\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "\n",
    "batch_shapes=[]\n",
    "full_data=[]\n",
    "with ds:\n",
    "    for xb,yb in dl:\n",
    "        batch_shapes.append(xb[0].shape)\n",
    "        full_data.append(yb)\n",
    "        if len(batch_shapes)-2>bs:raise AsyncException('batch_shapes should not be larger than the `ds.bs`*`ds.max_steps`')\n",
    "        if batch_shapes[0][0]-2>bs:raise AsyncException('batch_shapes should not be larger than the `ds.bs`')\n",
    "\n",
    "test_eq(batch_shapes[0][0],bs)\n",
    "test_eq(full_data[0]['s'].shape[0],bs)\n",
    "test_eq(batch_shapes[0],(bs,4))\n",
    "test_eq(type(full_data[0]),dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 02:06:08] p22390 line:106 WARNING - `self.learn` does not have a `fitter_fn`. Using default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing action: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-21 02:06:10] p22390 line:106 WARNING - `self.learn` does not have a `fitter_fn`. Using default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing action: 0\n"
     ]
    }
   ],
   "source": [
    "from fastrl.basic_train import AgentLearner\n",
    "from fastcore.test import test_eq\n",
    "bs=90\n",
    "\n",
    "class AlwaysDiscreteRight(nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super(AlwaysDiscreteRight,self).__init__(*args,**kwargs)\n",
    "        self.a=1\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return FloatTensor([[0.1,0.5]])\n",
    "    \n",
    "class AlwaysDiscreteLeft(nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super(AlwaysDiscreteLeft,self).__init__(*args,**kwargs)\n",
    "        self.a=0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return FloatTensor([[0.5,0.1]])\n",
    "    \n",
    "for m in (AlwaysDiscreteRight(),AlwaysDiscreteLeft()):\n",
    "    print(f'Testing action: {m.a}')\n",
    "    ds=AsyncExperienceSourceDataset('CartPole-v1',ExperienceSourceDataset,bs=bs,n_processes=4,dequeue_warnings=False)\n",
    "    dl=DataLoader(ds,batch_size=bs,num_workers=12)\n",
    "\n",
    "    model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2),m)\n",
    "    agent=DQNAgent(model=model)\n",
    "    learn=AgentLearner(DataBunch(dl,dl),model,agent=agent)\n",
    "    ds.learn=learn\n",
    "\n",
    "    batch_shapes=[]\n",
    "    full_data=[]\n",
    "    with ds:\n",
    "        for xb,yb in dl:\n",
    "            batch_shapes.append(xb[0].shape)\n",
    "            full_data.append(copy(yb))\n",
    "            if len(batch_shapes)>bs:raise AsyncException('batch_shapes should not be larger than the `ds.bs`*`ds.max_steps`')\n",
    "            if batch_shapes[0][0]>bs:raise AsyncException('batch_shapes should not be larger than the `ds.bs`')\n",
    "    assert all(any(o['d']) for o in full_data if len(o['d'])==bs),'Dones are not being returned'\n",
    "    assert all(all([a==m.a for a in o['a']]) for o in full_data)\n",
    "    test_eq(sum(len(o['s']) for o in full_data),bs)\n",
    "    full_data.clear()\n",
    "    batch_shapes.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "add_docs(AsyncExperienceSourceDataset,\n",
    "        __init__='Asynchronous form of ExperienceSourceDataset. Requires using `with AsyncExperienceSourceDataset():` or calling `start_procs()`'\n",
    "        ' before looping and `end_procs()` after looking. Using the context manager would be better due to exception handling so we can avoid any'\n",
    "        ' hanging processes. Returns the data samples from all processes, however can be modfied to behave differently.',\n",
    "        start_procs='Start the background processes for the environments. Also called in the context manager `__enter__` method.',\n",
    "        end_procs='End the processes cleanly. Also called in the context manager `__exit__` method.',\n",
    "        pause='Will cause the environments to stop iterating through episodes. Used for switching between test and train datasets.',\n",
    "        unpause='Allows environments to continue iterating.',\n",
    "        populate_proc_list='Initializes the process list `_proc_list`.',\n",
    "        q_empty='Goes through all `mp.JoinableQueue` queues and empties them. This is typically done during `end_procs`',\n",
    "        init_fitter_kwargs='Key work args to pass to the `fitter_fn`.',\n",
    "        get_fitter_fn='Returns a `fitter_fn` defined in `self.learn` else try the default field.'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def _grad_fitter(model:Optional[nn.Module],learner_cls:Optional['AgentLearner'],agent:Optional['BaseAgent'],ds_cls:ExperienceSourceDataset,\n",
    "            pause_event:mp.Event,cancel_event:mp.Event,main_queue:Optional[mp.JoinableQueue],metric_queue:Optional[mp.JoinableQueue]):\n",
    "    \"Default fitter for AsyncGradExperienceSourceDataset.\"\n",
    "    ds=ds_cls()\n",
    "    dl=DataLoader(ds,batch_size=1,num_workers=0)\n",
    "\n",
    "    if learner_cls is not None:\n",
    "        learn=learner_cls(data=DataBunch(dl,dl),model=model,agent=agent)\n",
    "        ds.learn=learn\n",
    "    try:\n",
    "        while not cancel_event.is_set():\n",
    "            for xb,yb in ds:\n",
    "                while pause_event.is_set() and not self.cancel_event.is_set():cancel_event.wait(0.1)\n",
    "                if main_queue is not None:\n",
    "                    loss=0.5 # Place holder\n",
    "                    main_queue.put((xb,{'loss':loss,**yb}))\n",
    "            if metric_queue is not None:\n",
    "                total_rewards=ds.pop_total_rewards()\n",
    "                if total_rewards:\n",
    "                    if metric_queue.full():_logger.warning('Metric queue is full. Increase its size,empty it, or set metric_queue to None.')\n",
    "                    metric_queue.put(TotalRewards(total_rewards))                    \n",
    "            while pause_event.is_set():pass\n",
    "    finally:\n",
    "        main_queue.put(None)\n",
    "        metric_queue.put(None)\n",
    "        cancel_event.set()\n",
    "        sys.stdout.flush()\n",
    "\n",
    "class AsyncGradExperienceSourceDataset(AsyncExperienceSourceDataset): \n",
    "    def __post_init__(self):\n",
    "        self.fitter_fn=ifnone(self.fitter_fn,_grad_fitter)\n",
    "        super(AsyncGradExperienceSourceDataset,self).__post_init__()\n",
    "        \n",
    "    def __getitem__(self,_):\n",
    "        if len(self._proc_list)==0:raise StopIteration()\n",
    "        gradients,loss=dequeuesoftly(self.main_queue,self.cancel_event,self.dequeue_n_attempts,self.dequeue_warnings)\n",
    "        if gradients is None:raise StopIteration()\n",
    "        return [gradients],[loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeRunCallback(LearnerCallback):\n",
    "    def on_backward_begin(self,*args,**kwargs): return {'skip_bwd':True,'skip_validate':True}\n",
    "    \n",
    "bs=40\n",
    "\n",
    "ds=AsyncGradExperienceSourceDataset('CartPole-v1',ExperienceSourceDataset,bs=bs,n_processes=4,dequeue_warnings=False)\n",
    "ds_empty=AsyncGradExperienceSourceDataset('CartPole-v1',ExperienceSourceDataset,bs=0,n_processes=0,dequeue_warnings=False)\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "dl_empty=DataLoader(ds_empty,batch_size=bs,num_workers=0)\n",
    "data=DataBunch(dl,dl_empty)\n",
    "\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback])\n",
    "learn.fit(3,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=40\n",
    "ds=AsyncGradExperienceSourceDataset('CartPole-v1',ExperienceSourceDataset,bs=bs,n_processes=1,dequeue_warnings=False)\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=12)\n",
    "\n",
    "batch_shapes=[]\n",
    "full_data=[]\n",
    "with ds:\n",
    "    for xb,yb in dl:\n",
    "        batch_shapes.append(xb[0].shape)\n",
    "        full_data.append(yb)\n",
    "        if len(batch_shapes)-2>bs:raise AsyncException('batch_shapes should not be larger than the `ds.bs`*`ds.max_steps`')\n",
    "        if batch_shapes[0][0]-2>bs:raise AsyncException('batch_shapes should not be larger than the `ds.bs`')\n",
    "\n",
    "test_eq(batch_shapes[0][0],bs)\n",
    "test_eq(full_data[0][0]['loss'].shape[0],bs)\n",
    "test_eq(batch_shapes[0],(bs,4))\n",
    "test_eq(type(full_data[0]),list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "add_docs(AsyncGradExperienceSourceDataset,\n",
    "         textwrap.fill(\"\"\"The `AsyncGradExperienceSourceDataset` class is instantiated via passing \n",
    "         the `env_name` that we want to train on, and a `partial` class of a `ExperienceSourceDataset` called `ds_cls`.\n",
    "         `bs` is a field here since the length of the dataset is not necessarily the length of an episode. If `None` it will be the length\n",
    "         of a single episode of the environment. Agents such as A3C will likely change this.\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AsyncExperienceSourceDataBunch(ExperienceSourceDataBunch):\n",
    "    @classmethod\n",
    "    def from_env(cls,env,bs=16,use_grad_experience=False,firstlast=False,n_processes=defaults.cpus,num_workers:int=defaults.cpus,queue_sz=None,add_valid=False,\n",
    "                fitter_fn=None,ds_kwargs:Dict=None,fitter_kwargs:Dict=None,learner_kwargs:Dict=None):\n",
    "        def create_ds(make_empty=False):\n",
    "            _sub_ds_cls=FirstLastExperienceSourceDataset if firstlast else ExperienceSourceDataset\n",
    "            _ds_cls=AsyncGradExperienceSourceDataset if use_grad_experience else AsyncExperienceSourceDataset\n",
    "            _ds=_ds_cls(env,bs=0 if make_empty else bs,ds_cls=_sub_ds_cls,n_processes=n_processes,queue_sz=queue_sz,fitter_fn=fitter_fn,\n",
    "                        ds_kwargs=ifnone(ds_kwargs,{}),fitter_kwargs=fitter_kwargs,learner_kwargs=ifnone(learner_kwargs,{}))\n",
    "            return _ds\n",
    "            \n",
    "        return cls.create(create_ds(),create_ds(not add_valid),bs=bs,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=16\n",
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',bs=bs)\n",
    "\n",
    "batch_shapes=[]\n",
    "full_data=[]\n",
    "with data.train_ds:\n",
    "    for xb,yb in data.train_dl:\n",
    "        batch_shapes.append(xb[0].shape)\n",
    "        full_data.append(yb)\n",
    "        if len(batch_shapes)>bs:raise AsyncException('batch_shapes should not be larger than `bs`')\n",
    "        if batch_shapes[0][0]>bs:raise AsyncException('batch_shapes should not be larger than `bs`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1')\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback]).fit(3,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',use_grad_experience=True)\n",
    "AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback]).fit(3,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',use_grad_experience=True,ds_kwargs={'skip_n_steps':4})\n",
    "AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback]).fit(3,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()\n",
    "notebook2html(n_workers=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
