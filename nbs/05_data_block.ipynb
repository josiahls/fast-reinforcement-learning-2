{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data_block\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Block\n",
    "\n",
    "> Primary handlers for interfacing the openai gym envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callbacks import *\n",
    "from fastrl.wrappers import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.metrics import *\n",
    "from dataclasses import asdict,dataclass,field\n",
    "from functools import partial\n",
    "from fastprogress.fastprogress import IN_NOTEBOOK\n",
    "from fastcore.utils import *\n",
    "from fastcore.foundation import *\n",
    "from torch.utils.data.dataset import IterableDataset\n",
    "import torch.multiprocessing as mp\n",
    "from functools import wraps\n",
    "from queue import Empty\n",
    "import textwrap\n",
    "import logging\n",
    "import gym\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s line:%(lineno)d %(levelname)s - %(message)s',\n",
    "                    datefmt='%m-%d %H:%M:%S')\n",
    "_logger=logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "_logger.setLevel('INFO')\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "`Dataset` instances are going to be a little different from the typically classification dataset that you might use in pytorch. Commonly, datasets have:\n",
    "- A known size to iter through\n",
    "- Maintain their state during the training sequence\n",
    "- Randomly sample their dataset\n",
    "- Have a common `x`/`y` or `input`/`target` data format\n",
    "\n",
    "For our `ExperienceSourceDataset`, most of this is going to be different. \n",
    "- We can have multiple sources (envs)\n",
    "\n",
    "You could think of a traditional dataset approach as being a mix of a `ExperienceSourceDataset` and a form of `ExperienceReplay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class Experience(object):\n",
    "    s:np.array\n",
    "    sp:np.array\n",
    "    a:np.array\n",
    "    r:np.array\n",
    "    d:np.array\n",
    "    agent_s:np.array\n",
    "        \n",
    "    @property\n",
    "    def x(self):return self.s.copy()\n",
    "    @x.setter\n",
    "    def x(self,v):self.s=v.copy()\n",
    "\n",
    "add_docs(Experience,x='Should return the field for `xb` in the training loop. It must be copied on return or'\n",
    "         ' else there will be strange multiple reference errors.'\n",
    "         'This is intended to be fed directly into a model. The `self.s.copy()` is a single tensor to be directly fed into a regular nn.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': array([[2, 1, 1, 2, 2],\n",
       "        [2, 1, 1, 1, 2],\n",
       "        [2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 2],\n",
       "        [2, 2, 2, 1, 2]]),\n",
       " 'sp': array([[2, 2, 1, 1, 2],\n",
       "        [2, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 2],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 1]]),\n",
       " 'a': array([[1, 2]]),\n",
       " 'r': array([[1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2]]),\n",
       " 'd': array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]]),\n",
       " 'agent_s': array([[5, 4, 4, 3, 3]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp=Experience(s=np.random.randint(1,3,(5,5)),\n",
    "               sp=np.random.randint(1,3,(5,5)),\n",
    "               a=np.random.randint(1,3,(1,2)),\n",
    "               r=np.random.randint(1,3,(1,20)),\n",
    "               d=np.random.randint(0,1,(5,5)),\n",
    "               agent_s=np.random.randint(0,6,(1,5)))\n",
    "asdict(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a couple constraints on what the `ExperienceSourceDataset` is going to look like. For `__getitem__` it should return a tuple of 2 elements:\n",
    "\n",
    "- `xb` which are the elements that are going to be directly fed into the model for getting actions.\n",
    "- `yb` which are all of the elements provided by the environment that we can use for training.\n",
    "\n",
    "Some semantics:\n",
    "- `iter` means what is returned from `next(dataset)` for farthur what is returned from `[o for o in dataset]`.\n",
    "- `step` means an individual step in the env. You can have multiple steps per `iter`.\n",
    "- `batch_size` is the same thing as `step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceSourceCallback(LearnerCallback):\n",
    "    def on_train_begin(self,*args,**kwargs):\n",
    "        self.learn.data.train_dl.dataset.learn=self.learn\n",
    "        if not self.learn.data.empty_val:\n",
    "            self.learn.data.valid_dl.dataset.learn=self.learn\n",
    "\n",
    "@dataclass\n",
    "class ExperienceSourceDataset(IterableDataset):\n",
    "    \"Similar to fastai's `LabelList`, iters in-order samples from `1->len(envs)` `envs`.\"\n",
    "    env:str\n",
    "    n_envs:int=1\n",
    "    learn:Optional[Learner]=None\n",
    "    callback_fns:List[LearnerCallback]=field(default_factory=lambda:[ExperienceSourceCallback])\n",
    "    # Behavior modification fields / param fields.\n",
    "    skip_n_steps:int=1\n",
    "    max_steps:Optional[int]=None\n",
    "    pixels:bool=False\n",
    "    # Env tracking fields\n",
    "    per_env_d:np.array=None\n",
    "    per_env_s:np.array=None\n",
    "    per_env_steps:np.array=None\n",
    "    per_env_rewards:np.array=None\n",
    "    # Metric fields\n",
    "    total_rewards:List=field(default_factory=list)\n",
    "    total_steps:List=field(default_factory=list)\n",
    "    # Private funcational fields.\n",
    "    _env_idx:int=0\n",
    "    _warned:bool=False\n",
    "    _end_interation:bool=False\n",
    "    _getitem_as_exp:bool=False\n",
    "    \n",
    "    \n",
    "#     def __init__(self,env:str,n_envs=1,skip_n_steps=1,max_steps=None,pixels=False):\n",
    "    def __post_init__(self):\n",
    "        def make_env():\n",
    "            env_o=gym.make(self.env)\n",
    "            if self.pixels:env_o.reset()\n",
    "            return env_o\n",
    "            \n",
    "        self.envs=[make_env() for _ in range(self.n_envs)]\n",
    "        if self.pixels:self.envs=[PixelObservationWrapper(e) for e in self.envs]\n",
    "            \n",
    "        self.per_env_d:np.array=np.zeros((len(self.envs),))+1\n",
    "        self.per_env_s:np.array=np.zeros((len(self.envs),*self.envs[0].observation_space.sample().shape))\n",
    "        self.per_env_steps:np.array=np.zeros((len(self.envs)))\n",
    "        self.per_env_rewards:np.array=np.zeros((len(self.envs)))\n",
    "        \n",
    "    def __len__(self): return ifnone(self.max_steps,self.envs[0].spec.max_episode_steps)\n",
    "    @log_args\n",
    "    def is_last_step(self,d,steps,idx,max_steps)->bool:return bool(d) or steps>=max_steps\n",
    "    @log_args\n",
    "    def at_start(self,idx,steps):return idx==0 and steps==0\n",
    "    @log_args\n",
    "    def skip_loop(self,steps,skip_steps,d):return steps%skip_steps!=0 and not d\n",
    "    @log_args\n",
    "    def cycle_env(self,idx,n_envs):self._env_idx=0 if idx==n_envs-1 else idx+1\n",
    "    def stop_loop(self):\n",
    "        self._end_interation=False\n",
    "        raise StopIteration()\n",
    "    @log_args\n",
    "    def reset_envs(self,idx):\n",
    "        for i,e in enumerate(self.envs):self.per_env_s[i]=e.reset() # TODO: There is the possiblity this will equal None (and crash)?\n",
    "        self.per_env_steps=np.zeros((len(self.envs)),dtype=int)\n",
    "        self.per_env_rewards=np.zeros((len(self.envs)))\n",
    "    @log_args\n",
    "    def pick_action(self,idx):\n",
    "        if self.learn is None:\n",
    "            if not self._warned:_logger.warning('`self.learn` is None. will use random actions instead.')\n",
    "            self._warned=True\n",
    "            return self.envs[0].action_space.sample(),np.zeros((1,1))\n",
    "        return self.learn.predict(self.per_env_s[idx])\n",
    "    \n",
    "    def pop_total_rewards(self):\n",
    "        total_rewards=self.total_rewards\n",
    "        if total_rewards:self.total_rewards,self.total_steps=[],[]\n",
    "        return total_rewards\n",
    "\n",
    "    def pop_reward_steps(self):\n",
    "        total_rewards,total_steps=self.total_rewards,self.total_steps\n",
    "        res=list(zip(total_rewards,total_steps))\n",
    "        if res:self.total_rewards,self.total_steps=[],[]\n",
    "        return res\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            try:\n",
    "                o=self.__getitem__(None)\n",
    "                yield o\n",
    "            except StopIteration:\n",
    "                return\n",
    "    \n",
    "    @log_args\n",
    "    def __getitem__(self,_):\n",
    "        idx=self._env_idx  # This is the current env that we are running on\n",
    "        if self._end_interation:self.stop_loop()\n",
    "        if self.at_start(idx,self.per_env_steps[idx]):self.reset_envs(idx)\n",
    "        \n",
    "        while True:\n",
    "            a,agent_s=self.pick_action(idx)\n",
    "            sp,r,d,_=self.envs[idx].step(a)\n",
    "            \n",
    "            exp=Experience(self.per_env_s[idx],sp,a,r,d,agent_s=ifnone(agent_s,[]))\n",
    "            \n",
    "            self.per_env_rewards[idx]+=r\n",
    "            self.per_env_s[idx]=sp\n",
    "            self.per_env_steps[idx]+=1\n",
    "            self.per_env_d[idx]=d\n",
    "            \n",
    "            if self.skip_loop(self.per_env_steps[idx],self.skip_n_steps,d):continue\n",
    "            \n",
    "            if self.is_last_step(self.per_env_d[idx],self.per_env_steps[idx],idx,len(self)):\n",
    "                self.total_rewards.append(self.per_env_rewards[idx])\n",
    "                self.total_steps.append(self.per_env_steps[idx])\n",
    "                self.per_env_steps[idx]=0\n",
    "                \n",
    "                self.cycle_env(idx,len(self.envs))\n",
    "                self._end_interation=True\n",
    "                \n",
    "            if self._getitem_as_exp:return exp\n",
    "            return exp.x,asdict(exp) # Must copy or else torch keeps only last tensor\n",
    "\n",
    "add_docs(ExperienceSourceDataset,\n",
    "         __init__='Provides an easy interface to iterate through an env or list of envs.\\n Some importants notes:\\n'\n",
    "                  'an iteration through a loop. This is the maximum steps, and may be less due to the environment ending early.\\n'\n",
    "                  '- `skip_n_steps` are the number of steps to skip in the returned elements. This can be seen as frame skipping.',\n",
    "        pick_action='Returns the action and learner\\'s `self.learn.model`\\'s state as determined by the learner for a state `self.s`'  \n",
    "                    'belonging to env `idx`. If the `self.learn` is None, a random action using the `action_space` from `self.envs[0]` is used.\\n\\n'\n",
    "                    'For the sake of clarity, the return type is Tuple[Tensor,Tensor] which can be understood as [a,agent_s] or [action, agent state].\\n\\n'\n",
    "                    'While the returned action like `1`,`2` if discrete and `[0.2,0.5,0.2,0.1]` is a continuous action output, the agent state\\n'\n",
    "                    'is simply the raw values are were used to get the action. This information can be useful where for example we have an agent playing\\n'\n",
    "                    'the cartpole game. The action can either be `0` or `1`. This is considered the \"action\".\\n'\n",
    "                    'The agent state is the result of `self.learn.model(self.s)`. This is the raw `nn.Module` output and in the cartpole env case, is likely a\\n'\n",
    "                    'tensor of `Tensor([0.35,0.75])`, which for a discrete agent would an action of `1`. (we do an argmax, thus the action is which ever \\n'\n",
    "                    'neuron has the highest expected reward. This can be used to determine how confident the agent was when taking an action.',\n",
    "        is_last_step='An env has reached it\\'s last step when it is either `d` is true or `steps` is more than or equal to `self.max_steps-1`. '\n",
    "                     'The reason this method has so many parameters is due to the use of `log_args` decorator. Having these all these parameters passed on makes '\n",
    "                     'debugging much easier.',\n",
    "        cycle_env='Increments the private `self._step` field to cyucle through the envs. Requires passing in parameters for easy debugging using `log_args`.',\n",
    "        stop_loop='Raises the `StopIteration` exception and resets the `self._end_interation=False`. Used when the current env is done.',\n",
    "        reset_envs='Performs a very interesting function for reseting all the envs. One might wonder \"why not reset the envs individually?\". The reason\\n '\n",
    "                   'is that performing a reset within a single process for most `gym` envs actually resets the overall renderer. This means that if you reset\\n '\n",
    "                   'one env, it affects all the others that haven\\'t finished yet. In order to avoid this issue,\\n '\n",
    "                   'we only reset when all the envs are ready to be reset. The `idx` is here only for debugging.',\n",
    "        at_start='Similar to `is_last_step`. We determine that the dataset as looped through all the envs and needs to reset them.\\n '\n",
    "                 'We have all the important params passed in for debugging via `log_args`.',\n",
    "        pop_total_rewards='Returns and clears the `total_rewards` fields. Each element of total reward is a single episode or full iteration through an env.',\n",
    "        pop_reward_steps='Returns and clears the `total_rewards` and `total_steps` fields. Each element in each represents data over a single episode.',\n",
    "        skip_loop='If the current step should be skipped per `self.skip-step` and the current step is not done then we have the loop do a pass over.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-18 17:32:01] p292 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"CartPole-v1\",n_envs=15,max_steps=50,skip_n_steps=1)\n",
    "bs=10\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "assert bool(final_yb['d'][-1])\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-18 17:32:03] p292 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=1)\n",
    "bs=10\n",
    "mountain_car_steps=200\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "test_eq(sum([len(o) for o in data]),mountain_car_steps)\n",
    "# assert bool(final_yb['d'][-1]),final_yb['d'][-1] MountainCar will likely not be done without some intervention.\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()\n",
    "\n",
    "r=ds.pop_total_rewards()[0]\n",
    "test_eq(r,-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-18 17:32:04] p292 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=2)\n",
    "bs=10\n",
    "mountain_car_steps=200//2 # If we skip 2 steps, this should be 100\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "test_eq(sum([len(o) for o in data]),mountain_car_steps)\n",
    "# assert bool(final_yb['d'][-1]),final_yb['d'][-1] MountainCar will likely not be done without some intervention.\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()\n",
    "\n",
    "r=ds.pop_total_rewards()[0]\n",
    "test_eq(r,-200) # r should still be -200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-18 17:32:06] p292 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=1,pixels=True)\n",
    "bs=10\n",
    "mountain_car_steps=200\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "    \n",
    "test_eq(data[0].shape,(bs,400,600,3))\n",
    "test_eq(sum([len(o) for o in data]),mountain_car_steps)\n",
    "# assert bool(final_yb['d'][-1]),final_yb['d'][-1] MountainCar will likely not be done without some intervention.\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()\n",
    "\n",
    "r,steps=ds.pop_reward_steps()[0]\n",
    "test_eq(r,-200)\n",
    "test_eq(steps,200)\n",
    "test_eq(len(ds.pop_reward_steps()),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class FirstLastExperienceSourceDataset(ExperienceSourceDataset):\n",
    "    \"Similar to `ExperienceSourceDataset` but only keeps the first and last parts of a step. Can be seen as frame skipping.\"\n",
    "    def __init__(self,*args,discount=0.99,skip_n_steps=1,**kwargs):\n",
    "        super(FirstLastExperienceSourceDataset,self).__init__(*args,skip_n_steps=1,**kwargs)\n",
    "        self.discount=discount\n",
    "        self.fst_lst_steps=skip_n_steps\n",
    "        self._getitem_as_exp=True\n",
    "    \n",
    "    @log_args\n",
    "    def __getitem__(self,_):\n",
    "        exp_ls=[]\n",
    "        while True:\n",
    "            exp=super(FirstLastExperienceSourceDataset,self).__getitem__(_)\n",
    "            exp_ls.append(exp)\n",
    "            if len(exp_ls)>=self.fst_lst_steps or self._end_interation:break\n",
    "\n",
    "        exp=exp_ls[-1]\n",
    "        exp.x=exp_ls[0].x\n",
    "\n",
    "        total_reward=0.0\n",
    "        for e in reversed(exp_ls):\n",
    "            total_reward*=self.discount\n",
    "            total_reward+=e.r\n",
    "        exp.r=total_reward\n",
    "\n",
    "        return exp.x,asdict(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-18 17:32:08] p292 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "ds=FirstLastExperienceSourceDataset(\"CartPole-v1\",n_envs=15,skip_n_steps=4)\n",
    "bs=10\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    test_eq(yb['r'][0],pytest.approx(3.99,0.1))\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-18 17:32:08] p292 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "ds=FirstLastExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=1)\n",
    "bs=10\n",
    "mountain_car_steps=200\n",
    "\n",
    "dl=DataLoader(ds,batch_size=bs,num_workers=0)\n",
    "final_yb=None\n",
    "data=[]\n",
    "for xb,yb in dl:\n",
    "    assert len(xb)<=bs\n",
    "    assert len(yb['s'])<=bs\n",
    "    assert len(yb['d'])<=bs\n",
    "    final_yb=yb\n",
    "    data.append(xb)\n",
    "\n",
    "test_eq(sum([len(o) for o in data]),mountain_car_steps) # Should be half since first last by default merges 2 steps\n",
    "# assert bool(final_yb['d'][-1]),final_yb['d'][-1] MountainCar will likely not be done without some intervention.\n",
    "if len(data)>1: # If there is more that 1 attempted batches, all the previous ones should be the correct size. The last one might be shorter\n",
    "    assert all(len(arr)==bs for arr in data[:-1])\n",
    "data.clear()\n",
    "\n",
    "r=ds.pop_total_rewards()[0]\n",
    "test_eq(r,-200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExperienceSourceDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceSourceDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    def from_env(cls,env:str,n_envs=1,firstlast=False,display=False,max_steps=None,skip_n_steps=1,path:PathOrStr='.',add_valid=True,\n",
    "                 cols=1,rows=1,max_w=800,bs=1):\n",
    "        def create_ds(make_empty=False):\n",
    "            _ds_cls=FirstLastExperienceSourceDataset if firstlast else ExperienceSourceDataset\n",
    "            _ds=_ds_cls(env,max_steps=0 if make_empty else max_steps,skip_n_steps=skip_n_steps)\n",
    "            if display:_ds=DatasetDisplayWrapper(_ds,cols=cols,rows=rows,max_w=max_w)\n",
    "            return _ds\n",
    "            \n",
    "        dss=(create_ds(),create_ds(not add_valid))\n",
    "        return cls.create(*dss,bs=bs,num_workers=0)\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, train_ds:Dataset, valid_ds:Dataset, test_ds:Optional[Dataset]=None, path:PathOrStr='.', bs:int=64,\n",
    "               val_bs:int=None, num_workers:int=defaults.cpus, dl_tfms:Optional[Collection[Callable]]=None,\n",
    "               device:torch.device=None, collate_fn:Callable=data_collate, no_check:bool=False, **dl_kwargs)->'DataBunch':\n",
    "        \"Create a `DataBunch` from `train_ds`, `valid_ds` and maybe `test_ds` with a batch size of `bs`. Passes `**dl_kwargs` to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        dls = [DataLoader(d, b, shuffle=s, drop_last=s, num_workers=num_workers, **dl_kwargs) for d,b,s in\n",
    "               zip(datasets, (bs,val_bs,val_bs,val_bs), (False,False,False,False)) if d is not None]\n",
    "        return cls(*dls, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-18 17:32:08] p292 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "data=ExperienceSourceDataBunch.from_env('CartPole-v1',n_envs=5,display=False,firstlast=False,add_valid=False,bs=5)\n",
    "for xb,yb in data.train_dl:\n",
    "    assert xb.shape[0]<=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-18 17:32:09] p292 line:69 WARNING - `self.learn` is None. will use random actions instead.\n"
     ]
    }
   ],
   "source": [
    "data=ExperienceSourceDataBunch.from_env('CartPole-v1',n_envs=5,display=False,firstlast=True,add_valid=False,bs=5)\n",
    "for xb,yb in data.train_dl:\n",
    "    assert len(xb)<=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async ExperienceSources\n",
    "\n",
    "Async Experience sources have the challenge of running single process ExperienceSources in separate threads. Some questions are how rigid we want to make the actual fit look.\n",
    "\n",
    "There are currently 2 ways to setup an Async dataset:\n",
    "- Agent gets the data collected from the child processes. The model gets updated on the main thread which intern reflects in the child processes.\n",
    "- A sub learner runs inside each process and fits up until the back prop. Instead of doing back prop in the process, we collect the gradients and update them in the main thread. \n",
    "\n",
    "The first one is farely straight forward and only requires the model, the agent, and an uninstantiated Dataset.\n",
    "The second is more complex. We basically have 2 fit procedures shared between the main process and the child processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "getattr(object, name[, default]) -> value\n",
       "\n",
       "Get a named attribute from an object; getattr(x, 'y') is equivalent to x.y.\n",
       "When a default argument is given, it is returned when the attribute doesn't\n",
       "exist; without it, an exception is raised in that case.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getattr??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def getattrsoftly(o:Optional[object],name:str,default):return getattr(o,name,default) if o is not None else default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AsyncExperienceSourceCallback(LearnerCallback):pass\n",
    "\n",
    "def _fitter(model:nn.Module,agent:BaseAgent,ds:ExperienceSourceDataset):pass\n",
    "\n",
    "@dataclass\n",
    "class AsyncExperienceSourceDataset(Dataset):\n",
    "    env:str\n",
    "    ds_cls:ExperienceSourceDataset.__class__\n",
    "    n_envs:int=1\n",
    "    learn:Optional[Learner]=None\n",
    "    callback_fns:List[LearnerCallback]=field(default_factory=lambda:[AsyncExperienceSourceCallback])\n",
    "    n_processes:int=1\n",
    "    bs:int=1\n",
    "    pause_event:mp.Event=mp.Event()\n",
    "    cancel_event:mp.Event=mp.Event()   \n",
    "    queue_sz:Optional[int]=None\n",
    "    metric_queue:Optional[mp.JoinableQueue]=None\n",
    "    fitter_fn:Optional[Callable]=_fitter\n",
    "    fitter_kwargs:Dict=None\n",
    "    _proc_list:List[mp.Process]=field(default_factory=list)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.queue_sz=ifnone(self.queue_sz,self.n_processes)\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.start_procs()\n",
    "        return self\n",
    "    \n",
    "    def __len__(self):return self.bs\n",
    "    \n",
    "    def __exit__(self,*exc):\n",
    "        return False\n",
    "    \n",
    "    def start_procs(self):\n",
    "        if self.learn is None:                   _logger.warning('`learn` is None. Will be using random actions for env iteration.')\n",
    "        elif not hasattr(self.learn,'fitter_fn'):_logger.warning('`learn` does not have a `fitter_fn`. Using default.')\n",
    "        self.populate_proc_list(self.fitter_fn,self.fitter_kwargs)\n",
    "            \n",
    "    def populate_proc_list(self,fitter_fn,kwargs):\n",
    "        for i in range(self.n_processes):\n",
    "            self._proc_list.append(mp.Process(target=fitter_fn,kwargs=kwargs))\n",
    "        \n",
    "    def end_procs(self):pass\n",
    "    def pause(self):self.pause_event.set()\n",
    "    \n",
    "    def __getitem__(self,_):raise NotImplimentedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-19 02:09:01] p292 line:36 WARNING - `learn` is None. Will be using random actions for env iteration.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NotImplimentedError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-59493a4f6cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAsyncExperienceSourceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CartPole-v1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mExperienceSourceDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-8e8815147156>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mraise\u001b[0m \u001b[0mNotImplimentedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'NotImplimentedError' is not defined"
     ]
    }
   ],
   "source": [
    "ds=AsyncExperienceSourceDataset('CartPole-v1',ExperienceSourceDataset,n_envs=2,n_processes=2,bs=128)\n",
    "with ds:\n",
    "    for xb,yb in ds:\n",
    "        print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "add_docs(AsyncExperienceSourceDataset,\n",
    "        __init__='Asynchronous form of ExperienceSourceDataset. Requires using `with AsyncExperienceSourceDataset():` or calling `start_procs()`'\n",
    "        ' before looping and `end_procs()` after looking. Using the context manager would be better due to exception handling so we can avoid any'\n",
    "        ' hanging processes. Returns the data samples from all processes, however can be modfied to behave differently.',\n",
    "        start_procs='Start the background processes for the environments. Also called in the context manager `__enter__` method.',\n",
    "        end_procs='End the processes cleanly. Also called in the context manager `__exit__` method.',\n",
    "        pause='Will cause the environments to stop iterating through episodes. Used for switching between test and train datasets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AsyncExperienceSourceCallback(LearnerCallback):\n",
    "    _order = -11\n",
    "    \n",
    "    def on_epoch_begin(self,**kwargs):\n",
    "        ds=(self.learn.data.train_ds if self.learn.model.training or self.learn.data.empty_val else\n",
    "            self.learn.data.valid_ds)\n",
    "        if not self.learn.data.empty_val:ds.pause_event.clear()\n",
    "\n",
    "        if len(ds.data_proc_list)==0:\n",
    "            if not hasattr(self.learn,'fitter'):\n",
    "                _logger.warning('Using the default fitter function which will likely not work. Make sure your `AgentLearner` has a `fitter` attribute to actually run/train.')\n",
    "            \n",
    "            for proc_idx in range(ds.n_processes):\n",
    "                _logger.info('Starting Process')\n",
    "                data_proc=self.load_process()\n",
    "                data_proc.start()\n",
    "                ds.data_proc_list.append(data_proc)\n",
    "                \n",
    "    def load_process(self):raise NotImplementedError()\n",
    "    def empty_queues(self):raise NotImplementedError()\n",
    "        \n",
    "    def on_batch_begin(self,last_target,last_input,**kwargs):\n",
    "        return {'last_input':[last_input]}\n",
    "\n",
    "\n",
    "    def on_batch_end(self,**kwargs):\n",
    "        # If not training, pause train ds, otherwise pause valid ds\n",
    "        ds=(self.learn.data.train_ds if not self.learn.model.training or self.learn.data.empty_val else\n",
    "            self.learn.data.valid_ds)\n",
    "        if not self.learn.data.empty_val:ds.pause_event.set()\n",
    "    \n",
    "    def on_train_end(self,**kwargs):\n",
    "        for ds in [self.learn.data.train_ds,None if self.learn.data.empty_val else self.learn.data.valid_ds]:\n",
    "            if ds is None: continue\n",
    "            ds.cancel_event.set()\n",
    "            for _ in range(5):\n",
    "                self.empty_queues()\n",
    "            for proc in ds.data_proc_list: proc.join(timeout=0)\n",
    "                \n",
    "class AsyncGradExperienceSourceCallback(AsyncExperienceSourceCallback):\n",
    "    def load_process(self):\n",
    "        ds=(self.learn.data.train_ds if self.learn.model.training or self.learn.data.empty_val else\n",
    "            self.learn.data.valid_ds)\n",
    "        return mp.Process(target=getattr(self.learn,'fitter',grad_fitter), \n",
    "                          args=(self.learn.model,self.learn.agent,ds.ds_cls),\n",
    "                          kwargs={'grad_queue':ds.grad_queue,'loss_queue':ds.loss_queue,'pause_event':ds.pause_event,'cancel_event':ds.cancel_event,\n",
    "                                  'metric_queue':ds.metric_queue})\n",
    "    def empty_queues(self):\n",
    "        ds=(self.learn.data.train_ds if self.learn.model.training or self.learn.data.empty_val else\n",
    "            self.learn.data.valid_ds)\n",
    "        while not ds.grad_queue.empty(): ds.grad_queue.get()\n",
    "        while not ds.loss_queue.empty(): ds.loss_queue.get()\n",
    "\n",
    "class AsyncDataExperienceSourceCallback(AsyncExperienceSourceCallback):\n",
    "    def load_process(self):\n",
    "        ds=(self.learn.data.train_ds if self.learn.model.training or self.learn.data.empty_val else\n",
    "            self.learn.data.valid_ds)\n",
    "        return mp.Process(target=getattr(self.learn,'fitter',data_fitter), \n",
    "                          args=(self.learn.model,self.learn.agent,ds.ds_cls),\n",
    "                          kwargs={'data_queue':ds.data_queue,'pause_event':ds.pause_event,'cancel_event':ds.cancel_event,\n",
    "                                  'metric_queue':ds.metric_queue})\n",
    "    def empty_queues(self):\n",
    "        ds=(self.learn.data.train_ds if self.learn.model.training or self.learn.data.empty_val else\n",
    "            self.learn.data.valid_ds)\n",
    "        while not ds.data_queue.empty():ds.data_queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def safe_fit(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args,cancel_event,**kwargs):\n",
    "        try:\n",
    "            return f(*args,cancel_event=cancel_event,**kwargs)\n",
    "        finally:\n",
    "            cancel_event.set()\n",
    "            for k,v in kwargs.items():\n",
    "                if k.__contains__('queue') and v is not None:v.put(None)\n",
    "            return None\n",
    "    return wrap\n",
    "\n",
    "@safe_fit\n",
    "def grad_fitter(model:nn.Module,agent:BaseAgent,ds:ExperienceSourceDataset,grad_queue:mp.JoinableQueue,\n",
    "                loss_queue:mp.JoinableQueue,pause_event:mp.Event,cancel_event:mp.Event,metric_queue:mp.JoinableQueue=None):\n",
    "    \"Updates a `train_queue` with `model.parameters()` and `loss_queue` with the loss. Note that this is only an example grad_fitter.\"\n",
    "    while not cancel_event.is_set(): # We are expecting the  grad_fitter to loop unless cancel_event is set\n",
    "        cancel_event.wait(0.1)\n",
    "        grad_queue.put(None)         # Adding `None` to `train_queue` will trigger an eventual ending of training\n",
    "        loss_queue.put(None)\n",
    "        if pause_event.is_set():     # There needs to be the ability for the grad_fitter to pause e.g. if waiting for validation to end.\n",
    "            cancel_event.wait(0.1)   # Using cancel_event to wait allows the main process to end this Process.\n",
    "        break\n",
    "\n",
    "@safe_fit\n",
    "def data_fitter(model:nn.Module,agent:BaseAgent,ds:ExperienceSourceDataset,data_queue:mp.JoinableQueue,\n",
    "                pause_event:mp.Event,cancel_event:mp.Event,metric_queue:mp.JoinableQueue=None):\n",
    "    _logger.warning('Using the `test_fitter` function. Make sure your `AgentLearner` has a `data_fitter` to actually run/train.')\n",
    "    while not cancel_event.is_set(): # We are expecting the  grad_fitter to loop unless cancel_event is set\n",
    "        cancel_event.wait(0.1)\n",
    "        data_queue.put(None)         # Adding `None` to `train_queue` will trigger an eventual ending of training\n",
    "        if pause_event.is_set():     # There needs to be the ability for the grad_fitter to pause e.g. if waiting for validation to end.\n",
    "            cancel_event.wait(0.1)   # Using cancel_event to wait allows the main process to end this Process.     \n",
    "            \n",
    "def _soft_queue_get(q:mp.Queue,e:mp.Event):\n",
    "    entry=None\n",
    "    while not e.is_set():\n",
    "        try:\n",
    "            entry=q.get_nowait()\n",
    "            break\n",
    "        except Empty:pass\n",
    "    return entry\n",
    "            \n",
    "class AsyncGradExperienceSourceDataset(ExperienceSourceDataset):\n",
    "    \"Contains dataloaders of multiple sub-datasets and executes them using `n_processes`. `xb` is the gradients from the agents, `yb` is the loss.\"\n",
    "    def __init__(self,env_name:str,n_envs=1,ds_cls=ExperienceSourceDataset,max_steps=None,bs=None,n_processes=1,queue_sz=None,*args,**kwargs):\n",
    "        self.n_processes=n_processes\n",
    "        self.n_envs=n_envs\n",
    "        self.env_name=env_name\n",
    "        self.ds_cls=ds_cls\n",
    "        self.pause_event=mp.Event()                               # If the event is set, then the Process will freeze.\n",
    "        self.cancel_event=mp.Event()                              # If the event is set, then the Process will freeze.\n",
    "        self.max_steps=max_steps\n",
    "        self.queue_sz=ifnone(queue_sz,self.n_processes)\n",
    "        self.grad_queue=mp.JoinableQueue(maxsize=self.queue_sz)\n",
    "        self.loss_queue=mp.JoinableQueue(maxsize=self.queue_sz)\n",
    "        self.metric_queue:mp.JoinableQueue=None\n",
    "        self.data_proc_list=[]\n",
    "        self.callback_fns=[AsyncGradExperienceSourceCallback]\n",
    "        self._env=gym.make(self.env_name)\n",
    "        self.bs=ifnone(bs,ifnone(self.max_steps,self._env.spec.max_episode_steps))\n",
    "    \n",
    "    def __len__(self): return ifnone(self.max_steps,self._env.spec.max_episode_steps)*self.n_envs\n",
    "#     def __len__(self): return self.bs\n",
    "    \n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        if len(self.data_proc_list)==0: raise StopIteration()\n",
    "        train_entry=_soft_queue_get(self.grad_queue,self.cancel_event)\n",
    "\n",
    "        if train_entry is None:\n",
    "            raise StopIteration()\n",
    "        \n",
    "        train_loss_entry=_soft_queue_get(self.loss_queue,self.cancel_event)\n",
    "        return train_entry,[train_loss_entry]     \n",
    "    \n",
    "class AsyncDataExperienceSourceDataset(ExperienceSourceDataset):\n",
    "    \"Contains dataloaders of multiple sub-datasets and executes them using `n_processes`. `xb` is the gradients from the agents, `yb` is the loss.\"\n",
    "    def __init__(self,env_name:str,n_envs=1,ds_cls=ExperienceSourceDataset,max_steps=None,bs=None,n_processes=1,queue_sz=None,**kwargs):\n",
    "        self.n_processes=n_processes\n",
    "        self.n_envs=n_envs\n",
    "        self.ds_cls=ds_cls\n",
    "        self.env_name=env_name\n",
    "        self.pause_event=mp.Event()                               # If the event is set, then the Process will freeze.\n",
    "        self.cancel_event=mp.Event()                              # If the event is set, then the Process will freeze.\n",
    "        self.max_steps=max_steps\n",
    "        self.queue_sz=ifnone(queue_sz,self.n_processes)\n",
    "        self.data_queue=mp.JoinableQueue(maxsize=self.queue_sz)\n",
    "        self.metric_queue:mp.JoinableQueue=None\n",
    "        self.data_proc_list=[]\n",
    "        self.callback_fns=[AsyncDataExperienceSourceCallback]\n",
    "        self._env=gym.make(self.env_name)\n",
    "        self.bs=ifnone(bs,ifnone(self.max_steps,self._env.spec.max_episode_steps))\n",
    "        \n",
    "#     def __len__(self): return self.bs\n",
    "    def __len__(self): return ifnone(self.max_steps,self._env.spec.max_episode_steps)*self.n_envs\n",
    "        \n",
    "    def __getitem__(self,_):\n",
    "        if len(self.data_proc_list)==0: raise StopIteration()\n",
    "        train_entry=_soft_queue_get(self.data_queue,self.cancel_event)\n",
    "        if train_entry is None:raise StopIteration()\n",
    "        return Experience(**train_entry).x,train_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(AsyncGradExperienceSourceDataset,\n",
    "         __init__=textwrap.fill(\"\"\"The `AsyncGradExperienceSourceDataset` class is instantiated via passing \n",
    "         the `env_name` that we want to train on, and a `partial` class of a `ExperienceSourceDataset` called `ds_cls`.\n",
    "         `bs` is a field here since the length of the dataset is not necessarily the length of an episode. If `None` it will be the length\n",
    "         of a single episode of the environment. Agents such as A3C will likely change this.\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AsyncExperienceSourceDataBunch(ExperienceSourceDataBunch):\n",
    "    @classmethod\n",
    "    def from_env(cls,env:str,n_envs=1,data_exp=True,firstlast=False,display=False,max_steps=None,skip_n_steps=1,path:PathOrStr='.',add_valid=True,\n",
    "                 cols=1,rows=1,max_w=800,n_processes=1,queue_sz=None,bs=1):\n",
    "        def create_ds(make_empty=False):\n",
    "            _sub_ds_cls=FirstLastExperienceSourceDataset if firstlast else ExperienceSourceDataset\n",
    "            _sub_ds_cls=partial(_sub_ds_cls,env=env,n_envs=n_envs,max_steps=0 if make_empty else max_steps,skip_n_steps=skip_n_steps)\n",
    "            _ds_cls=AsyncDataExperienceSourceDataset if data_exp else AsyncGradExperienceSourceDataset\n",
    "            _ds=_ds_cls(env,max_steps=0 if make_empty else max_steps,skip_n_steps=skip_n_steps,ds_cls=_sub_ds_cls,n_processes=n_processes,queue_sz=queue_sz)\n",
    "            for k,v in {'env':env,'n_envs':n_envs,'skip_n_steps':skip_n_steps}.items():\n",
    "                if not hasattr(_ds,k):setattr(_ds,k,v)\n",
    "            if display:_ds=DatasetDisplayWrapper(_ds,cols=cols,rows=rows,max_w=max_w)\n",
    "            return _ds\n",
    "            \n",
    "#         dss=(create_ds(),create_ds() if add_valid else None)\n",
    "        return cls.create(create_ds(),create_ds(not add_valid),bs=bs,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@safe_fit\n",
    "def dqn_fitter(model:nn.Module,agent:BaseAgent,ds:ExperienceSourceDataset,data_queue:mp.JoinableQueue,\n",
    "               pause_event:mp.Event,cancel_event:mp.Event,metric_queue:mp.JoinableQueue=None):\n",
    "    dataset=ds()\n",
    "    while not cancel_event.is_set(): \n",
    "        for xb,yb in dataset:\n",
    "            data_queue.put(yb)\n",
    "            if pause_event.is_set():cancel_event.wait(0.1) \n",
    "            if cancel_event.is_set():break\n",
    "        if metric_queue is not None:metric_queue.put(TotalRewards(np.mean(dataset.pop_total_rewards())))\n",
    "        if cancel_event.is_set():break\n",
    "                \n",
    "@safe_fit\n",
    "def dqn_grad_fitter(model:nn.Module,agent:BaseAgent,ds:ExperienceSourceDataset,grad_queue:mp.JoinableQueue,loss_queue:mp.JoinableQueue,\n",
    "                    pause_event:mp.Event,cancel_event:mp.Event,metric_queue:mp.JoinableQueue=None):\n",
    "    dataset=ds()\n",
    "    while not cancel_event.is_set(): \n",
    "        for xb,yb in dataset:\n",
    "            sys.stdout.flush()\n",
    "            grad_queue.put(xb)\n",
    "            loss_queue.put(0.5)\n",
    "            if pause_event.is_set():cancel_event.wait(0.1) \n",
    "            if cancel_event.is_set():break\n",
    "        if metric_queue is not None:metric_queue.put(TotalRewards(np.mean(dataset.pop_total_rewards())))\n",
    "        if cancel_event.is_set():break\n",
    "\n",
    "@safe_fit\n",
    "def buggy_dqn_fitter(model:nn.Module,agent:BaseAgent,ds:ExperienceSourceDataset,data_queue:mp.JoinableQueue,\n",
    "                pause_event:mp.Event,cancel_event:mp.Event,metric_queue:mp.JoinableQueue=None):\n",
    "    dataset=ds()\n",
    "    while not cancel_event.is_set(): \n",
    "        for xb,yb in dataset:\n",
    "            data_queue.put(yb)\n",
    "            if pause_event.is_set():cancel_event.wait(0.1) \n",
    "            if cancel_event.is_set():break\n",
    "            raise Exception('Crashing on purpose')\n",
    "        if cancel_event.is_set():break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.basic_train import *\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no fitter is added, then calling the fit function will likelly result in a `TypeError` where the `smooth_loss` is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeRunCallback2(LearnerCallback):\n",
    "    def on_backward_begin(self,*args,**kwargs): return {'skip_bwd':True,'skip_validate':True}\n",
    "#     def on_batch_begin(self,last_target,last_input,**kwargs):\n",
    "#         print(*last_input)\n",
    "#         print('hello')\n",
    "#         sys.stdout.flush()\n",
    "#         return {'last_input':last_input.unsqueeze(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',data_exp=True,display=False,max_steps=50,firstlast=False,add_valid=False,n_processes=1,n_envs=1,bs=4)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback2])\n",
    "setattr(learn,'fitter',dqn_fitter)\n",
    "learn.fit(2,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',data_exp=True,display=False,max_steps=50,firstlast=True,add_valid=False,n_processes=4,n_envs=2,bs=4)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback2])\n",
    "setattr(learn,'fitter',dqn_fitter)\n",
    "learn.fit(1,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',data_exp=True,display=False,max_steps=50,firstlast=True,add_valid=False,n_processes=1,n_envs=1)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback])\n",
    "with pytest.raises(TypeError):\n",
    "    learn.fit(1,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',data_exp=False,display=False,firstlast=True,add_valid=False,n_processes=2,n_envs=2)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback])\n",
    "setattr(learn,'fitter',dqn_grad_fitter)\n",
    "learn.fit(1,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',display=False,firstlast=True,add_valid=False,max_steps=50,n_processes=2,n_envs=2)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback])\n",
    "setattr(learn,'fitter',dqn_fitter)\n",
    "learn.fit(3,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',display=False,firstlast=True,add_valid=False,max_steps=50,n_processes=2,n_envs=2)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback])\n",
    "setattr(learn,'fitter',buggy_dqn_fitter)\n",
    "with pytest.raises(TypeError):\n",
    "    learn.fit(1,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',display=False,firstlast=True,add_valid=False,max_steps=50,n_processes=2,n_envs=2,bs=128)\n",
    "model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2))\n",
    "agent=DQNAgent(model=model)\n",
    "learn=AgentLearner(data,model,agent=agent,callback_fns=[FakeRunCallback])\n",
    "setattr(learn,'fitter',dqn_fitter)\n",
    "learn.fit(1,lr=0.01,wd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=AsyncExperienceSourceDataBunch.from_env('CartPole-v1',n_envs=5,display=False,max_steps=50,firstlast=False,add_valid=False)\n",
    "for xb,yb in data.train_dl:\n",
    "    test_eq(len(xb),1)\n",
    "    test_eq(tuple(xb[0].shape),(5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Shower\n",
    "We can define a wrapper around a dataset which will show up to `rows * cols` environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DatasetDisplayWrapper(object):\n",
    "    def __init__(self,ds,rows=2,cols=2,max_w=800):\n",
    "        \"Wraps a ExperienceSourceDataset instance showing multiple envs in a `rows` by `cols` grid in a Jupyter notebook.\"\n",
    "        # Ref: https://stackoverflow.com/questions/1443129/completely-wrap-an-object-in-python\n",
    "        # We are basically Wrapping any instance of ExperienceSourceDataset (kind of cool right?)\n",
    "        clss=(ExperienceSourceDataset,FirstLastExperienceSourceDataset,\n",
    "              AsyncGradExperienceSourceDataset,AsyncDataExperienceSourceDataset)\n",
    "        assert issubclass(ds.__class__,clss),'Currently this only works with the ExperienceSourceDataset and Async*ExperienceSourceDataset class only.'\n",
    "        self.__class__ = type(ds.__class__.__name__,(self.__class__, ds.__class__),{})\n",
    "        self.__dict__=ds.__dict__\n",
    "        self.rows,self.cols,self.max_w=rows,cols,max_w\n",
    "        self.current_display=None\n",
    "        if not IN_NOTEBOOK: \n",
    "            _logger.warning('It seems you are not running in a notebook. Nothing is going to be displayed.')\n",
    "            return\n",
    "        \n",
    "        if self.envs[0].render('rgb_array') is None: self.envs[0].reset()\n",
    "        rdr=self.envs[0].render('rgb_array')\n",
    "        if rdr.shape[1]*self.cols>max_w:\n",
    "            _logger.warning('Max Width is %s but %s*%s is greater than. Decreasing the number of cols to %s, rows increase by %s',\n",
    "                            max_w,rdr.shape[1],self.cols,max_w%rdr.shape[1],max_w%rdr.shape[1])\n",
    "            self.cols=max_w%rdr.shape[1]\n",
    "            self.rows+=max_w%rdr.shape[1]\n",
    "        self.max_displays=self.cols*self.rows\n",
    "        self.current_display=np.zeros(shape=(self.rows*rdr.shape[0],self.cols*rdr.shape[1],rdr.shape[2])).astype('uint8')\n",
    "        _logger.info('%s, %s, %s, %s, %s',0,0//self.cols,0%self.cols,rdr.shape,self.current_display.shape)\n",
    "\n",
    "    def __getitem__(self,_):\n",
    "        idx=self._env_idx\n",
    "        o=super(DatasetDisplayWrapper,self).__getitem__(idx)\n",
    "        idx=idx%self.max_displays\n",
    "        if self.current_display is not None and idx<self.rows*self.cols:\n",
    "            display.clear_output(wait=True)\n",
    "            im=self.envs[idx].render(mode='rgb_array')\n",
    "            self.current_display[(idx//self.cols)*im.shape[0]:(idx//self.cols)*im.shape[0]+im.shape[0],\n",
    "                                 (idx%self.cols)*im.shape[1]:(idx%self.cols)*im.shape[1]+im.shape[1],:]=im\n",
    "            new_im=PIL.Image.fromarray(self.current_display)\n",
    "            display.display(new_im)\n",
    "        else:\n",
    "            display.display(PIL.Image.fromarray(self.current_display))\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AsyncGradExperienceSourceDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-f239fcdff7f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mExperienceSourceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MountainCar-v0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_n_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetDisplayWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-59c90c6e34ba>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ds, rows, cols, max_w)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# We are basically Wrapping any instance of ExperienceSourceDataset (kind of cool right?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         clss=(ExperienceSourceDataset,FirstLastExperienceSourceDataset,\n\u001b[0;32m----> 8\u001b[0;31m               AsyncGradExperienceSourceDataset,AsyncDataExperienceSourceDataset)\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Currently this only works with the ExperienceSourceDataset and Async*ExperienceSourceDataset class only.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AsyncGradExperienceSourceDataset' is not defined"
     ]
    }
   ],
   "source": [
    "ds=ExperienceSourceDataset(\"MountainCar-v0\",n_envs=15,skip_n_steps=1,pixels=True)\n",
    "ds=DatasetDisplayWrapper(ds,1,1,800)\n",
    "dl=DataLoader(ds,batch_size=1,num_workers=0)\n",
    "for xb,yb in dl:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 02_callbacks.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted 05_data_block.ipynb.\n",
      "Converted 06_basic_train.ipynb.\n",
      "Converted 12_a3c.a3c_data.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted notes.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: /opt/project/fastrl/nbs/05_data_block.ipynb\n",
      "An error occurred while executing the following cell:\n",
      "------------------\n",
      "from nbdev.showdoc import show_doc\n",
      "from fastrl.data_block import *\n",
      "------------------\n",
      "\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-1-b022c5ef8e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowdoc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_block\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/opt/project/fastrl/fastrl/data_block.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m    313\u001b[0m         \u001b[0mstart_procs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Start the background processes for the environments. Also called in the context manager `__enter__` method.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    314\u001b[0m         \u001b[0mend_procs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'End the processes cleanly. Also called in the context manager `__exit__` method.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 315\u001b[0;31m         pause='Will cause the environments to stop iterating through episodes. Used for switching between test and train datasets.')\n",
      "\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    317\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36madd_docs\u001b[0;34m(cls, cls_doc, **docs)\u001b[0m\n",
      "\u001b[1;32m    188\u001b[0m     nodoc = [c for n,c in vars(cls).items() if callable(c)\n",
      "\u001b[1;32m    189\u001b[0m              and not n.startswith('_') and c.__doc__ is None]\n",
      "\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnodoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Missing docs: {nodoc}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Missing class docs: {cls}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mAssertionError\u001b[0m: Missing docs: [<function _fitter at 0x7f7c61c8e5f0>, <function AsyncExperienceSourceDataset.populate_proc_list at 0x7f7c61c9d290>]\n",
      "AssertionError: Missing docs: [<function _fitter at 0x7f7c61c8e5f0>, <function AsyncExperienceSourceDataset.populate_proc_list at 0x7f7c61c9d290>]\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Conversion failed on the following:\n05_data_block.ipynb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-e212a96b8210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnotebook2script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnotebook2html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/nbdev/export2html.py\u001b[0m in \u001b[0;36mnotebook2html\u001b[0;34m(fname, force_all, n_workers, cls, template_file, exporter, dest)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Conversion failed on the following:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Conversion failed on the following:\n05_data_block.ipynb"
     ]
    }
   ],
   "source": [
    "# # hide\n",
    "from nbdev.export import *\n",
    "notebook2script()\n",
    "notebook2html(n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
