{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp actorcritic.sac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import torch.nn.utils as nn_utils\n",
    "from fastai.torch_basics import *\n",
    "import torch.nn.functional as F\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "import torch.multiprocessing as mp\n",
    "from torch.optim import *\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from fastrl.data import *\n",
    "from fastrl.async_data import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.learner import *\n",
    "from fastrl.metrics import *\n",
    "from fastai.callback.progress import *\n",
    "from fastrl.ptan_extension import *\n",
    "\n",
    "from torch.distributions import *\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "HID_SIZE = 64\n",
    "\n",
    "class ModelActor(nn.Module):\n",
    "    def __init__(self, obs_size, act_size):\n",
    "        super(ModelActor, self).__init__()\n",
    "\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Linear(obs_size, HID_SIZE),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(HID_SIZE, HID_SIZE),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(HID_SIZE, act_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.logstd = nn.Parameter(torch.zeros(act_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mu(x.float())\n",
    "\n",
    "\n",
    "class ModelCritic(nn.Module):\n",
    "    def __init__(self, obs_size):\n",
    "        super(ModelCritic, self).__init__()\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(obs_size, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.value(x.float())\n",
    "\n",
    "\n",
    "class AgentA2C(BaseAgent):\n",
    "    \n",
    "    preprocessor:Callable=default_states_preprocessor\n",
    "    def __init__(self, model, device=\"cpu\"):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, states, agent_states):\n",
    "        states_v = torch.tensor(np.stack(states)).float().to(self.device) #self.preprocessor(states[0].reshape(1,-1))\n",
    "\n",
    "        mu_v = self.model(states_v)\n",
    "        mu = mu_v.data.cpu().numpy()\n",
    "        logstd = self.model.logstd.data.cpu().numpy()\n",
    "        actions = mu + np.exp(logstd) * np.random.normal(size=logstd.shape)\n",
    "        actions = np.clip(actions, -1, 1)\n",
    "#         print(actions)\n",
    "        return actions, agent_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "\n",
    "LEARNING_RATE_ACTOR = 1e-4\n",
    "LEARNING_RATE_CRITIC = 1e-3\n",
    "\n",
    "PPO_EPS = 0.2\n",
    "PPO_EPOCHES = 10\n",
    "PPO_BATCH_SIZE = 64\n",
    "\n",
    "def calc_logprob(mu_v, logstd_v, actions_v):\n",
    "    p1 = - ((mu_v - actions_v) ** 2) / (2*torch.exp(logstd_v).clamp(min=1e-3))\n",
    "    p2 = - torch.log(torch.sqrt(2 * math.pi * torch.exp(logstd_v)))\n",
    "    return p1 + p2\n",
    "\n",
    "\n",
    "def calc_adv_ref(trajectory, net_crt, states_v, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    By trajectory calculate advantage and 1-step ref value\n",
    "    :param trajectory: trajectory list\n",
    "    :param net_crt: critic network\n",
    "    :param states_v: states tensor\n",
    "    :return: tuple with advantage numpy array and reference values\n",
    "    \"\"\"\n",
    "    values_v = net_crt(states_v)\n",
    "    values = values_v.squeeze().data.cpu().numpy()\n",
    "    # generalized advantage estimator: smoothed version of the advantage\n",
    "    last_gae = 0.0\n",
    "    result_adv = []\n",
    "    result_ref = []\n",
    "    for val, next_val, (exp,) in zip(reversed(values[:-1]), reversed(values[1:]),\n",
    "                                     reversed(trajectory[:-1])):\n",
    "        if exp.done:\n",
    "            delta = exp.reward - val\n",
    "            last_gae = delta\n",
    "        else:\n",
    "            delta = exp.reward + GAMMA * next_val - val\n",
    "            last_gae = delta + GAMMA * GAE_LAMBDA * last_gae\n",
    "        result_adv.append(last_gae)\n",
    "        result_ref.append(last_gae + val)\n",
    "\n",
    "    adv_v = torch.FloatTensor(list(reversed(result_adv))).to(device)\n",
    "    ref_v = torch.FloatTensor(list(reversed(result_ref))).to(device)\n",
    "    return adv_v, ref_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def loss_func(*yb,learn):\n",
    "    b=list(learn.xb)+list(learn.yb)\n",
    "    yxb=b\n",
    "    trajectory=[(Experience(state=b[0][i],action=b[1][i],reward=b[2][i],\n",
    "                done=(b[3][i] and learn.max_step!=b[5][i]),episode_reward=b[4][i],\n",
    "                steps=b[5][i]),) for i in range(len(b[0]))]\n",
    "    net_crt=learn.net_crt\n",
    "    net_act=learn.model\n",
    "    opt_crt=learn.opt_crt\n",
    "    opt_act=learn.opt_act\n",
    "    \n",
    "\n",
    "    traj_states = [t[0].state for t in trajectory]\n",
    "    traj_actions = [t[0].action for t in trajectory]\n",
    "#     traj_states = [t.state for t in trajectory]\n",
    "#     traj_actions = [t.action for t in trajectory]\n",
    "#     traj_states_v = torch.FloatTensor(traj_states).to(device)\n",
    "#     traj_actions_v = torch.FloatTensor(traj_actions).to(device)\n",
    "    traj_states_v = torch.stack(traj_states).float().to(default_device())\n",
    "    traj_actions_v = torch.stack(traj_actions).float().to(default_device())\n",
    "#     print(traj_states_v.size(),net_act)\n",
    "    traj_adv_v, traj_ref_v = calc_adv_ref(trajectory, net_crt, traj_states_v, device=default_device())\n",
    "    mu_v = net_act(traj_states_v)\n",
    "    old_logprob_v = calc_logprob(mu_v, net_act.logstd, traj_actions_v)\n",
    "\n",
    "    # normalize advantages\n",
    "    traj_adv_v = (traj_adv_v - torch.mean(traj_adv_v)) / torch.std(traj_adv_v)\n",
    "\n",
    "    # drop last entry from the trajectory, an our adv and ref value calculated without it\n",
    "    trajectory = trajectory[:-1]\n",
    "    old_logprob_v = old_logprob_v[:-1].detach()\n",
    "\n",
    "    sum_loss_value = 0.0\n",
    "    sum_loss_policy = 0.0\n",
    "    count_steps = 0\n",
    "\n",
    "    for epoch in range(PPO_EPOCHES):\n",
    "        for batch_ofs in range(0, len(trajectory), PPO_BATCH_SIZE):\n",
    "            states_v = traj_states_v[batch_ofs:batch_ofs + PPO_BATCH_SIZE]\n",
    "            actions_v = traj_actions_v[batch_ofs:batch_ofs + PPO_BATCH_SIZE]\n",
    "            batch_adv_v = traj_adv_v[batch_ofs:batch_ofs + PPO_BATCH_SIZE].unsqueeze(-1)\n",
    "            batch_ref_v = traj_ref_v[batch_ofs:batch_ofs + PPO_BATCH_SIZE]\n",
    "            batch_old_logprob_v = old_logprob_v[batch_ofs:batch_ofs + PPO_BATCH_SIZE]\n",
    "\n",
    "            # critic training\n",
    "            opt_crt.zero_grad()\n",
    "            value_v = net_crt(states_v)\n",
    "            loss_value_v = F.mse_loss(value_v.squeeze(-1), batch_ref_v)\n",
    "            loss_value_v.backward()\n",
    "            opt_crt.step()\n",
    "\n",
    "            # actor training\n",
    "            opt_act.zero_grad()\n",
    "            mu_v = net_act(states_v)\n",
    "            logprob_pi_v = calc_logprob(mu_v, net_act.logstd, actions_v)\n",
    "            ratio_v = torch.exp(logprob_pi_v - batch_old_logprob_v)\n",
    "            surr_obj_v = batch_adv_v * ratio_v\n",
    "            clipped_surr_v = batch_adv_v * torch.clamp(ratio_v, 1.0 - PPO_EPS, 1.0 + PPO_EPS)\n",
    "            loss_policy_v = -torch.min(surr_obj_v, clipped_surr_v).mean()\n",
    "            loss_policy_v.backward()\n",
    "            opt_act.step()\n",
    "\n",
    "            sum_loss_value += loss_value_v.item()\n",
    "            sum_loss_policy += loss_policy_v.item()\n",
    "            count_steps += 1\n",
    "    return torch.tensor(sum_loss_value+sum_loss_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PPOTrainer(Callback):\n",
    "    def after_loss(self):raise CancelBatchException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PPOLearner(AgentLearner):\n",
    "    def __init__(self,dls,agent=None,actr_lr=1e-4,crtic_lr=1e-3,max_step=1,**kwargs):\n",
    "        store_attr()\n",
    "        self.net_crt=ModelCritic(3).to(default_device())\n",
    "        self.opt_act = Adam(agent.model.parameters(), lr=actr_lr)\n",
    "        self.opt_crt = Adam(self.net_crt.parameters(), lr=crtic_lr)\n",
    "\n",
    "        super().__init__(dls,loss_func=partial(loss_func,learn=self),model=agent.model,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_avg_episode_r</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_avg_episode_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2447894.250000</td>\n",
       "      <td>-833.402907</td>\n",
       "      <td>None</td>\n",
       "      <td>-833.402907</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1443182.875000</td>\n",
       "      <td>-1079.645498</td>\n",
       "      <td>None</td>\n",
       "      <td>-1079.645498</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1004285.062500</td>\n",
       "      <td>-1214.675004</td>\n",
       "      <td>None</td>\n",
       "      <td>-1214.675004</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>771823.125000</td>\n",
       "      <td>-1296.550904</td>\n",
       "      <td>None</td>\n",
       "      <td>-1296.550904</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>629101.875000</td>\n",
       "      <td>-1336.413165</td>\n",
       "      <td>None</td>\n",
       "      <td>-1336.413165</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>534776.812500</td>\n",
       "      <td>-1362.607398</td>\n",
       "      <td>None</td>\n",
       "      <td>-1362.607398</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>484733.281250</td>\n",
       "      <td>-1370.539334</td>\n",
       "      <td>None</td>\n",
       "      <td>-1370.539334</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>485329.968750</td>\n",
       "      <td>-1365.002604</td>\n",
       "      <td>None</td>\n",
       "      <td>-1365.002604</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>446202.343750</td>\n",
       "      <td>-1364.499230</td>\n",
       "      <td>None</td>\n",
       "      <td>-1364.499230</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>428917.250000</td>\n",
       "      <td>-1354.561390</td>\n",
       "      <td>None</td>\n",
       "      <td>-1354.561390</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>400369.593750</td>\n",
       "      <td>-1346.928558</td>\n",
       "      <td>None</td>\n",
       "      <td>-1346.928558</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>377806.093750</td>\n",
       "      <td>-1336.811242</td>\n",
       "      <td>None</td>\n",
       "      <td>-1336.811242</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>351514.656250</td>\n",
       "      <td>-1331.277223</td>\n",
       "      <td>None</td>\n",
       "      <td>-1331.277223</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>329120.312500</td>\n",
       "      <td>-1325.190888</td>\n",
       "      <td>None</td>\n",
       "      <td>-1325.190888</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>307555.375000</td>\n",
       "      <td>-1321.164551</td>\n",
       "      <td>None</td>\n",
       "      <td>-1321.164551</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>288388.843750</td>\n",
       "      <td>-1315.630358</td>\n",
       "      <td>None</td>\n",
       "      <td>-1315.630358</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>271208.125000</td>\n",
       "      <td>-1312.474035</td>\n",
       "      <td>None</td>\n",
       "      <td>-1312.474035</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>257516.484375</td>\n",
       "      <td>-1308.474874</td>\n",
       "      <td>None</td>\n",
       "      <td>-1308.474874</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>243990.140625</td>\n",
       "      <td>-1304.673443</td>\n",
       "      <td>None</td>\n",
       "      <td>-1304.673443</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>232039.671875</td>\n",
       "      <td>-1301.321865</td>\n",
       "      <td>None</td>\n",
       "      <td>-1301.321865</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>220553.281250</td>\n",
       "      <td>-1296.376734</td>\n",
       "      <td>None</td>\n",
       "      <td>-1296.376734</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>211473.750000</td>\n",
       "      <td>-1291.952518</td>\n",
       "      <td>None</td>\n",
       "      <td>-1291.952518</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>203125.234375</td>\n",
       "      <td>-1288.113080</td>\n",
       "      <td>None</td>\n",
       "      <td>-1288.113080</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>197370.734375</td>\n",
       "      <td>-1283.913037</td>\n",
       "      <td>None</td>\n",
       "      <td>-1283.913037</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>191385.078125</td>\n",
       "      <td>-1280.457286</td>\n",
       "      <td>None</td>\n",
       "      <td>-1280.457286</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>184295.468750</td>\n",
       "      <td>-1277.305672</td>\n",
       "      <td>None</td>\n",
       "      <td>-1277.305672</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>178864.234375</td>\n",
       "      <td>-1273.421524</td>\n",
       "      <td>None</td>\n",
       "      <td>-1273.421524</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>174169.781250</td>\n",
       "      <td>-1270.963855</td>\n",
       "      <td>None</td>\n",
       "      <td>-1270.963855</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>170696.718750</td>\n",
       "      <td>-1267.609494</td>\n",
       "      <td>None</td>\n",
       "      <td>-1267.609494</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>166112.890625</td>\n",
       "      <td>-1264.369431</td>\n",
       "      <td>None</td>\n",
       "      <td>-1264.369431</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    }
   ],
   "source": [
    "env='Pendulum-v0'\n",
    "agent=AgentA2C(ModelActor(3, 1).to(default_device()), device=default_device())\n",
    "\n",
    "block=ExperienceBlock(agent=agent,seed=0,n_steps=1,\n",
    "                      dls_kwargs={'bs':2049,'num_workers':0,'verbose':False,'indexed':True,'shuffle_train':False})\n",
    "blk=IterableDataBlock(blocks=(block),splitter=FuncSplitter(lambda x:False))\n",
    "dls=blk.dataloaders([env]*1,n=2049,device=default_device())\n",
    "\n",
    "learner=PPOLearner(dls,agent=agent,cbs=[PPOTrainer], metrics=[AvgEpisodeRewardMetric(Experience)],max_step=gym.make(env)._max_episode_steps)\n",
    "learner.fit(30,lr=0.001,wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
