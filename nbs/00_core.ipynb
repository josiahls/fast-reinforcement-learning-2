{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os,warnings\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.basics import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "# Local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-institute",
   "metadata": {},
   "source": [
    "# Core\n",
    "> Core libs for fastrl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-telling",
   "metadata": {},
   "source": [
    "## D\n",
    "> A better dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def map_dict_ex(d,f,*args,gen=False,wise=None,**kwargs):\n",
    "    \"Like `map`, but for dicts and uses `bind`, and supports `str` and indexing\"\n",
    "    g = (bind(f,*args,**kwargs) if callable(f)\n",
    "         else f.format if isinstance(f,str)\n",
    "         else f.__getitem__)\n",
    "\n",
    "    if wise is None:  return map(g,d.items())\n",
    "    return ((k,g(v)) if wise=='value' else (g(k),v) for k,v in d.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-excuse",
   "metadata": {},
   "source": [
    "Check that general mapping for dicts works nicely..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict={'a':1,'b':2,'c':3}\n",
    "test_eq(dict(map_dict_ex(test_dict,lambda t:(t[0]+'_new',t[1]+1))),{'a_new':2,'b_new':3,'c_new':4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-packet",
   "metadata": {},
   "source": [
    "Check that key and value wise mapping works correctly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(dict(map_dict_ex(test_dict,lambda k:k+'_new',wise='key')),{'a_new':1,'b_new':2,'c_new':3})\n",
    "test_eq(dict(map_dict_ex(test_dict,lambda v:v+1,wise='value')),{'a':2,'b':3,'c':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_error_msg='Found idxs: %s have values more than %s e.g.: %s'\n",
    "\n",
    "class D(dict):\n",
    "    \"Improved version of `dict` with array handling abilities\"\n",
    "    def __init__(self,*args,mapping=False,**kwargs):\n",
    "        self.mapping=mapping\n",
    "        super().__init__(*args,**kwargs)\n",
    "        \n",
    "    def eq_k(self,o:'D',with_diff=False):\n",
    "        eq=set(o.keys())==set(self.keys())\n",
    "        if with_diff: return eq,set(o.keys()).symmetric_difference(set(self.keys()))\n",
    "        return eq\n",
    "    def _new(self,*args,**kwargs): return type(self)(*args,**kwargs)\n",
    "    \n",
    "    def map(self,f,*args,gen=False,**kwargs): \n",
    "        return (self._new,noop)[gen](map_dict_ex(self,f,*args,**kwargs),mapping=True)\n",
    "    def mapk(self,f,*args,gen=False,wise='key',**kwargs):\n",
    "        return self.map(f,*args,gen=gen,wise=wise,**kwargs)\n",
    "    def mapv(self,f,*args,gen=False,wise='value',**kwargs):\n",
    "        return self.map(f,*args,gen=gen,wise=wise,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict=D({'a':1,'b':2,'c':3})\n",
    "test_eq(test_dict.map(lambda t:(t[0]+'_new',t[1]+1)),{'a_new':2,'b_new':3,'c_new':4})\n",
    "test_eq(isinstance(test_dict.map(lambda t:(t[0]+'_new',t[1]+1),gen=True),map),True)\n",
    "test_eq(dict(test_dict.map(lambda t:(t[0]+'_new',t[1]+1),gen=True)),{'a_new':2,'b_new':3,'c_new':4})\n",
    "\n",
    "test_eq(test_dict.mapk(lambda k:k+'_new'),{'a_new':1,'b_new':2,'c_new':3})\n",
    "test_eq(dict(test_dict.mapk(lambda k:k+'_new',gen=True)),{'a_new':1,'b_new':2,'c_new':3})\n",
    "\n",
    "test_eq(test_dict.mapv(lambda v:v+1,wise='value'),{'a':2,'b':3,'c':4})\n",
    "test_eq(dict(test_dict.mapv(lambda v:v+1,gen=True,wise='value')),{'a':2,'b':3,'c':4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-celtic",
   "metadata": {},
   "source": [
    "`BD` is the primary data structure that `fastrl` uses. It allows for easily iterating and doing operations on steps attained from environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-study",
   "metadata": {},
   "source": [
    "## BD \n",
    "> A batch wise dictionary that requires all values to be numpy,tensor, or None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-platinum",
   "metadata": {},
   "source": [
    "We need to change any indexer that is passed. We don't know if the indexer is going to\n",
    "be a numpy array, slice, tensor, or int.\n",
    "All we know is 2 things:\n",
    "- If it is an int, the batch dim will disappear\n",
    "- If it is an indexer, then the batch dim will stay, but be smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def tensor2shape(k,t:'TensorBatch',relative_shape=False):\n",
    "    \"Converts a tensor into a dict of shapes, or a 1d numpy array\"\n",
    "    return {\n",
    "        k:t.cpu().numpy().reshape(-1,) if len(t.shape)==2 and t.shape[1]==1 else \n",
    "        [str((1,*t.shape[1:]) if relative_shape else t.shape)]*t.shape[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-cabinet",
   "metadata": {},
   "source": [
    "`tensor2shape` is a function for preparing tensors for showing in pandas. For example\n",
    "if we have a tensor that has 5 dimensions, it would be very hard to read if displayed in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tensor2shape('test',torch.randn(3,5)),\n",
    "       {'test': ['torch.Size([3, 5])', 'torch.Size([3, 5])', 'torch.Size([3, 5])']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-socket",
   "metadata": {},
   "source": [
    "If the tensor has only 1 channel, then we can show its literal value..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tensor2shape('test',torch.tensor([[1],[2],[3]]))['test'],\n",
    "        {'test': np.array([1, 2, 3])}['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def tensor2mu(k,t:Tensor): return {f'{k}_mu':t.reshape(t.shape[0],-1).double().mean(axis=1)}\n",
    "tensor2mu.__docs__=\"Returns a dict with key `k`_mu with the mean of `t` batchwise \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-cleaners",
   "metadata": {},
   "source": [
    "Outputs a dictionary that has the mean of the tensor. The returned dictionary's keys \n",
    "have the naming convention: *[k]_mu*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "o=torch.randn(3,5)\n",
    "test_eq(tensor2mu('test',o)['test_mu'],{'test_mu': o.double().mean(axis=1)}['test_mu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-regard",
   "metadata": {},
   "source": [
    "Ok I have reworked the tensor management soooo many times. I think the core issue is the tensors themselves. They should individually be incharge of\n",
    "determining if they match the expected batch size I think...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TensorBatch(TensorBase):\n",
    "    \"A tensor that maintains and propagates a batch dimension\"\n",
    "    def __new__(cls, x, bs=1,**kwargs):\n",
    "        res=super(TensorBatch,cls).__new__(cls,x,**kwargs)\n",
    "        \n",
    "        if bs==1:\n",
    "            if len(res.shape)<2: \n",
    "                res=res.unsqueeze(0)\n",
    "        else:\n",
    "            if res.shape[0]!=bs and res.shape[1]==bs and len(res.shape)==2: \n",
    "#                 print('tansposing',res,bs)\n",
    "                res=torch.transpose(res,1,0)\n",
    "            \n",
    "        assert len(res.shape)>1,f'Tensor has shape {res.shape} while bs is {bs}'\n",
    "        return res\n",
    "    \n",
    "    @property\n",
    "    def bs(self): return self.shape[0]\n",
    "    def get(self,*args):\n",
    "#         print(self)\n",
    "        res=self[args]\n",
    "        if len(self.shape)>len(res.shape): res=res.unsqueeze(0)\n",
    "        return res\n",
    "    \n",
    "    @classmethod\n",
    "    def vstack(cls,*args):\n",
    "        new_bs=sum(map(_get_bs,*args))\n",
    "        return cls(torch.vstack(*args),bs=new_bs)\n",
    "              \n",
    "def obj2tensor(o):\n",
    "    return (o if isinstance(o,TensorBatch) else\n",
    "            TensorBatch(o) if isinstance(o,(L,list,np.ndarray,Tensor,TensorBatch)) else\n",
    "            TensorBatch([o])) \n",
    "\n",
    "def _get_bs(o): return o.bs if isinstance(o,TensorBatch) else TensorBatch(o).bs\n",
    "\n",
    "# export\n",
    "class BD(D):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        if not self.mapping: self.update(self.mapv(obj2tensor))\n",
    "        self.bs=list(self.values())[0].bs\n",
    "\n",
    "    def __radd__(self,o): return self if isinstance(o,int) else self.__add__(o) \n",
    "    def __add__(self,o):\n",
    "#         print('add',self.bs)\n",
    "        return BD({k:TensorBatch.vstack((self[k],o[k])) for k in self})\n",
    "    \n",
    "    def __getitem__(self,o):\n",
    "        if is_listy(o) or isinstance(o,(TensorBatch,int,Tensor)): \n",
    "            return type(self)({k:self[k].get(o) for k in self})\n",
    "        return super().__getitem__(o)\n",
    "\n",
    "    @classmethod\n",
    "    def merge(cls,*ds,**kwargs): return cls(merge(*ds),**kwargs)\n",
    "    @delegates(pd.DataFrame)\n",
    "    def pandas(self,mu=False,relative_shape=False,**kwargs):\n",
    "        \"Turns a `BD` into a pandas Dataframe optionally showing `mu` of values.\"\n",
    "        return pd.DataFrame(merge(\n",
    "            *tuple(tensor2shape(k,v,relative_shape) for k,v in self.items()),\n",
    "            *(tuple(tensor2mu(k,v) for k,v in self.items()) if mu else ())\n",
    "        ),**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-boxing",
   "metadata": {},
   "source": [
    "> Note: I think that BD should do zero undirected shae correction. I think it would be better for it to validate the shapes have batch dims\n",
    "    that match. But I think that the __init__ should accept a shape_map for a key->single batch shape. I can have a default \n",
    "    key map so it can still be convenient, however this would open up BD to be more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-voltage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBatch([[1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBatch.vstack((Tensor([[1,2,3,4]]),Tensor([[1,2,3,4]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-director",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBatch([1]).bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-wrist",
   "metadata": {},
   "source": [
    "Ok so the solution was that `BD` itself does not validate or coerce batch sizes.\n",
    "It does not check that they all match.\n",
    "It merely uses the TensorBatch object in all its operations.\n",
    "The TensorBatch object tracks and manages what the batch size is really supposed to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-dylan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n",
      "Converted 00_core.ipynb.\n",
      "Converted 00_nbdev_extension.ipynb.\n",
      "Converted 05_data.block.ipynb.\n",
      "Converted 05_data.test_async.ipynb.\n",
      "Converted 20_test_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted nbdev_template.ipynb.\n",
      "converting: /home/fastrl_user/fastrl/nbs/00_core.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import make_readme\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-indication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
