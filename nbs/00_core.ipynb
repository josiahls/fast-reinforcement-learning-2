{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev']  # upgrade fastrl on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os,warnings\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.basics import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "# Local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-ballet",
   "metadata": {},
   "source": [
    "# Core\n",
    "> Core libs for fastrl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-corruption",
   "metadata": {},
   "source": [
    "## D\n",
    "> A better dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def isnone(v): return v is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def map_dict_ex(d,f,*args,gen=False,wise=None,**kwargs):\n",
    "    \"Like `map`, but for dicts and uses `bind`, and supports `str` and indexing\"\n",
    "    g = (bind(f,*args,**kwargs) if callable(f)\n",
    "         else f.format if isinstance(f,str)\n",
    "         else f.__getitem__)\n",
    "\n",
    "    if wise is None:  return map(g,d.items())\n",
    "    return ((k,g(v)) if wise=='value' else (g(k),v) for k,v in d.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-screw",
   "metadata": {},
   "source": [
    "Check that general mapping for dicts works nicely..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict={'a':1,'b':2,'c':3}\n",
    "test_eq(dict(map_dict_ex(test_dict,lambda t:(t[0]+'_new',t[1]+1))),{'a_new':2,'b_new':3,'c_new':4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-birmingham",
   "metadata": {},
   "source": [
    "Check that key and value wise mapping works correctly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(dict(map_dict_ex(test_dict,lambda k:k+'_new',wise='key')),{'a_new':1,'b_new':2,'c_new':3})\n",
    "test_eq(dict(map_dict_ex(test_dict,lambda v:v+1,wise='value')),{'a':2,'b':3,'c':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_error_msg='Found idxs: %s have values more than %s e.g.: %s'\n",
    "\n",
    "class D(dict):\n",
    "    \"Improved version of `dict` with array handling abilities\"\n",
    "    def __init__(self,*args,mapping=False,**kwargs):\n",
    "        self.mapping=mapping\n",
    "        super().__init__(*args,**kwargs)\n",
    "        \n",
    "    def eq_k(self,o:'D',with_diff=False):\n",
    "        eq=set(o.keys())==set(self.keys())\n",
    "        if with_diff: return eq,set(o.keys()).symmetric_difference(set(self.keys()))\n",
    "        return eq\n",
    "    def _new(self,*args,**kwargs): return type(self)(*args,**kwargs)\n",
    "\n",
    "    def map(self,f,*args,gen=False,**kwargs): \n",
    "        return (self._new,noop)[gen](map_dict_ex(self,f,*args,**kwargs),mapping=True)\n",
    "    def mapk(self,f,*args,gen=False,wise='key',**kwargs):\n",
    "        return self.map(f,*args,gen=gen,wise=wise,**kwargs)\n",
    "    def mapv(self,f,*args,gen=False,wise='value',**kwargs):\n",
    "        return self.map(f,*args,gen=gen,wise=wise,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict=D({'a':1,'b':2,'c':3})\n",
    "test_eq(test_dict.map(lambda t:(t[0]+'_new',t[1]+1)),{'a_new':2,'b_new':3,'c_new':4})\n",
    "test_eq(isinstance(test_dict.map(lambda t:(t[0]+'_new',t[1]+1),gen=True),map),True)\n",
    "test_eq(dict(test_dict.map(lambda t:(t[0]+'_new',t[1]+1),gen=True)),{'a_new':2,'b_new':3,'c_new':4})\n",
    "\n",
    "test_eq(test_dict.mapk(lambda k:k+'_new'),{'a_new':1,'b_new':2,'c_new':3})\n",
    "test_eq(dict(test_dict.mapk(lambda k:k+'_new',gen=True)),{'a_new':1,'b_new':2,'c_new':3})\n",
    "\n",
    "test_eq(test_dict.mapv(lambda v:v+1,wise='value'),{'a':2,'b':3,'c':4})\n",
    "test_eq(dict(test_dict.mapv(lambda v:v+1,gen=True,wise='value')),{'a':2,'b':3,'c':4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-necessity",
   "metadata": {},
   "source": [
    "`BD` is the primary data structure that `fastrl` uses. It allows for easily iterating and doing operations on steps attained from environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-yukon",
   "metadata": {},
   "source": [
    "## BD \n",
    "> A batch wise dictionary that requires all values to be numpy,tensor, or None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-surrey",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-caution",
   "metadata": {},
   "source": [
    "#### Stacking API\n",
    "> We use the fastcore typedispatch decortors to select the currect method of stacking arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def stack(a:Tensor,b:Tensor): return torch.vstack((a,b))\n",
    "@typedispatch\n",
    "def stack(a:(np.array,np.ndarray),b:(np.array,np.ndarray)): return np.vstack((a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-external",
   "metadata": {},
   "source": [
    "#### Exceptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "class BDTypeError(Exception):\n",
    "    def __init__(self,k,v):\n",
    "        self.message=f'Key:{k} has value {type(v)} when it should have type Tensor, np.ndarray, or None'\n",
    "        super().__init__(self.message)\n",
    "    @classmethod\n",
    "    def check(cls,d:dict,strict=False): \n",
    "        for k,v in d.items():\n",
    "            if isinstance(k,int): raise TypeError(f'{k} cannot be an int since ints can be used to index.')\n",
    "            types=(np.ndarray,NoneType)\n",
    "            if not strict:types=(*types,list,L,Tensor)\n",
    "            if not isinstance(v,(list,L,Tensor,np.ndarray,NoneType)): raise cls(k,v)\n",
    "                \n",
    "class BDBatchSizeError(Exception):\n",
    "    def __init__(self,k,v,bs):\n",
    "        self.message=f'Key:{k} has shape {v} when it should have shape[0]=={bs}'\n",
    "        super().__init__(self.message)\n",
    "    @classmethod\n",
    "    def check(cls,d:'BD'): \n",
    "        for k,v in d.items():\n",
    "            if v.shape[0]!=d.bd_batch_size: raise cls(k,v.shape,d.bd_batch_size)\n",
    "                \n",
    "class BDKeyMisMatchError(Exception):\n",
    "    def __init__(self,different):\n",
    "        self.message=f'Keys: {different} are not shared by the dictionaries'\n",
    "        super().__init__(self.message)\n",
    "    @classmethod\n",
    "    def check(cls,d:'BD',other:'BD'): \n",
    "        eq,different=d.eq_k(other,with_diff=True)\n",
    "        if not eq: raise cls(different)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-noise",
   "metadata": {},
   "source": [
    "#### Correction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def list2tensor(l:(L,list)): return tensor(l) if not isinstance(l,np.ndarray) else l\n",
    "@typedispatch\n",
    "def batch_dim(o:Tensor,bs=1): return o.unsqueeze(0) if len(o.shape)<2 or o.shape[0]>bs else o\n",
    "@typedispatch\n",
    "def batch_dim(o:np.ndarray,bs=1): return np.expand_dims(o,0) if len(o.shape)<2 or o.shape[0]>bs else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BD(D):\n",
    "    def __init__(self,*args,bd_batch_size=1,**kwargs):\n",
    "        \"Converts listy values to tensors, and keep np.ndarray and tensor values. Adds batch dims and validates them.\"\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.bd_batch_size=ifnone(bd_batch_size,self.bs)\n",
    "        BDTypeError.check(self)\n",
    "        if not self.mapping: \n",
    "            self.update(self.mapv(list2tensor).mapv(batch_dim,bs=self.bd_batch_size))\n",
    "            self.mapping=False\n",
    "        BDTypeError.check(self,strict=True)\n",
    "        if not self.mapping: BDBatchSizeError.check(self)\n",
    "    @property\n",
    "    def bs(self):\n",
    "        if len(self.values())==0: return 0\n",
    "        return dict(self).popitem()[1].shape[0]\n",
    "        \n",
    "    def __getitem__(self,o):\n",
    "        if isinstance(o,int) or is_listy(o): \n",
    "            bs=1 if isinstance(o,int) else None\n",
    "            return BD({k:self[k][o] for k in self},bd_batch_size=bs)\n",
    "        return super().__getitem__(o)\n",
    "    \n",
    "    def __add__(self,o):\n",
    "        BDKeyMisMatchError.check(self,o)\n",
    "        return BD({k:stack(self[k],o[k]) for k in self},\n",
    "                  bd_batch_size=self.bd_batch_size+o.bd_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-suggestion",
   "metadata": {},
   "source": [
    "We need to change any indexer that is passed. We don't know if the indexer is going to\n",
    "be a numpy array, slice, tensor, or int.\n",
    "All we know is 2 things:\n",
    "- If it is an int, the batch dim will disappear\n",
    "- If it is an indexer, then the batch dim will stay, but be smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_f=lambda: {'state':np.random.rand(4,),'next_state':torch.rand(4,),\n",
    "                'action':np.random.randint(0,2),'reward':np.random.ranf(),\n",
    "                'steps':np.random.randint(0,20),'episode_reward':np.random.randint(5,40),\n",
    "                'env':np.random.randint(5,40),'done':np.random.randint(0,2)==0}\n",
    "test_fail(lambda:BD(step_f()))\n",
    "step_f=lambda: {'state':np.random.rand(4,),'next_state':torch.rand(4,),\n",
    "                'action':[np.random.randint(0,2)],'reward':[np.random.ranf()],\n",
    "                'steps':[np.random.randint(0,20)],'episode_reward':[np.random.randint(5,40)],\n",
    "                'env':[np.random.randint(5,40)],'done':[np.random.randint(0,2)==0],\n",
    "                'image':torch.rand(5,5,3)}\n",
    "\n",
    "test_d=sum((BD(step_f()) for _ in range(19)),BD(step_f()))\n",
    "test_eq(test_d.bd_batch_size,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(type(test_d['state']),np.ndarray)\n",
    "test_eq(type(test_d[5]),BD)\n",
    "test_eq(test_d[5:8].bd_batch_size,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-penguin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n",
      "Converted .data.block_old.ipynb.\n",
      "Converted 00_core.ipynb.\n",
      "Converted 00_nbdev_extension.ipynb.\n",
      "Converted 05_data.block.ipynb.\n",
      "Converted 05_data.test_async.ipynb.\n",
      "Converted 20_test_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted nbdev_template.ipynb.\n",
      "No notebooks were modified\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import make_readme\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-captain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
