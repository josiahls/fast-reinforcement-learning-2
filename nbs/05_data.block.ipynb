{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev']  # upgrade fastrl on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "from time import sleep\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# Local modules\n",
    "from fastrl.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time,sys\n",
    "import torch.multiprocessing as mp\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-watch",
   "metadata": {},
   "source": [
    "# Data Block\n",
    "> Fastrl transforms for iterating through environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQN(Module):\n",
    "    def __init__(self):\n",
    "        self.policy=nn.Sequential(\n",
    "            nn.Linear(4,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50,2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x): \n",
    "        return torch.argmax(self.policy(x),dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-preview",
   "metadata": {},
   "source": [
    "Development of this was helped by [IterableData documentation on multiple workers](https://github.com/pytorch/pytorch/blob/4949eea0ffb60dc81a0a78402fa59fdf68206718/torch/utils/data/dataset.py#L64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-planning",
   "metadata": {},
   "source": [
    "This code is heavily modifed from https://github.com/Shmuma/ptan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-canyon",
   "metadata": {},
   "source": [
    "Reference for env [semantics related to vectorized environments](https://github.com/openai/universe/blob/master/doc/env_semantics.rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-resource",
   "metadata": {},
   "source": [
    "Useful links:\n",
    "- [torch multiprocessing](https://github.com/pytorch/pytorch/blob/a61a8d059efa0fb139a09e479b1a2c8dd1cf1a44/torch/utils/data/dataloader.py#L564)\n",
    "- [torch worker](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/_utils/worker.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-chicken",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/fastrl/fastrl/core.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D.mapv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _listify_if_single(o,single): \n",
    "    if not isinstance(o,(np.ndarray,Tensor)) and single:\n",
    "        return L(o)\n",
    "    if isinstance(o,(np.ndarray)) and single:\n",
    "        return np.expand_dims(o,0) if len(o.shape)==1 else o\n",
    "    if isinstance(o,(np.ndarray)) and single:\n",
    "        return o.unsqueeze(0) if len(o.size())==1 else o\n",
    "    return o\n",
    "\n",
    "def init_experience(single=False,but='',**kwargs): \n",
    "    \"Returns dictionary with default values that can be overridden.\"\n",
    "    experience=D(\n",
    "        state=0,action=0,next_state=0,reward=0,done=False,\n",
    "        step=0,steps=0,n_env=0,image=0\n",
    "    )\n",
    "    for s in but.split(','):\n",
    "        if s in experience:del experience[s]\n",
    "    return D(merge(experience,kwargs)).mapv(_listify_if_single,single=single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-thumb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 0,\n",
       " 'action': 0,\n",
       " 'next_state': 0,\n",
       " 'reward': 0,\n",
       " 'done': False,\n",
       " 'step': 0,\n",
       " 'steps': 0,\n",
       " 'n_env': 0,\n",
       " 'image': 0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_experience()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-frontier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 0,\n",
       " 'action': 0,\n",
       " 'next_state': 0,\n",
       " 'reward': 0,\n",
       " 'done': False,\n",
       " 'steps': 0,\n",
       " 'n_env': 0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_experience(but='image,step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-aruba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': (#3) [0,0,0],\n",
       " 'action': (#3) [0,0,0],\n",
       " 'next_state': (#3) [0,0,0],\n",
       " 'reward': (#3) [0,0,0],\n",
       " 'done': (#3) [False,False,False],\n",
       " 'step': (#3) [0,0,0],\n",
       " 'steps': (#3) [0,0,0],\n",
       " 'n_env': (#3) [0,0,0],\n",
       " 'image': (#3) [0,0,0]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([init_experience(),init_experience()],init_experience())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _state2experience(s,**kwargs):   return init_experience(state=s,**kwargs)\n",
    "def _env_reset(o):                   return o.reset()\n",
    "def _env_seed(o,seed):               return o.seed(seed)\n",
    "def _env_render(o,mode='rgb_array'): return [o.render(mode=mode).copy()]\n",
    "def _env_step(o,*args,**kwargs):     return o.step(*args,**kwargs)\n",
    "\n",
    "class FakeAgent:\n",
    "    def __init__(self,action_space): store_attr()\n",
    "    def __call__(self,state,**kwargs):\n",
    "        return L([self.action_space.sample() for _ in range(state.shape[0])]),D(kwargs)\n",
    "\n",
    "class ExperienceSource(Stateful):\n",
    "    _stateattrs=('pool',)\n",
    "    def __init__(self,env:str,agent=None,n_envs:int=1,steps_count:int=1,steps_delta:int=1,\n",
    "                 seed:int=None,render=None,num_workers=0,but='',**kwargs):\n",
    "        store_attr()\n",
    "        self.env_kwargs=kwargs\n",
    "        self.pool=L()\n",
    "        if self.render is None: self.but+=',image'\n",
    "\n",
    "    def _init_state(self):\n",
    "        \"Inits the histories, experiences, and the environment pool when sent to a `Process`\"\n",
    "        self.history,self.pool=L((deque(maxlen=self.steps_count),\n",
    "                                  gym.make(self.env,**self.env_kwargs)) \n",
    "                                  for _ in range(self.n_envs)).zip().map(L) \n",
    "        self.pool.map(_env_seed,seed=self.seed)\n",
    "        if self.agent is None: self.agent=FakeAgent(self.pool[0].action_space)\n",
    "        self.reset_all()\n",
    "        \n",
    "    def reset_all(self):\n",
    "        self.experiences=self.pool.map(_env_reset)\n",
    "        self.experiences=self.experiences.map(_state2experience,but=self.but,single=self.n_envs==1)\n",
    "        if self.n_envs>1:self.experiences=sum(self.experiences[1:],self.experiences[0])\n",
    "        else:            self.experiences=self.experiences[0]\n",
    "        self.attempt_render(self.experiences)\n",
    "        \n",
    "    def attempt_render(self,experiences,indexes=None):\n",
    "        if self.render is not None: \n",
    "            pool=self.pool if indexes is None else self.pool[indexes]\n",
    "            renders=pool.map(_env_render,mode=self.render)\n",
    "            # No idea why we have to do this, but multiprocessing hangs forever otherwise\n",
    "            if self.num_workers>0:sleep(0.1) \n",
    "            experiences['image']=np.vstack(renders).astype(float)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"Iterates through a list of environments.\"\n",
    "        if not self.pool:self._init_state()\n",
    "        while True: \n",
    "#             try:\n",
    "#             print(self.experiences)\n",
    "            not_done_idxs=self.experiences.argwhere('done',L.argwhere,lambda x:x==False)\n",
    "            not_done_experiences=self.experiences.filter(indexes=not_done_idxs)\n",
    "#             print(not_done_experiences)\n",
    "            actions,experiences=self.agent(**not_done_experiences)\n",
    "            step_res=self.pool[not_done_idxs].zipwith(actions).starmap(_env_step)\n",
    "            next_states,(rewards,dones,info)=step_res.zip()[0],step_res.zip()[1:].map(L)\n",
    "            \n",
    "            self.attempt_render(self.experiences,not_done_idxs)\n",
    "\n",
    "            experiences=D(merge(not_done_experiences,experiences,\n",
    "                                D(next_state=next_states,reward=rewards,done=dones)))\n",
    "            if self.n_envs>1:\n",
    "                split_experiences=parallel(partial(experiences.subset),not_done_idxs,\n",
    "                                           threadpool=True,n_workers=2,progress=False)\n",
    "                yield split_experiences\n",
    "            else:\n",
    "                print(experiences)\n",
    "                yield experiences # {'actions':actions}\n",
    "#             except ValueError:\n",
    "#                 self.reset_all()\n",
    "            \n",
    "add_docs(ExperienceSource,\n",
    "        \"\"\"Iterates through `n_envs` of `env` feeding experience or states into `agent`.\n",
    "           If `agent` is None, then random actions will be taken instead.\n",
    "           It will return `steps_count` experiences every `steps_delta`.\n",
    "           At the end of an env, it will return `steps_count-1` experiences per next. \"\"\",\n",
    "        reset_all=\"resets the envs and experience\",\n",
    "        attempt_render=\"Updates `experiences` with images if `render is not None`. Optionally indexes can be passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SourceDataset(IterableDataset):\n",
    "    \"Iterates through a `source` object. Allows for re-initing source connections when `num_workers>0`\"\n",
    "    def __init__(self,source=None): store_attr('source')\n",
    "    def __iter__(self):             return iter(self.source)\n",
    "    def wif(self):                  self.source._init_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "source=ExperienceSource('CartPole-v1',None,n_envs=2)\n",
    "dataset=SourceDataset(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-breakfast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>next_state</th>\n",
       "      <th>reward</th>\n",
       "      <th>done</th>\n",
       "      <th>step</th>\n",
       "      <th>steps</th>\n",
       "      <th>n_env</th>\n",
       "      <th>state_mu</th>\n",
       "      <th>next_state_mu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.034632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>-0.013647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.014316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.011686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.042595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>-0.011611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.022921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>-0.035306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.003363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>-0.011064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.031966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.060836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.036953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.090404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.012809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.072685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.037470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.055736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>0</td>\n",
       "      <td>torch.Size([20, 4])</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.013918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  state  action           next_state  reward   done  step  \\\n",
       "0   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "1   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "2   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "3   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "4   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "5   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "6   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "7   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "8   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "9   torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "10  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "11  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "12  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "13  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "14  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "15  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "16  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "17  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "18  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "19  torch.Size([20, 4])       0  torch.Size([20, 4])     1.0  False     0   \n",
       "\n",
       "    steps  n_env  state_mu  next_state_mu  \n",
       "0       0      0 -0.006892      -0.034632  \n",
       "1       0      0  0.009369      -0.013647  \n",
       "2       0      0 -0.006892      -0.014316  \n",
       "3       0      0  0.009369       0.011686  \n",
       "4       0      0 -0.006892      -0.042595  \n",
       "5       0      0  0.009369      -0.011611  \n",
       "6       0      0 -0.006892      -0.022921  \n",
       "7       0      0  0.009369      -0.035306  \n",
       "8       0      0 -0.006892      -0.003363  \n",
       "9       0      0  0.009369      -0.011064  \n",
       "10      0      0 -0.006892      -0.031966  \n",
       "11      0      0  0.009369       0.012880  \n",
       "12      0      0 -0.006892      -0.060836  \n",
       "13      0      0  0.009369       0.036953  \n",
       "14      0      0 -0.006892      -0.090404  \n",
       "15      0      0  0.009369       0.012809  \n",
       "16      0      0 -0.006892      -0.072685  \n",
       "17      0      0  0.009369       0.037470  \n",
       "18      0      0 -0.006892      -0.055736  \n",
       "19      0      0  0.009369       0.013918  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=None\n",
    "for x in DataLoader(dataset,num_workers=0,n=10,persistent_workers=True,wif=dataset.wif):\n",
    "    data=D(x) if data is None else data+D(x)\n",
    "data.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-priority",
   "metadata": {},
   "source": [
    "`ExperienceSource` is designed for iterating through `n_envs` environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-charter",
   "metadata": {},
   "source": [
    "A single experience is a `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "D(state=None,action=None,next_state=None,reward=None,rewards=None,\n",
    "             step=None,steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-function",
   "metadata": {},
   "source": [
    "However, an agent has full power to add fields to this dict wile running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ExperienceSource._init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ExperienceSource.__iter__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-burning",
   "metadata": {},
   "source": [
    "If the `self.pool` field is empty, it will call `_init_state` to reinitialize everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gym\n",
    "from queue import deque\n",
    "\n",
    "class ExperienceSource(object):\n",
    "    def __init__(self, env:str,agent,n_envs:int=1,steps_count:int=1,steps_delta:int=1,\n",
    "                 vectorized:bool=False,seed:int=None):\n",
    "        store_attr()\n",
    "        self.pool:List[gym.Env]=[gym.make(self.env) for _ in range(self.n_envs)]\n",
    "    \n",
    "    def init_env(self,env,states,histories,cur_rewards,cur_steps,env_lens):\n",
    "        env.seed(self.seed)\n",
    "        obs=env.reset()\n",
    "        if self.vectorized:\n",
    "            obs_len = len(obs)\n",
    "            states.extend(obs)\n",
    "        else:\n",
    "            obs_len = 1\n",
    "            states.append(obs)\n",
    "        env_lens.append(obs_len)\n",
    "\n",
    "        for _ in range(obs_len):\n",
    "            histories.append(deque(maxlen=self.steps_count))\n",
    "            cur_rewards.append(0.0)\n",
    "            cur_steps.append(0)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        states,histories,cur_rewards,cur_steps,env_lens=[],[],[],[],[]\n",
    "\n",
    "        for env in self.pool: self.init_env(env,states,histories,cur_rewards,cur_steps,env_lens)\n",
    "\n",
    "        iter_idx = 0\n",
    "        while True:\n",
    "            actions = [None] * len(states)\n",
    "            states_input = []\n",
    "            states_indices = []\n",
    "            for idx, state in enumerate(states):\n",
    "                if state is None:\n",
    "                    actions[idx] = self.pool[0].action_space.sample()  # assume that all envs are from the same family\n",
    "                else:\n",
    "                    states_input.append(state)\n",
    "                    states_indices.append(idx)\n",
    "            if states_input:\n",
    "                states_actions = self.agent(states_input)\n",
    "                for idx, action in enumerate(states_actions):\n",
    "                    g_idx = states_indices[idx]\n",
    "                    actions[g_idx] = action\n",
    "#             grouped_actions = _group_list(actions, env_lens)\n",
    "            grouped_actions=np.split(actions,env_lens[:])\n",
    "\n",
    "            global_ofs = 0\n",
    "            for env_idx, (env, action_n) in enumerate(zip(self.pool, grouped_actions)):\n",
    "                if self.vectorized:\n",
    "                    next_state_n, r_n, is_done_n, _ = env.step(action_n)\n",
    "                else:\n",
    "                    next_state, r, is_done, _ = env.step(action_n[0])\n",
    "                    next_state_n, r_n, is_done_n = [next_state], [r], [is_done]\n",
    "\n",
    "                for ofs, (action, next_state, r, is_done) in enumerate(zip(action_n, next_state_n, r_n, is_done_n)):\n",
    "                    idx = global_ofs + ofs\n",
    "                    state = states[idx]\n",
    "                    history = histories[idx]\n",
    "\n",
    "                    cur_rewards[idx] += r\n",
    "                    cur_steps[idx] += 1\n",
    "                    if state is not None:\n",
    "                        history.append(dict(state=state,next_state=next_state, action=action, reward=r, done=is_done,steps=cur_steps[idx],episode_reward=cur_rewards[idx],env=env_idx))\n",
    "                    if len(history) == self.steps_count and iter_idx % self.steps_delta == 0:\n",
    "                        yield tuple(history)\n",
    "                    states[idx] = next_state\n",
    "                    if is_done:\n",
    "                        # in case of very short episode (shorter than our steps count), send gathered history\n",
    "                        if 0 < len(history) < self.steps_count:\n",
    "                            yield tuple(history)\n",
    "                        # generate tail of history\n",
    "                        while len(history) > 1:\n",
    "                            history.popleft()\n",
    "                            yield tuple(history)\n",
    "                        cur_rewards[idx] = 0.0\n",
    "                        cur_steps[idx] = 0\n",
    "                        # vectorized envs are reset automatically\n",
    "                        env.seed(self.seed)\n",
    "                        states[idx]=env.reset() if not self.vectorized else None\n",
    "                        history.clear()\n",
    "                global_ofs += len(action_n)\n",
    "            iter_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=lambda s: [0]\n",
    "\n",
    "data=None\n",
    "\n",
    "for e,_ in zip(ExperienceSource('CartPole-v1',agent,seed=0,steps_count=3),range(70)):\n",
    "    data=D(e) if data is None else data+D(e)\n",
    "data.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TestDataset(IterableDataset):\n",
    "    def __init__(self,start=1,end=10,policy=None,device='cpu',n_envs=1):\n",
    "        store_attr('start,end,policy,device,n_envs')\n",
    "        \n",
    "    def init_envs(self,n):\n",
    "        self.envs=[gym.make('CartPole-v1') for i in range(n)]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        worker_info=torch.utils.data.get_worker_info()\n",
    "        \n",
    "        if worker_info is None:  # single-process data loading, return the full iterator\n",
    "            self.init_envs(self.n_envs)\n",
    "        else:  # in a worker process\n",
    "            # split workload\n",
    "            per_worker=int(math.ceil(self.n_envs/worker_info.num_workers))\n",
    "            self.init_envs(per_worker)\n",
    "        return iter(range(iter_start, iter_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():   \n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import make_readme\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-shirt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
