{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp basic_agents\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Note these are modified versions of 'Shmuma/Ptan'. Github, 2020, https://github.com/Shmuma/ptan/blob/master/ptan/agent.py. Accessed 13 June 2020.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "import torch, torch.nn.functional as F\n",
    "from torch import ByteTensor, DoubleTensor, FloatTensor, HalfTensor, LongTensor, ShortTensor, Tensor\n",
    "from torch import nn, optim, as_tensor\n",
    "from torch.utils.data import BatchSampler, DataLoader, Dataset, Sampler, TensorDataset\n",
    "from torch.nn.utils import weight_norm, spectral_norm\n",
    "from dataclasses import asdict,dataclass\n",
    "from typing import Callable,Tuple,Union\n",
    "# from fastai.torch_core import *\n",
    "# from fastai.basic_data import *\n",
    "# from fastai.basic_train import *\n",
    "from fastai.basics import *\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\"Note these are modified versions of 'Shmuma/Ptan'. Github, 2020, https://github.com/Shmuma/ptan/blob/master/ptan/agent.py. Accessed 13 June 2020.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "from fastcore.foundation import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import pytest\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Action Selection\n",
    "\n",
    "> Methods of exploratively selecting actions based on a model state input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ActionSelector:\n",
    "    \"Abstract class which converts scores to the actions.\"\n",
    "    def __call__(self,scores):raise NotImplementedError\n",
    "\n",
    "class ArgmaxActionSelector(ActionSelector):\n",
    "    \"Selects actions using argmax.\"\n",
    "    def __call__(self,scores):\n",
    "        assert isinstance(scores,np.ndarray)\n",
    "        return np.argmax(scores,axis=1)\n",
    "\n",
    "@dataclass\n",
    "class EpsilonGreedyActionSelector(ActionSelector):\n",
    "    epsilon:float=0.05\n",
    "    selector:ActionSelector=ArgmaxActionSelector()\n",
    "\n",
    "    def __call__(self,scores):\n",
    "        assert isinstance(scores,np.ndarray)\n",
    "        bs,n_a=scores.shape\n",
    "        a=self.selector(scores)\n",
    "        mask=np.random.random(size=bs)<self.epsilon\n",
    "        rand_a=np.random.choice(n_a, sum(mask))\n",
    "        a[mask]=rand_a\n",
    "        return a\n",
    "\n",
    "class ProbabilityActionSelector(ActionSelector):\n",
    "    \"Converts probabilities of actions into action by sampling them.\"\n",
    "    def __call__(self,probs):\n",
    "        assert isinstance(probs,np.ndarray)\n",
    "        actions=[np.random.choice(len(prob),p=prob) for prob in probs]\n",
    "        return np.array(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Agents\n",
    "\n",
    "> Basic Agent classes for handling models and actions. Details, please ref `basic_train`\n",
    "\n",
    "There is an important difference between `Learner`'s, `nn.Module`'s, and `Agent`'s. \n",
    "\n",
    "`Learners`:\n",
    "- Ref `basic_train`\n",
    "\n",
    "`nn.Module`:\n",
    "- Contain only `pytorch` related code.\n",
    "- Function as the brain of any of these agents and are the objects to be optimized.\n",
    "- Are highly portable, however for runtime usage are too \"dumb\" or simple to be practical. If by themselves, extra code needs to wrap them to handle environments.\n",
    "\n",
    "`Agent` (`agent_core`):\n",
    "- Contain a `nn.Module` and a limited number of `fastrl` objects. Unlike `nn.Module`, these can maintain a state.\n",
    "- Function as the interface between the `nn.Module` and the environments. They have 2 goals:\n",
    "    - Convert states into something the `nn.Module` can interpret.\n",
    "    - Modify the `nn.Module` output (actions) for randomized exploration.\n",
    "- Designed to be highly portable only requiring `basic_agents` as a dependency. These should allow for easily saving, and using in environments where `fastrl` might not necessarily be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def default_states_preprocessor(s,dtype=np.float32):\n",
    "    \"Convert list of states into the form suitable for model. By default we assume Variable.\"\n",
    "    np_s=np.expand_dims(s,0) if len(np.array(s).shape)==1 else np.array(s, copy=False)\n",
    "    return torch.tensor(np_s.astype(dtype))\n",
    "\n",
    "def float32_preprocessor(s):\n",
    "    np_s=np.array(s, dtype=np.float32)\n",
    "    return torch.tensor(np_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class BaseAgent(object):\n",
    "    model:nn.Module=None # If None, learner will set\n",
    "    def initial_state(self):return None\n",
    "    def __call__(self,sl,asl,include_batch_dim=False):\n",
    "        assert isinstance(sl,(list,np.ndarray))\n",
    "        assert isinstance(asl,(list,np.ndarray))\n",
    "        assert len(asl)==len(sl)\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class TestAgent(BaseAgent):\n",
    "    env:object=None\n",
    "    def initial_state(self):return None\n",
    "    def __call__(self,sl,asl=None,include_batch_dim=False):\n",
    "        if type(self.env)!=list:return self.env.action_space.sample(),None\n",
    "        return self.env[0].action_space.sample(),None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(BaseAgent.initial_state,\"Should create initial empty state for the agent. It will be called for the start of the episode.\")\n",
    "add_docs(BaseAgent.__call__,textwrap.fill(\"\"\"Convert observations and state list `sl` into actions to take. Agent state list `asl` may also be used by the agent.\n",
    "         It is expected that `asl` is likely either going to be an internal state tracked by the agent, or it is simply a parameter used during subclassing.\n",
    "         The `include_batch_dim` should toggle whether to remove/include the batch dim of an action. Naturally, `gym` envs don't understand batch dimensions.\"\"\"\n",
    "        ))\n",
    "add_docs(BaseAgent,\"Abstract Agent interface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGQCAIAAAD9V4nPAAAGpUlEQVR4nO3d0WliQRiA0XWxidThlrF1aE1aR8pY60gZdx8CEkwignHG5DvnSRyQ34fLxwwyrpZl+QUAVb9nDwAAMwkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCEDaevYA0HI87F5fbLb7uZMAr4QQ5jgV8S11hPEcjQKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhjPPhtWon7leDKYQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhhEGOh92F1c12P2wS4C0hBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCAFIE0IA0oQQgDQhBCBNCGGE42F3YXWz3Q+bBDgjhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhACkCSEAaUIIQJoQApAmhHCV1W3u9OFjvjv8bEIId/dvv72w+md3GDYJ8J4QApC2nj0AVDy/nO8L/z7ZC8J8doQwwvsKfvYmMJgQwkxaCNMJIdyd2sEjE0IA0oQQgDQhhLvz61B4ZEIIM2kkTCeEMMKHwVNBeASrZVlmzwDfwBde7Hl249otV6x5fuF2QghXecwbrj2/cDtHowAAAFWORuEqjkbhp3I0CkCaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaEAKQJoQApAkhAGlCCECaf58AIM2OEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANKEEIA0IQQgTQgBSBNCANL+A2WoP4lWj3t5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400 at 0x7FC9B8621A10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image\n",
    "\n",
    "env=gym.make('CartPole-v1')\n",
    "agent=TestAgent(env=env)\n",
    "\n",
    "done,episode_count,max_episodes=True,0,10\n",
    "\n",
    "while True:\n",
    "    if done:s=env.reset()\n",
    "    s,done,r,_=env.step(agent(s)[0])\n",
    "    display.clear_output(wait=True)\n",
    "    im=env.render(mode='rgb_array')\n",
    "    new_im=PIL.Image.fromarray(im)\n",
    "    display.display(new_im)\n",
    "    if done and episode_count>max_episodes:break\n",
    "    if done:episode_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class DiscreteAgent(BaseAgent):\n",
    "    \"DiscreteAgent a simple discrete action selector.\"\n",
    "    a_selector:ActionSelector=None\n",
    "    device:str=None\n",
    "    preprocessor:Callable=default_states_preprocessor\n",
    "    apply_softmax:bool=False\n",
    "        \n",
    "    def safe_unbatch(self,o:np.array)->np.array:return o[0] if o.shape[0]==1 and len(o.shape)>1 else o\n",
    "    def split_v(self,v,asl): return v,asl\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self,s,asl=None,include_batch_dim=False):\n",
    "        s=self.preprocessor(s) if self.preprocessor is not None else s\n",
    "        asl= np.zeros(s.shape) if asl is None else asl\n",
    "        s=s.to(self.device) if torch.is_tensor(s) else s\n",
    "        v=self.model(s)\n",
    "        if type(v)==tuple:v,asl=self.split_v(v,asl)\n",
    "        if self.apply_softmax:\n",
    "            v=F.softmax(v,dim=1)\n",
    "        q=v.data.cpu().numpy()\n",
    "        al=self.a_selector(q)\n",
    "        if not include_batch_dim:al=self.safe_unbatch(al).tolist()\n",
    "        return al if len(al)!=1 or include_batch_dim else al[0],asl\n",
    "\n",
    "@dataclass\n",
    "class DQNAgent(DiscreteAgent):\n",
    "    \"DQNAgent is a memoryless DQN agent which calculates Q values from the observations and  converts them into the actions using a_selector.\"\n",
    "    def __post_init__(self):\n",
    "        self.a_selector=ifnone(self.a_selector,ArgmaxActionSelector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(DQNAgent,__call__='DQNAgents will likely never have `asl` passed and used. This is however here for novel DQN implimentations.',\n",
    "         safe_unbatch='Will remove the batch dim from `o` if `o` represents a single item.',\n",
    "         split_v='In the event that `v` is a tuple, then there is multle ouputs from the `model`. Primarly used for A2C.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400 at 0x7FC9B8621510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env=gym.make('CartPole-v1')\n",
    "agent=DQNAgent(model=nn.Sequential(nn.Linear(4,5),nn.ReLU(),nn.Linear(5,2)))\n",
    "\n",
    "done,episode_count,max_episodes=True,0,10\n",
    "\n",
    "while True:\n",
    "    if done:s=env.reset()\n",
    "    s,done,r,_=env.step(agent(s)[0])\n",
    "    display.clear_output(wait=True)\n",
    "    im=env.render(mode='rgb_array')\n",
    "    new_im=PIL.Image.fromarray(im)\n",
    "    display.display(new_im)\n",
    "    if done and episode_count>max_episodes:break\n",
    "    if done:episode_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TargetNet:\n",
    "    \"Wrapper around model which provides copy of it instead of trained weights.\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.target_model = copy.deepcopy(model)\n",
    "\n",
    "    def sync(self):self.target_model.load_state_dict(self.model.state_dict())\n",
    "    def alpha_sync(self,alpha):\n",
    "        \"Blend params of target net with params from the model.\"\n",
    "        assert isinstance(alpha,float)\n",
    "        assert 0.0<alpha<=1.0\n",
    "        state=self.model.state_dict()\n",
    "        tgt_state=self.target_model.state_dict()\n",
    "        for k, v in state.items():\n",
    "            tgt_state[k]=tgt_state[k]*alpha+(1-alpha)*v\n",
    "        self.target_model.load_state_dict(tgt_state)\n",
    "\n",
    "@dataclass\n",
    "class PolicyAgent(DiscreteAgent):\n",
    "    \"Policy agent gets action probabilities from the model and samples actions from it.\"\n",
    "    def __post_init__(self):\n",
    "        self.a_selector=ifnone(self.a_selector,ProbabilityActionSelector())\n",
    "        self.apply_softmax=True\n",
    "\n",
    "class ActorCriticAgent(PolicyAgent):\n",
    "    \"Policy agent which returns policy and value tensors from observations. Value are stored in agent's state \\\n",
    "     and could be reused for rollouts calculations by ExperienceSource.\"\n",
    "    def split_v(self,v,asl):\n",
    "        return v[0],v[1].data.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearA2C(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(LinearA2C, self).__init__()\n",
    "\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        fx=x.float()\n",
    "        return self.policy(fx)\n",
    "model=LinearA2C((4,),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([[0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent=PolicyAgent(model=model)\n",
    "agent([ 0.044186,-0.021265,0.033516,-0.011447])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 02_callbacks.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted 05a_data.ipynb.\n",
      "Converted 05b_async_data.ipynb.\n",
      "Converted 06_basic_train.ipynb.\n",
      "Converted 12_a3c.a3c_data.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted notes.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: /opt/project/fastrl/nbs/12_a3c.a3c_data.ipynb\n",
      "An error occurred while executing the following cell:\n",
      "------------------\n",
      "from nbdev.showdoc import show_doc\n",
      "from fastrl.a3c.a3c_data import *\n",
      "------------------\n",
      "\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-1-19dfa7b4de72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowdoc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma3c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma3c_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/opt/project/fastrl/fastrl/a3c/a3c_data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_train\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai.callbacks'\n",
      "ModuleNotFoundError: No module named 'fastai.callbacks'\n",
      "\n",
      "converting: /opt/project/fastrl/nbs/03_basic_agents.ipynb\n",
      "converting: /opt/project/fastrl/nbs/05b_async_data.ipynb\n",
      "converting: /opt/project/fastrl/nbs/05a_data.ipynb\n",
      "An error occurred while executing the following cell:\n",
      "------------------\n",
      "show_doc(Experience:d:bool;s:np.ndarray;sp:np.ndarray;r:float;a:Any;eid, default_cls_level=2)\n",
      "------------------\n",
      "\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-cdb6cff51b73>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n",
      "\u001b[0;31m    show_doc(Experience:d:bool;s:np.ndarray;sp:np.ndarray;r:float;a:Any;eid, default_cls_level=2)\u001b[0m\n",
      "\u001b[0m                       ^\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n",
      "\n",
      "SyntaxError: invalid syntax (<ipython-input-9-cdb6cff51b73>, line 1)\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Conversion failed on the following:\n12_a3c.a3c_data.ipynb\n05a_data.ipynb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3b122d1c3416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnotebook2script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnotebook2html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/fastrl/lib/python3.7/site-packages/nbdev/export2html.py\u001b[0m in \u001b[0;36mnotebook2html\u001b[0;34m(fname, force_all, n_workers, cls, template_file, exporter, dest, pause)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Conversion failed on the following:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Conversion failed on the following:\n12_a3c.a3c_data.ipynb\n05a_data.ipynb"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()\n",
    "notebook2html(n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
